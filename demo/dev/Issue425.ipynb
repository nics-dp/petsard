{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alex/PETsARD\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/alex/PETsARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PETsARD import Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Loader with adult-income...\n",
      "Loader - Benchmarker: file benchmark/adult-income.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "Now is Splitter with p80_[3-1]...\n",
      "Now is Preprocessor with default-smartnoise...\n",
      "Now is Synthesizer with smartnoise-dpctgan1...\n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n",
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.6638, Loss D: 1.4180\n",
      "epsilon is 0.15860823157309964, alpha is 63.0\n",
      "Epoch 2, Loss G: 0.6776, Loss D: 1.4011\n",
      "epsilon is 0.2216642694416628, alpha is 63.0\n",
      "Epoch 3, Loss G: 0.6861, Loss D: 1.3940\n",
      "epsilon is 0.28472030731022596, alpha is 63.0\n",
      "Epoch 4, Loss G: 0.6762, Loss D: 1.3812\n",
      "epsilon is 0.34710902716040415, alpha is 60.0\n",
      "Epoch 5, Loss G: 0.6738, Loss D: 1.3817\n",
      "epsilon is 0.4024613095868127, alpha is 52.0\n",
      "Epoch 6, Loss G: 0.6471, Loss D: 1.3979\n",
      "epsilon is 0.4515993657903439, alpha is 47.0\n",
      "Epoch 7, Loss G: 0.6596, Loss D: 1.3907\n",
      "epsilon is 0.4962859837952557, alpha is 44.0\n",
      "Epoch 8, Loss G: 0.6551, Loss D: 1.3856\n",
      "epsilon is 0.5375915636650713, alpha is 41.0\n",
      "Epoch 9, Loss G: 0.6494, Loss D: 1.3961\n",
      "epsilon is 0.5762365810254404, alpha is 38.0\n",
      "Epoch 10, Loss G: 0.6402, Loss D: 1.4045\n",
      "epsilon is 0.6126697704683502, alpha is 36.0\n",
      "Epoch 11, Loss G: 0.6491, Loss D: 1.3988\n",
      "epsilon is 0.647234091186736, alpha is 35.0\n",
      "Epoch 12, Loss G: 0.6509, Loss D: 1.3873\n",
      "epsilon is 0.6802222968339516, alpha is 33.0\n",
      "Epoch 13, Loss G: 0.6409, Loss D: 1.3922\n",
      "epsilon is 0.7118279736110865, alpha is 32.0\n",
      "Epoch 14, Loss G: 0.6450, Loss D: 1.3940\n",
      "epsilon is 0.7422620138594418, alpha is 31.0\n",
      "Epoch 15, Loss G: 0.6397, Loss D: 1.3958\n",
      "epsilon is 0.7716159290947441, alpha is 30.0\n",
      "Epoch 16, Loss G: 0.6281, Loss D: 1.4060\n",
      "epsilon is 0.7999936860599901, alpha is 29.0\n",
      "Epoch 17, Loss G: 0.6327, Loss D: 1.3900\n",
      "epsilon is 0.8275140561350208, alpha is 28.0\n",
      "Epoch 18, Loss G: 0.6299, Loss D: 1.3938\n",
      "epsilon is 0.8543135139612916, alpha is 27.0\n",
      "Epoch 19, Loss G: 0.6234, Loss D: 1.3985\n",
      "epsilon is 0.8803777006335741, alpha is 27.0\n",
      "Epoch 20, Loss G: 0.6252, Loss D: 1.3981\n",
      "epsilon is 0.905624272189402, alpha is 26.0\n",
      "Epoch 21, Loss G: 0.6196, Loss D: 1.4033\n",
      "epsilon is 0.9304932560453646, alpha is 25.0\n",
      "Epoch 22, Loss G: 0.6202, Loss D: 1.4000\n",
      "epsilon is 0.9545798718600312, alpha is 25.0\n",
      "Epoch 23, Loss G: 0.6214, Loss D: 1.3965\n",
      "epsilon is 0.9783005120040562, alpha is 24.0\n",
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 83.0615 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 21574 rows (same as raw) in 1.2 sec.\n",
      "Now is Postprocessor with default-smartnoise...\n",
      "Now is Evaluator with sdmetrics-diag...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|██████████| 15/15 [00:00<00:00, 811.81it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|██████████| 1/1 [00:00<00:00, 414.74it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-1]_[train]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-1]_[validation]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Evaluator with sdmetrics-qual...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 193.43it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:01<00:00, 58.09it/s]\n",
      "\n",
      "Overall Score: 51.42%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 68.45%\n",
      "- Column Pair Trends: 34.39%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-1]_[train]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-1]_[validation]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Synthesizer with smartnoise-dpctgan01...\n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n",
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 0.1976 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizer (SmartNoise): Sampling dpctgan # 21574 rows (same as raw) in 1.1906 sec.\n",
      "Now is Postprocessor with default-smartnoise...\n",
      "Now is Evaluator with sdmetrics-diag...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|██████████| 15/15 [00:00<00:00, 1050.87it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|██████████| 1/1 [00:00<00:00, 1368.01it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-1]_[train]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-1]_[validation]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan01]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Evaluator with sdmetrics-qual...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 223.00it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:01<00:00, 59.22it/s]\n",
      "\n",
      "Overall Score: 47.38%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 60.28%\n",
      "- Column Pair Trends: 34.47%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-1]_[train]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-1]_[validation]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan01]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Splitter with p80_[3-2]...\n",
      "Now is Preprocessor with default-smartnoise...\n",
      "Now is Synthesizer with smartnoise-dpctgan1...\n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n",
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.6651, Loss D: 1.4011\n",
      "epsilon is 0.15866311892080576, alpha is 63.0\n",
      "Epoch 2, Loss G: 0.6797, Loss D: 1.4004\n",
      "epsilon is 0.22142493498885218, alpha is 63.0\n",
      "Epoch 3, Loss G: 0.6961, Loss D: 1.3864\n",
      "epsilon is 0.28418675105689856, alpha is 63.0\n",
      "Epoch 4, Loss G: 0.6758, Loss D: 1.3895\n",
      "epsilon is 0.34633002942105806, alpha is 60.0\n",
      "Epoch 5, Loss G: 0.6661, Loss D: 1.3875\n",
      "epsilon is 0.4015731545481313, alpha is 52.0\n",
      "Epoch 6, Loss G: 0.6583, Loss D: 1.3982\n",
      "epsilon is 0.4506005161157811, alpha is 48.0\n",
      "Epoch 7, Loss G: 0.6509, Loss D: 1.3993\n",
      "epsilon is 0.49516787482910385, alpha is 44.0\n",
      "Epoch 8, Loss G: 0.6495, Loss D: 1.3954\n",
      "epsilon is 0.536380963391444, alpha is 41.0\n",
      "Epoch 9, Loss G: 0.6383, Loss D: 1.4014\n",
      "epsilon is 0.5749622912348105, alpha is 38.0\n",
      "Epoch 10, Loss G: 0.6410, Loss D: 1.3982\n",
      "epsilon is 0.6113151880138817, alpha is 36.0\n",
      "Epoch 11, Loss G: 0.6375, Loss D: 1.4007\n",
      "epsilon is 0.6457681952056338, alpha is 35.0\n",
      "Epoch 12, Loss G: 0.6365, Loss D: 1.3995\n",
      "epsilon is 0.6787092989025427, alpha is 33.0\n",
      "Epoch 13, Loss G: 0.6392, Loss D: 1.4004\n",
      "epsilon is 0.7102272545279615, alpha is 32.0\n",
      "Epoch 14, Loss G: 0.6382, Loss D: 1.3890\n",
      "epsilon is 0.7405829652116281, alpha is 31.0\n",
      "Epoch 15, Loss G: 0.6410, Loss D: 1.3917\n",
      "epsilon is 0.7698679254741809, alpha is 30.0\n",
      "Epoch 16, Loss G: 0.6356, Loss D: 1.3879\n",
      "epsilon is 0.7981860887310861, alpha is 29.0\n",
      "Epoch 17, Loss G: 0.6339, Loss D: 1.3956\n",
      "epsilon is 0.8256562173252816, alpha is 28.0\n",
      "Epoch 18, Loss G: 0.6376, Loss D: 1.3936\n",
      "epsilon is 0.8524147819194525, alpha is 27.0\n",
      "Epoch 19, Loss G: 0.6288, Loss D: 1.3955\n",
      "epsilon is 0.8783595793414056, alpha is 27.0\n",
      "Epoch 20, Loss G: 0.6269, Loss D: 1.3977\n",
      "epsilon is 0.9035791974396322, alpha is 26.0\n",
      "Epoch 21, Loss G: 0.6331, Loss D: 1.3990\n",
      "epsilon is 0.928430573891368, alpha is 25.0\n",
      "Epoch 22, Loss G: 0.6254, Loss D: 1.3985\n",
      "epsilon is 0.9524069659825894, alpha is 25.0\n",
      "Epoch 23, Loss G: 0.6242, Loss D: 1.3918\n",
      "epsilon is 0.9761239254276721, alpha is 24.0\n",
      "Epoch 24, Loss G: 0.6248, Loss D: 1.3961\n",
      "epsilon is 0.9991189965420118, alpha is 24.0\n",
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 85.8581 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 21623 rows (same as raw) in 1.2932 sec.\n",
      "Now is Postprocessor with default-smartnoise...\n",
      "Now is Evaluator with sdmetrics-diag...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|██████████| 15/15 [00:00<00:00, 1044.94it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|██████████| 1/1 [00:00<00:00, 1267.54it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-2]_[train]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-2]_[validation]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Evaluator with sdmetrics-qual...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 206.49it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:01<00:00, 59.54it/s]\n",
      "\n",
      "Overall Score: 56.45%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 72.12%\n",
      "- Column Pair Trends: 40.78%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-2]_[train]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-2]_[validation]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Synthesizer with smartnoise-dpctgan01...\n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 0.3847 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 21623 rows (same as raw) in 1.2351 sec.\n",
      "Now is Postprocessor with default-smartnoise...\n",
      "Now is Evaluator with sdmetrics-diag...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|██████████| 15/15 [00:00<00:00, 986.43it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|██████████| 1/1 [00:00<00:00, 1321.04it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-2]_[train]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-2]_[validation]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan01]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Evaluator with sdmetrics-qual...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 227.06it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:01<00:00, 59.85it/s]\n",
      "\n",
      "Overall Score: 48.79%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 61.9%\n",
      "- Column Pair Trends: 35.68%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-2]_[train]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-2]_[validation]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan01]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Splitter with p80_[3-3]...\n",
      "Now is Preprocessor with default-smartnoise...\n",
      "Now is Synthesizer with smartnoise-dpctgan1...\n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n",
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.6649, Loss D: 1.4043\n",
      "epsilon is 0.1585509713673449, alpha is 63.0\n",
      "Epoch 2, Loss G: 0.6787, Loss D: 1.4056\n",
      "epsilon is 0.22191544334461827, alpha is 63.0\n",
      "Epoch 3, Loss G: 0.6933, Loss D: 1.3861\n",
      "epsilon is 0.2852799153218917, alpha is 63.0\n",
      "Epoch 4, Loss G: 0.6827, Loss D: 1.3834\n",
      "epsilon is 0.3479140147506966, alpha is 59.0\n",
      "Epoch 5, Loss G: 0.6643, Loss D: 1.3866\n",
      "epsilon is 0.403392662020092, alpha is 52.0\n",
      "Epoch 6, Loss G: 0.6544, Loss D: 1.3956\n",
      "epsilon is 0.452644434043316, alpha is 47.0\n",
      "Epoch 7, Loss G: 0.6571, Loss D: 1.3916\n",
      "epsilon is 0.497458412238722, alpha is 44.0\n",
      "Epoch 8, Loss G: 0.6531, Loss D: 1.3924\n",
      "epsilon is 0.5388609587598374, alpha is 41.0\n",
      "Epoch 9, Loss G: 0.6455, Loss D: 1.4029\n",
      "epsilon is 0.5775727553096368, alpha is 38.0\n",
      "Epoch 10, Loss G: 0.6468, Loss D: 1.3987\n",
      "epsilon is 0.614090123130953, alpha is 36.0\n",
      "Epoch 11, Loss G: 0.6437, Loss D: 1.3953\n",
      "epsilon is 0.648771130744903, alpha is 35.0\n",
      "Epoch 12, Loss G: 0.6427, Loss D: 1.3902\n",
      "epsilon is 0.6818087273645281, alpha is 33.0\n",
      "Epoch 13, Loss G: 0.6373, Loss D: 1.4001\n",
      "epsilon is 0.713506362926507, alpha is 32.0\n",
      "Epoch 14, Loss G: 0.6444, Loss D: 1.3989\n",
      "epsilon is 0.7440225183825124, alpha is 31.0\n",
      "Epoch 15, Loss G: 0.6368, Loss D: 1.3940\n",
      "epsilon is 0.7734487232837379, alpha is 30.0\n",
      "Epoch 16, Loss G: 0.6426, Loss D: 1.3934\n",
      "epsilon is 0.8018889585796374, alpha is 29.0\n",
      "Epoch 17, Loss G: 0.6414, Loss D: 1.3974\n",
      "epsilon is 0.8294620053775574, alpha is 28.0\n",
      "Epoch 18, Loss G: 0.6360, Loss D: 1.3945\n",
      "epsilon is 0.8563043427668217, alpha is 27.0\n",
      "Epoch 19, Loss G: 0.6409, Loss D: 1.3913\n",
      "epsilon is 0.8824936689904629, alpha is 27.0\n",
      "Epoch 20, Loss G: 0.6401, Loss D: 1.3974\n",
      "epsilon is 0.9077685101667551, alpha is 26.0\n",
      "Epoch 21, Loss G: 0.6376, Loss D: 1.3884\n",
      "epsilon is 0.932655969460448, alpha is 25.0\n",
      "Epoch 22, Loss G: 0.6362, Loss D: 1.3944\n",
      "epsilon is 0.9568581170557787, alpha is 25.0\n",
      "Epoch 23, Loss G: 0.6354, Loss D: 1.3942\n",
      "epsilon is 0.9805826372112327, alpha is 24.0\n",
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 83.5855 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 21523 rows (same as raw) in 1.3364 sec.\n",
      "Now is Postprocessor with default-smartnoise...\n",
      "Now is Evaluator with sdmetrics-diag...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|██████████| 15/15 [00:00<00:00, 1062.39it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|██████████| 1/1 [00:00<00:00, 1240.55it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-3]_[train]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-3]_[validation]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-3]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Evaluator with sdmetrics-qual...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 220.82it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:01<00:00, 57.38it/s]\n",
      "\n",
      "Overall Score: 58.94%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 73.75%\n",
      "- Column Pair Trends: 44.13%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-3]_[train]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-3]_[validation]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-3]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Synthesizer with smartnoise-dpctgan01...\n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 0.2082 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 21523 rows (same as raw) in 1.2559 sec.\n",
      "Now is Postprocessor with default-smartnoise...\n",
      "Now is Evaluator with sdmetrics-diag...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|██████████| 15/15 [00:00<00:00, 1003.09it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|██████████| 1/1 [00:00<00:00, 1644.83it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-3]_[train]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-3]_[validation]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-3]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan01]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Evaluator with sdmetrics-qual...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 214.03it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:01<00:00, 58.62it/s]\n",
      "\n",
      "Overall Score: 48.59%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 60.96%\n",
      "- Column Pair Trends: 36.22%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-3]_[train]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-3]_[validation]] save to csv...\n",
      "Now is 20240328_exp6_na_Loader[adult-income]_Splitter[p80_[3-3]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan01]_Postprocessor[default-smartnoise] save to csv...\n"
     ]
    }
   ],
   "source": [
    "exec = Executor(config='exp7.yaml')\n",
    "exec.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PETsARD import Synthesizer, Loader, Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = Synthesizer(method='smartnoise-dpctgan', epsilon=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = Loader(filepath='benchmark://adult-income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader - Benchmarker: file benchmark/adult-income.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n"
     ]
    }
   ],
   "source": [
    "load.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = Processor(load.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro.fit(load.data)\n",
    "pre = pro.transform(load.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre['a1'] = 0\n",
    "pre['a2'] = np.random.random(pre.shape[0])\n",
    "pre['a3'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.995129</td>\n",
       "      <td>0.503377</td>\n",
       "      <td>0.351675</td>\n",
       "      <td>0.835431</td>\n",
       "      <td>-1.197259</td>\n",
       "      <td>0.661662</td>\n",
       "      <td>0.757997</td>\n",
       "      <td>0.778627</td>\n",
       "      <td>0.918438</td>\n",
       "      <td>0.291492</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>0.604155</td>\n",
       "      <td>0.033620</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.046942</td>\n",
       "      <td>0.588156</td>\n",
       "      <td>-0.945524</td>\n",
       "      <td>0.057819</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>0.378804</td>\n",
       "      <td>0.927623</td>\n",
       "      <td>0.122937</td>\n",
       "      <td>0.666068</td>\n",
       "      <td>0.527087</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.772930</td>\n",
       "      <td>0.636385</td>\n",
       "      <td>0.132525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.776316</td>\n",
       "      <td>0.787260</td>\n",
       "      <td>1.394723</td>\n",
       "      <td>0.864528</td>\n",
       "      <td>0.747550</td>\n",
       "      <td>0.346997</td>\n",
       "      <td>0.984199</td>\n",
       "      <td>0.221977</td>\n",
       "      <td>0.243266</td>\n",
       "      <td>0.419463</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>0.034265</td>\n",
       "      <td>0.812162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.703379</td>\n",
       "      <td>0.859461</td>\n",
       "      <td>0.353796</td>\n",
       "      <td>0.308732</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>0.542282</td>\n",
       "      <td>0.789915</td>\n",
       "      <td>0.910324</td>\n",
       "      <td>0.862913</td>\n",
       "      <td>0.494145</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>0.855088</td>\n",
       "      <td>0.645976</td>\n",
       "      <td>0</td>\n",
       "      <td>0.577522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.068066</td>\n",
       "      <td>0.604215</td>\n",
       "      <td>1.704525</td>\n",
       "      <td>0.499208</td>\n",
       "      <td>-0.030373</td>\n",
       "      <td>0.544271</td>\n",
       "      <td>0.667095</td>\n",
       "      <td>0.879964</td>\n",
       "      <td>0.609112</td>\n",
       "      <td>0.880922</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>0.251747</td>\n",
       "      <td>0.161525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28553</th>\n",
       "      <td>1.047121</td>\n",
       "      <td>0.071625</td>\n",
       "      <td>1.251867</td>\n",
       "      <td>0.737525</td>\n",
       "      <td>1.525474</td>\n",
       "      <td>0.227831</td>\n",
       "      <td>0.311953</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.698924</td>\n",
       "      <td>0.310281</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>0.532051</td>\n",
       "      <td>0.901186</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28554</th>\n",
       "      <td>-1.213941</td>\n",
       "      <td>0.353624</td>\n",
       "      <td>1.140952</td>\n",
       "      <td>0.408477</td>\n",
       "      <td>-0.030373</td>\n",
       "      <td>0.626076</td>\n",
       "      <td>0.984686</td>\n",
       "      <td>0.555693</td>\n",
       "      <td>0.133992</td>\n",
       "      <td>0.273176</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>0.439570</td>\n",
       "      <td>0.705194</td>\n",
       "      <td>0</td>\n",
       "      <td>0.537257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28555</th>\n",
       "      <td>-0.849254</td>\n",
       "      <td>0.515404</td>\n",
       "      <td>0.640492</td>\n",
       "      <td>0.871191</td>\n",
       "      <td>0.747550</td>\n",
       "      <td>0.296695</td>\n",
       "      <td>0.962364</td>\n",
       "      <td>0.960930</td>\n",
       "      <td>0.806830</td>\n",
       "      <td>0.860804</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.195490</td>\n",
       "      <td>0.428895</td>\n",
       "      <td>0.164286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28556</th>\n",
       "      <td>0.098933</td>\n",
       "      <td>0.240612</td>\n",
       "      <td>-0.334178</td>\n",
       "      <td>0.216394</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>0.235095</td>\n",
       "      <td>0.761610</td>\n",
       "      <td>0.077530</td>\n",
       "      <td>0.813487</td>\n",
       "      <td>0.182156</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>0.708335</td>\n",
       "      <td>0.854212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.596671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28557</th>\n",
       "      <td>1.411808</td>\n",
       "      <td>0.217383</td>\n",
       "      <td>-0.357510</td>\n",
       "      <td>0.016569</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>0.965923</td>\n",
       "      <td>0.486063</td>\n",
       "      <td>0.904605</td>\n",
       "      <td>0.484651</td>\n",
       "      <td>0.687867</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>0.101099</td>\n",
       "      <td>0.529202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28558 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  workclass    fnlwgt  education  educational-num  \\\n",
       "0     -0.995129   0.503377  0.351675   0.835431        -1.197259   \n",
       "1     -0.046942   0.588156 -0.945524   0.057819        -0.419335   \n",
       "2     -0.776316   0.787260  1.394723   0.864528         0.747550   \n",
       "3     -0.703379   0.859461  0.353796   0.308732        -0.419335   \n",
       "4     -1.068066   0.604215  1.704525   0.499208        -0.030373   \n",
       "...         ...        ...       ...        ...              ...   \n",
       "28553  1.047121   0.071625  1.251867   0.737525         1.525474   \n",
       "28554 -1.213941   0.353624  1.140952   0.408477        -0.030373   \n",
       "28555 -0.849254   0.515404  0.640492   0.871191         0.747550   \n",
       "28556  0.098933   0.240612 -0.334178   0.216394        -0.419335   \n",
       "28557  1.411808   0.217383 -0.357510   0.016569        -0.419335   \n",
       "\n",
       "       marital-status  occupation  relationship      race    gender  \\\n",
       "0            0.661662    0.757997      0.778627  0.918438  0.291492   \n",
       "1            0.378804    0.927623      0.122937  0.666068  0.527087   \n",
       "2            0.346997    0.984199      0.221977  0.243266  0.419463   \n",
       "3            0.542282    0.789915      0.910324  0.862913  0.494145   \n",
       "4            0.544271    0.667095      0.879964  0.609112  0.880922   \n",
       "...               ...         ...           ...       ...       ...   \n",
       "28553        0.227831    0.311953      0.012006  0.698924  0.310281   \n",
       "28554        0.626076    0.984686      0.555693  0.133992  0.273176   \n",
       "28555        0.296695    0.962364      0.960930  0.806830  0.860804   \n",
       "28556        0.235095    0.761610      0.077530  0.813487  0.182156   \n",
       "28557        0.965923    0.486063      0.904605  0.484651  0.687867   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country    income  \\\n",
       "0         -0.144804     -0.217127       -0.034087        0.604155  0.033620   \n",
       "1         -0.144804     -0.217127        0.772930        0.636385  0.132525   \n",
       "2         -0.144804     -0.217127       -0.034087        0.034265  0.812162   \n",
       "3         -0.144804     -0.217127       -0.034087        0.855088  0.645976   \n",
       "4         -0.144804     -0.217127       -0.034087        0.251747  0.161525   \n",
       "...             ...           ...             ...             ...       ...   \n",
       "28553     -0.144804     -0.217127       -0.034087        0.532051  0.901186   \n",
       "28554     -0.144804     -0.217127       -0.034087        0.439570  0.705194   \n",
       "28555     -0.144804     -0.217127       -0.195490        0.428895  0.164286   \n",
       "28556     -0.144804     -0.217127       -0.034087        0.708335  0.854212   \n",
       "28557     -0.144804     -0.217127       -0.034087        0.101099  0.529202   \n",
       "\n",
       "       a1        a2  a3  \n",
       "0       0  0.871788   1  \n",
       "1       0  0.029399   1  \n",
       "2       0  0.349855   1  \n",
       "3       0  0.577522   1  \n",
       "4       0  0.295154   1  \n",
       "...    ..       ...  ..  \n",
       "28553   0  0.937796   1  \n",
       "28554   0  0.537257   1  \n",
       "28555   0  0.512454   1  \n",
       "28556   0  0.596671   1  \n",
       "28557   0  0.092375   1  \n",
       "\n",
       "[28558 rows x 18 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn.create(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n",
      "/Users/alex/miniforge3/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.6213, Loss D: 1.4276\n",
      "epsilon is 0.16539326917926575, alpha is 63.0\n",
      "Epoch 2, Loss G: 0.6474, Loss D: 1.3944\n",
      "epsilon is 0.21238679862294077, alpha is 63.0\n",
      "Epoch 3, Loss G: 0.6488, Loss D: 1.3935\n",
      "epsilon is 0.25938032806661576, alpha is 63.0\n",
      "Epoch 4, Loss G: 0.6197, Loss D: 1.3962\n",
      "epsilon is 0.3063738575102908, alpha is 63.0\n",
      "Epoch 5, Loss G: 0.5991, Loss D: 1.4126\n",
      "epsilon is 0.3531762138695386, alpha is 61.0\n",
      "Epoch 6, Loss G: 0.6009, Loss D: 1.4024\n",
      "epsilon is 0.39631335278973134, alpha is 55.0\n",
      "Epoch 7, Loss G: 0.5924, Loss D: 1.4049\n",
      "epsilon is 0.43552886535289415, alpha is 51.0\n",
      "Epoch 8, Loss G: 0.5884, Loss D: 1.4080\n",
      "epsilon is 0.47179542622961596, alpha is 47.0\n",
      "Epoch 9, Loss G: 0.5837, Loss D: 1.4060\n",
      "epsilon is 0.5056658918344662, alpha is 45.0\n",
      "Epoch 10, Loss G: 0.5652, Loss D: 1.4268\n",
      "epsilon is 0.5376066394269979, alpha is 42.0\n",
      "Epoch 11, Loss G: 0.5629, Loss D: 1.4130\n",
      "epsilon is 0.5679249663015458, alpha is 40.0\n",
      "Epoch 12, Loss G: 0.5691, Loss D: 1.4121\n",
      "epsilon is 0.596853491098662, alpha is 39.0\n",
      "Epoch 13, Loss G: 0.5676, Loss D: 1.4103\n",
      "epsilon is 0.6245402216922431, alpha is 37.0\n",
      "Epoch 14, Loss G: 0.5736, Loss D: 1.4094\n",
      "epsilon is 0.6511997413860319, alpha is 36.0\n",
      "Epoch 15, Loss G: 0.5739, Loss D: 1.4152\n",
      "epsilon is 0.6769469490953505, alpha is 35.0\n",
      "Epoch 16, Loss G: 0.5724, Loss D: 1.4131\n",
      "epsilon is 0.701838749784307, alpha is 34.0\n",
      "Epoch 17, Loss G: 0.5704, Loss D: 1.4093\n",
      "epsilon is 0.7259388662962076, alpha is 33.0\n",
      "Epoch 18, Loss G: 0.5620, Loss D: 1.4183\n",
      "epsilon is 0.7493189583899535, alpha is 32.0\n",
      "Epoch 19, Loss G: 0.5636, Loss D: 1.4123\n",
      "epsilon is 0.7720599684284829, alpha is 31.0\n",
      "Epoch 20, Loss G: 0.5480, Loss D: 1.4283\n",
      "epsilon is 0.7942537490212791, alpha is 30.0\n",
      "Epoch 21, Loss G: 0.5474, Loss D: 1.4199\n",
      "epsilon is 0.81600504387155, alpha is 29.0\n",
      "Epoch 22, Loss G: 0.5372, Loss D: 1.4194\n",
      "epsilon is 0.8370915714324787, alpha is 29.0\n",
      "Epoch 23, Loss G: 0.5377, Loss D: 1.4226\n",
      "epsilon is 0.8577783729641005, alpha is 28.0\n",
      "Epoch 24, Loss G: 0.5333, Loss D: 1.4139\n",
      "epsilon is 0.8781228315395789, alpha is 28.0\n",
      "Epoch 25, Loss G: 0.5356, Loss D: 1.4186\n",
      "epsilon is 0.8978857049882135, alpha is 27.0\n",
      "Epoch 26, Loss G: 0.5235, Loss D: 1.4326\n",
      "epsilon is 0.9174891907963331, alpha is 27.0\n",
      "Epoch 27, Loss G: 0.5174, Loss D: 1.4374\n",
      "epsilon is 0.936490724224457, alpha is 26.0\n",
      "Epoch 28, Loss G: 0.5217, Loss D: 1.4430\n",
      "epsilon is 0.9553543302144257, alpha is 26.0\n",
      "Epoch 29, Loss G: 0.5156, Loss D: 1.4297\n",
      "epsilon is 0.973783797857625, alpha is 25.0\n",
      "Epoch 30, Loss G: 0.5104, Loss D: 1.4339\n",
      "epsilon is 0.9919086137251131, alpha is 25.0\n",
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 145.8527 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 28558 rows (same as raw) in 1.8905 sec.\n"
     ]
    }
   ],
   "source": [
    "syn.fit_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.213842</td>\n",
       "      <td>0.378421</td>\n",
       "      <td>-1.665627</td>\n",
       "      <td>0.457459</td>\n",
       "      <td>0.915976</td>\n",
       "      <td>0.755850</td>\n",
       "      <td>0.625214</td>\n",
       "      <td>0.528381</td>\n",
       "      <td>0.313889</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.298984</td>\n",
       "      <td>0.691848</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>0</td>\n",
       "      <td>0.316471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070798</td>\n",
       "      <td>0.260739</td>\n",
       "      <td>-0.845750</td>\n",
       "      <td>0.318958</td>\n",
       "      <td>-0.464415</td>\n",
       "      <td>0.653427</td>\n",
       "      <td>0.335096</td>\n",
       "      <td>0.267787</td>\n",
       "      <td>0.834815</td>\n",
       "      <td>0.425244</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.223387</td>\n",
       "      <td>0.612194</td>\n",
       "      <td>0.439642</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391335</td>\n",
       "      <td>0.669126</td>\n",
       "      <td>-1.461205</td>\n",
       "      <td>0.364340</td>\n",
       "      <td>1.525971</td>\n",
       "      <td>0.482476</td>\n",
       "      <td>0.249313</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.807993</td>\n",
       "      <td>0.559630</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.320505</td>\n",
       "      <td>0.643952</td>\n",
       "      <td>0.677502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.785340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.700239</td>\n",
       "      <td>0.274085</td>\n",
       "      <td>-1.665627</td>\n",
       "      <td>0.609465</td>\n",
       "      <td>0.619518</td>\n",
       "      <td>0.362836</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.508626</td>\n",
       "      <td>0.708894</td>\n",
       "      <td>0.516176</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.403409</td>\n",
       "      <td>0.621772</td>\n",
       "      <td>0.400277</td>\n",
       "      <td>0</td>\n",
       "      <td>0.765021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.334466</td>\n",
       "      <td>0.188462</td>\n",
       "      <td>0.663565</td>\n",
       "      <td>0.734834</td>\n",
       "      <td>0.946645</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.387464</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.623019</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.582947</td>\n",
       "      <td>0.647679</td>\n",
       "      <td>0.569104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.763882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28553</th>\n",
       "      <td>-0.715579</td>\n",
       "      <td>0.223443</td>\n",
       "      <td>-1.665627</td>\n",
       "      <td>0.511427</td>\n",
       "      <td>-1.146148</td>\n",
       "      <td>0.599685</td>\n",
       "      <td>0.498482</td>\n",
       "      <td>0.669555</td>\n",
       "      <td>0.079360</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.056692</td>\n",
       "      <td>0.725708</td>\n",
       "      <td>0.104803</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28554</th>\n",
       "      <td>-0.179735</td>\n",
       "      <td>0.269597</td>\n",
       "      <td>-1.665627</td>\n",
       "      <td>0.141874</td>\n",
       "      <td>0.484982</td>\n",
       "      <td>0.852177</td>\n",
       "      <td>0.517799</td>\n",
       "      <td>0.565493</td>\n",
       "      <td>0.745751</td>\n",
       "      <td>0.449720</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.234959</td>\n",
       "      <td>0.648658</td>\n",
       "      <td>0.230802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.650293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28555</th>\n",
       "      <td>1.202145</td>\n",
       "      <td>0.281587</td>\n",
       "      <td>-1.665627</td>\n",
       "      <td>0.446594</td>\n",
       "      <td>-0.239144</td>\n",
       "      <td>0.931462</td>\n",
       "      <td>0.382002</td>\n",
       "      <td>0.843361</td>\n",
       "      <td>0.707828</td>\n",
       "      <td>0.190422</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.109349</td>\n",
       "      <td>0.721817</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28556</th>\n",
       "      <td>0.929170</td>\n",
       "      <td>0.284173</td>\n",
       "      <td>-1.665627</td>\n",
       "      <td>0.765168</td>\n",
       "      <td>1.743282</td>\n",
       "      <td>0.666401</td>\n",
       "      <td>0.270140</td>\n",
       "      <td>0.219959</td>\n",
       "      <td>0.602144</td>\n",
       "      <td>0.637914</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.429247</td>\n",
       "      <td>0.775983</td>\n",
       "      <td>0.173159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.757490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28557</th>\n",
       "      <td>-0.042280</td>\n",
       "      <td>0.401752</td>\n",
       "      <td>0.224381</td>\n",
       "      <td>0.540044</td>\n",
       "      <td>0.641416</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.671715</td>\n",
       "      <td>0.117993</td>\n",
       "      <td>0.495781</td>\n",
       "      <td>0.112364</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.707899</td>\n",
       "      <td>0.604601</td>\n",
       "      <td>0.634655</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28558 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  workclass    fnlwgt  education  educational-num  \\\n",
       "0     -0.213842   0.378421 -1.665627   0.457459         0.915976   \n",
       "1      0.070798   0.260739 -0.845750   0.318958        -0.464415   \n",
       "2      0.391335   0.669126 -1.461205   0.364340         1.525971   \n",
       "3      0.700239   0.274085 -1.665627   0.609465         0.619518   \n",
       "4      0.334466   0.188462  0.663565   0.734834         0.946645   \n",
       "...         ...        ...       ...        ...              ...   \n",
       "28553 -0.715579   0.223443 -1.665627   0.511427        -1.146148   \n",
       "28554 -0.179735   0.269597 -1.665627   0.141874         0.484982   \n",
       "28555  1.202145   0.281587 -1.665627   0.446594        -0.239144   \n",
       "28556  0.929170   0.284173 -1.665627   0.765168         1.743282   \n",
       "28557 -0.042280   0.401752  0.224381   0.540044         0.641416   \n",
       "\n",
       "       marital-status  occupation  relationship      race    gender  \\\n",
       "0            0.755850    0.625214      0.528381  0.313889  0.000051   \n",
       "1            0.653427    0.335096      0.267787  0.834815  0.425244   \n",
       "2            0.482476    0.249313      0.000024  0.807993  0.559630   \n",
       "3            0.362836    0.000036      0.508626  0.708894  0.516176   \n",
       "4            0.000006    0.387464      0.000024  0.623019  0.000051   \n",
       "...               ...         ...           ...       ...       ...   \n",
       "28553        0.599685    0.498482      0.669555  0.079360  0.000051   \n",
       "28554        0.852177    0.517799      0.565493  0.745751  0.449720   \n",
       "28555        0.931462    0.382002      0.843361  0.707828  0.190422   \n",
       "28556        0.666401    0.270140      0.219959  0.602144  0.637914   \n",
       "28557        0.000006    0.671715      0.117993  0.495781  0.112364   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country    income  \\\n",
       "0         -0.144804     -0.217127        0.298984        0.691848  0.012382   \n",
       "1         -0.144804     -0.217127        0.223387        0.612194  0.439642   \n",
       "2         -0.144804     -0.217127        0.320505        0.643952  0.677502   \n",
       "3         -0.144804     -0.217127        0.403409        0.621772  0.400277   \n",
       "4         -0.144804     -0.217127        0.582947        0.647679  0.569104   \n",
       "...             ...           ...             ...             ...       ...   \n",
       "28553     -0.144804     -0.217127        0.056692        0.725708  0.104803   \n",
       "28554     -0.144804     -0.217127        0.234959        0.648658  0.230802   \n",
       "28555     -0.144804     -0.217127        0.109349        0.721817  0.000061   \n",
       "28556     -0.144804     -0.217127        0.429247        0.775983  0.173159   \n",
       "28557     -0.144804     -0.217127        0.707899        0.604601  0.634655   \n",
       "\n",
       "       a1        a2  a3  \n",
       "0       0  0.316471   1  \n",
       "1       0  0.507375   1  \n",
       "2       0  0.785340   1  \n",
       "3       0  0.765021   1  \n",
       "4       0  0.763882   1  \n",
       "...    ..       ...  ..  \n",
       "28553   0  0.471054   1  \n",
       "28554   0  0.650293   1  \n",
       "28555   0  0.456195   1  \n",
       "28556   0  0.757490   1  \n",
       "28557   0  0.673111   1  \n",
       "\n",
       "[28558 rows x 18 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn.data_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
