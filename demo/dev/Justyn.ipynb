{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "path_petsard = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(path_petsard)\n",
    "sys.path.append(path_petsard)\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Test: import PETsARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Reporter' from 'PETsARD.reporter' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPETsARD\u001b[39;00m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\__init__.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPETsARD\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msynthesizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Synthesizer\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPETsARD\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Evaluator, Describer\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPETsARD\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Reporter\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPETsARD\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPETsARD\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, Status\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Reporter' from 'PETsARD.reporter' (unknown location)"
     ]
    }
   ],
   "source": [
    "import PETsARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Test: Module-by-Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader - Benchmarker: file benchmark\\adult.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "   age workclass  fnlwgt education  educational-num marital-status  \\\n",
      "0   25   Private  226802      11th                7  Never-married   \n",
      "\n",
      "          occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Machine-op-inspct    Own-child  Black   Male             0             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              40  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "from PETsARD import Loader\n",
    "\n",
    "\n",
    "load = Loader(\n",
    "    filepath='benchmark://adult',\n",
    "    na_values={k: '?' for k in [\n",
    "        'workclass',\n",
    "        'occupation',\n",
    "        'native-country'\n",
    "    ]}\n",
    ")\n",
    "load.load()\n",
    "print(load.data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col': {'age': {...},\n",
      "         'capital-gain': {...},\n",
      "         'capital-loss': {...},\n",
      "         'education': {...},\n",
      "         'educational-num': {...},\n",
      "         'fnlwgt': {...},\n",
      "         'gender': {...},\n",
      "         'hours-per-week': {...},\n",
      "         'income': {...},\n",
      "         'marital-status': {...},\n",
      "         'native-country': {...},\n",
      "         'occupation': {...},\n",
      "         'race': {...},\n",
      "         'relationship': {...},\n",
      "         'workclass': {...}},\n",
      " 'global': {'col_num': 15,\n",
      "            'na_percentage': 0.07411653904426518,\n",
      "            'row_num': 48842}}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(load.metadata.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4884\n",
      "43958\n",
      "   age  workclass  fnlwgt   education  educational-num      marital-status  \\\n",
      "0   28  Local-gov  336951  Assoc-acdm               12  Married-civ-spouse   \n",
      "\n",
      "        occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Protective-serv      Husband  White   Male             0             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              40  United-States   >50K  \n",
      "   age workclass  fnlwgt education  educational-num marital-status  \\\n",
      "0   25   Private  226802      11th                7  Never-married   \n",
      "\n",
      "          occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Machine-op-inspct    Own-child  Black   Male             0             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              40  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "from PETsARD import Splitter\n",
    "\n",
    "\n",
    "split = Splitter(\n",
    "    num_samples=30,\n",
    "    train_split_ratio=0.1\n",
    ")\n",
    "split.split(data=load.data)\n",
    "print(split.data[1]['train'].shape[0])\n",
    "print(split.data[1]['validation'].shape[0])\n",
    "print(split.data[1]['train'].head(1))\n",
    "print(split.data[1]['validation'].head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor: transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0 -0.780418   0.883733  1.454353   0.901467         0.764544        0.351167   \n",
      "\n",
      "   occupation  relationship      race    gender  capital-gain  capital-loss  \\\n",
      "0    0.976728       0.00389  0.023586  0.146383     -0.150177       -0.2158   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0       -0.017024        0.492324  0.765818  \n"
     ]
    }
   ],
   "source": [
    "from PETsARD import Processor\n",
    "\n",
    "\n",
    "proc = Processor(\n",
    "    metadata=load.metadata,\n",
    ")\n",
    "proc.fit(\n",
    "    data=split.data[1]['train'],\n",
    ")\n",
    "preproc_data = proc.transform(\n",
    "    data=split.data[1]['train']\n",
    ")\n",
    "print(preproc_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal: Cont. as 0~1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing method: sdv-single_table-gaussiancopula\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0236 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 1.8214 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 2708 rows (same as raw) in 0.3409 sec.\n",
      "        age  workclass   fnlwgt  education  educational-num  marital-status  \\\n",
      "0  0.124381   0.514998 -0.65838   0.515023         1.705128        0.615378   \n",
      "\n",
      "   occupation  relationship      race    gender  capital-gain  capital-loss  \\\n",
      "0    0.840579      0.143538  0.322134  0.154478     -0.150177       -0.2158   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0          0.0683        0.710517  0.861915  \n"
     ]
    }
   ],
   "source": [
    "from PETsARD import Synthesizer\n",
    "\n",
    "\n",
    "sdv_methods = [\n",
    "    # 'sdv-single_table-copulagan',\n",
    "    # 'sdv-single_table-ctgan',\n",
    "    'sdv-single_table-gaussiancopula',\n",
    "    # 'sdv-single_table-tvae'\n",
    "]\n",
    "\n",
    "smartnoise_methods = [\n",
    "    # 'smartnoise-mwem',\n",
    "]\n",
    "# 可能由於版本限制，無法執行 aim\n",
    " # 'smartnoise-aim',\n",
    "# GAN系未支援\n",
    " # 'smartnoise-dpctgan',\n",
    " # 'smartnoise-patectgan',\n",
    " # 'smartnoise-dpgan',\n",
    " # 'smartnoise-pategan',\n",
    "\n",
    "for synthesizing_method in sdv_methods + smartnoise_methods:\n",
    "    print(f\"Synthesizing method: {synthesizing_method}\")\n",
    "    syn = Synthesizer(\n",
    "        method=synthesizing_method,\n",
    "        epsilon=10.0,\n",
    "    )\n",
    "    syn.create(data=preproc_data)\n",
    "    syn.fit_sample()\n",
    "    print(syn.data_syn.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical\n",
    "for mst, pacsynth in smartnoise\n",
    "\n",
    "`ValueError: The transformer appears to have some continuous columns. Please provide only categorical or ordinal.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc_cate = Processor(\n",
    "#     metadata=loader.metadata,\n",
    "# )\n",
    "\n",
    "# metadata_col = loader.metadata.metadata['col']\n",
    "# colnames_discrete = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "# proc_cate.update_config(\n",
    "#     {'encoder': {col: 'encoder_label' if col in colnames_discrete else None for col in metadata_col},\n",
    "#      'scaler': {col: None for col in metadata_col},\n",
    "#      }\n",
    "# )\n",
    "\n",
    "# proc_cate.fit(\n",
    "#     data=splitter.data[1]['train'],\n",
    "#     sequence=None\n",
    "# )\n",
    "# preproc_data_cate = proc_cate.transform(\n",
    "#     data=splitter.data[1]['train']\n",
    "# )\n",
    "# print(preproc_data_cate.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smartnoise_methods_cate = [\n",
    "#     'smartnoise-mst',\n",
    "#     'smartnoise-pacsynth',\n",
    "# ]\n",
    "\n",
    "# for col in preproc_data_cate.columns:\n",
    "#     preproc_data_cate[col] = preproc_data_cate[col].astype('category')\n",
    "\n",
    "# for synthesizing_method in smartnoise_methods_cate:\n",
    "#     print(f\"Synthesizing method: {synthesizing_method}\")\n",
    "#     synthesizer_cate = PETsARD.Synthesizer(\n",
    "#         data=preproc_data_cate,\n",
    "#         synthesizing_method=synthesizing_method,\n",
    "#         epsilon=1.0,\n",
    "#     )\n",
    "#     synthesizer_cate.fit_sample()\n",
    "#     print(synthesizer_cate.data_syn.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor: inverse_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age workclass         fnlwgt     education  educational-num  \\\n",
      "0  40.257969   Private  119697.654351  Some-college        14.405845   \n",
      "\n",
      "  marital-status        occupation relationship   race gender  capital-gain  \\\n",
      "0  Never-married  Transport-moving      Husband  White   Male  1.136868e-13   \n",
      "\n",
      "   capital-loss  hours-per-week native-country income  \n",
      "0           0.0       41.055941  United-States   >50K  \n"
     ]
    }
   ],
   "source": [
    "postproc_data = proc.inverse_transform(\n",
    "    data=syn.data_syn\n",
    ")\n",
    "print(postproc_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\anonymeter\\stats\\confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.32880988624667346, baseline = 0.32880988624667346. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risk</th>\n",
       "      <th>risk_CI_btm</th>\n",
       "      <th>risk_CI_top</th>\n",
       "      <th>attack_rate</th>\n",
       "      <th>attack_rate_err</th>\n",
       "      <th>baseline_rate</th>\n",
       "      <th>baseline_rate_err</th>\n",
       "      <th>control_rate</th>\n",
       "      <th>control_rate_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69281</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  \\\n",
       "result   0.0          0.0      0.69281      0.32881          0.32881   \n",
       "\n",
       "        baseline_rate  baseline_rate_err  control_rate  control_rate_err  \n",
       "result        0.32881            0.32881       0.32881           0.32881  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PETsARD import Evaluator\n",
    "\n",
    "\n",
    "eval = Evaluator(\n",
    "    method='anonymeter-singlingout_univariate',\n",
    "    n_attacks=2 # 2000\n",
    ")\n",
    "eval.create(\n",
    "    data={\n",
    "        'ori': split.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': split.data[1]['validation']\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.get_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\anonymeter\\stats\\confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.32880988624667346, baseline = 0.32880988624667346. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risk</th>\n",
       "      <th>risk_CI_btm</th>\n",
       "      <th>risk_CI_top</th>\n",
       "      <th>attack_rate</th>\n",
       "      <th>attack_rate_err</th>\n",
       "      <th>baseline_rate</th>\n",
       "      <th>baseline_rate_err</th>\n",
       "      <th>control_rate</th>\n",
       "      <th>control_rate_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69281</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  \\\n",
       "result   0.0          0.0      0.69281      0.32881          0.32881   \n",
       "\n",
       "        baseline_rate  baseline_rate_err  control_rate  control_rate_err  \n",
       "result        0.32881            0.32881       0.32881           0.32881  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    method='anonymeter-linkability',\n",
    "    n_attacks=2, # 2000,\n",
    "    n_neighbors=10,\n",
    "    aux_cols=[\n",
    "        ['age', 'fnlwgt', 'race', 'gender', 'native-country'],\n",
    "        ['workclass', 'education', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    ]\n",
    ")\n",
    "eval.create(\n",
    "    data={\n",
    "        'ori': split.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': split.data[1]['validation']\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.get_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\anonymeter\\stats\\confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.32880988624667346, baseline = 0.32880988624667346. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risk</th>\n",
       "      <th>risk_CI_btm</th>\n",
       "      <th>risk_CI_top</th>\n",
       "      <th>attack_rate</th>\n",
       "      <th>attack_rate_err</th>\n",
       "      <th>baseline_rate</th>\n",
       "      <th>baseline_rate_err</th>\n",
       "      <th>control_rate</th>\n",
       "      <th>control_rate_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69281</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  \\\n",
       "result   0.0          0.0      0.69281      0.32881          0.32881   \n",
       "\n",
       "        baseline_rate  baseline_rate_err  control_rate  control_rate_err  \n",
       "result        0.32881            0.32881       0.32881           0.32881  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    method='anonymeter-inference',\n",
    "    n_attacks=2, #2000,\n",
    "    secret='age'\n",
    ")\n",
    "eval.create(\n",
    "    data={\n",
    "        'ori': split.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': split.data[1]['validation']\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.get_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: :   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 63.06it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:02<00:00, 38.04it/s]\n",
      "\n",
      "Overall Score: 74.44%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 87.95%\n",
      "- Column Pair Trends: 60.93%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Column Shapes</th>\n",
       "      <th>Column Pair Trends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.744405</td>\n",
       "      <td>0.879508</td>\n",
       "      <td>0.609302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Score  Column Shapes  Column Pair Trends\n",
       "result  0.744405       0.879508            0.609302"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    method='sdmetrics-single_table-qualityreport',\n",
    ")\n",
    "eval.create(\n",
    "    data={\n",
    "        'ori': split.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.get_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|██████████| 15/15 [00:00<00:00, 646.26it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|██████████| 1/1 [00:00<00:00, 174.82it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Data Validity</th>\n",
       "      <th>Data Structure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score  Data Validity  Data Structure\n",
       "result    1.0            1.0             1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    method='sdmetrics-single_table-diagnosticreport',\n",
    ")\n",
    "eval.create(\n",
    "    data={\n",
    "        'ori': split.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.get_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>col_count</th>\n",
       "      <th>na_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4884</td>\n",
       "      <td>15</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_count  col_count  na_count\n",
       "0       4884         15       369"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PETsARD import Describer\n",
    "\n",
    "desc = PETsARD.Describer(\n",
    "    config={'method': 'default'},\n",
    ")\n",
    "desc.create(\n",
    "    data={\n",
    "        'data': split.data[1]['train'],\n",
    "    }\n",
    ")\n",
    "desc.eval()\n",
    "desc.get_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global':    row_count  col_count  na_count\n",
       " 0       4884         15       369,\n",
       " 'columnwise':                           mean    median            std      min        max  \\\n",
       " age                  38.572891      37.0      13.549109     17.0       90.0   \n",
       " fnlwgt           187399.196970  177120.5  102840.990508  19793.0  1455435.0   \n",
       " educational-num      10.044431      10.0       2.558085      1.0       16.0   \n",
       " capital-gain        883.443284       0.0    5883.267006      0.0    99999.0   \n",
       " capital-loss         87.815930       0.0     406.972818      0.0     4356.0   \n",
       " hours-per-week       40.210688      40.0      12.376924      1.0       99.0   \n",
       " workclass                  NaN       NaN            NaN      NaN        NaN   \n",
       " education                  NaN       NaN            NaN      NaN        NaN   \n",
       " marital-status             NaN       NaN            NaN      NaN        NaN   \n",
       " occupation                 NaN       NaN            NaN      NaN        NaN   \n",
       " relationship               NaN       NaN            NaN      NaN        NaN   \n",
       " race                       NaN       NaN            NaN      NaN        NaN   \n",
       " gender                     NaN       NaN            NaN      NaN        NaN   \n",
       " native-country             NaN       NaN            NaN      NaN        NaN   \n",
       " income                     NaN       NaN            NaN      NaN        NaN   \n",
       " \n",
       "                    kurtosis       skew        q1         q3  na_count  nunique  \n",
       " age               -0.178965   0.560403      28.0      48.00         0      NaN  \n",
       " fnlwgt             7.502092   1.477560  116601.0  234700.75         0      NaN  \n",
       " educational-num    0.513784  -0.279693       9.0      12.00         0      NaN  \n",
       " capital-gain     229.391240  14.111253       0.0       0.00         0      NaN  \n",
       " capital-loss      21.242718   4.645728       0.0       0.00         0      NaN  \n",
       " hours-per-week     3.043167   0.201892      40.0      45.00         0      NaN  \n",
       " workclass               NaN        NaN       NaN        NaN       288      8.0  \n",
       " education               NaN        NaN       NaN        NaN         0     16.0  \n",
       " marital-status          NaN        NaN       NaN        NaN         0      7.0  \n",
       " occupation              NaN        NaN       NaN        NaN       289     14.0  \n",
       " relationship            NaN        NaN       NaN        NaN         0      6.0  \n",
       " race                    NaN        NaN       NaN        NaN         0      5.0  \n",
       " gender                  NaN        NaN       NaN        NaN         0      2.0  \n",
       " native-country          NaN        NaN       NaN        NaN        83     39.0  \n",
       " income                  NaN        NaN       NaN        NaN         0      2.0  ,\n",
       " 'pairwise':                                      corr\n",
       " age             age              1.000000\n",
       " fnlwgt          age             -0.081350\n",
       " educational-num age              0.019272\n",
       " capital-gain    age              0.080164\n",
       " capital-loss    age              0.058298\n",
       " hours-per-week  age              0.065291\n",
       " fnlwgt          fnlwgt           1.000000\n",
       " educational-num fnlwgt          -0.028311\n",
       " capital-gain    fnlwgt           0.001275\n",
       " capital-loss    fnlwgt          -0.017446\n",
       " hours-per-week  fnlwgt          -0.018517\n",
       " educational-num educational-num  1.000000\n",
       " capital-gain    educational-num  0.134103\n",
       " capital-loss    educational-num  0.078068\n",
       " hours-per-week  educational-num  0.128306\n",
       " capital-gain    capital-gain     1.000000\n",
       " capital-loss    capital-gain    -0.032408\n",
       " hours-per-week  capital-gain     0.075328\n",
       " capital-loss    capital-loss     1.000000\n",
       " hours-per-week  capital-loss     0.059843\n",
       "                 hours-per-week   1.000000}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PETsARD.operator import DescriberOperator\n",
    "\n",
    "desc = DescriberOperator(\n",
    "    config={'method': 'default'},\n",
    ")\n",
    "desc.run(input={'data': {'data': split.data[1]['train']}})\n",
    "desc.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "path_petsard = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(path_petsard)\n",
    "sys.path.append(path_petsard)\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\anonymeter\\stats\\confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.32880988624667346, baseline = 0.32880988624667346. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    }
   ],
   "source": [
    "from PETsARD import Loader, Evaluator\n",
    "\n",
    "\n",
    "load_ori = Loader(filepath='../ori.csv')\n",
    "load_syn = Loader(filepath='../syn.csv')\n",
    "load_control = Loader(filepath='../control.csv')\n",
    "\n",
    "load_ori.load()\n",
    "load_syn.load()\n",
    "load_control.load()\n",
    "\n",
    "eval_data = {\n",
    "    'ori': load_ori.data,\n",
    "    'syn': load_syn.data,\n",
    "    'control': load_control.data\n",
    "}\n",
    "eval = Evaluator(method='anonymeter-singlingout_univariate', n_attacks=2)\n",
    "eval.create(data=eval_data)\n",
    "eval.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Evaluator',\n",
       "  'sd-qlt_[global]'):         risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  \\\n",
       " result   0.0          0.0      0.69281      0.32881          0.32881   \n",
       " \n",
       "         baseline_rate  baseline_rate_err  control_rate  control_rate_err  \n",
       " result        0.32881            0.32881       0.32881           0.32881  ,\n",
       " ('Evaluator', 'sd-qlt_[columnwise]'): None,\n",
       " ('Evaluator', 'sd-qlt_[pairwise]'): None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_config = {\n",
    "    'method': 'save_data',\n",
    "    'output': 'test',\n",
    "    'source': ['Synthesizer', 'sd-qlt'],\n",
    "}\n",
    "report_data = {\n",
    "    ('Evaluator', 'sd-qlt_[global]'): eval.get_global(),\n",
    "    ('Evaluator', 'sd-qlt_[columnwise]'): eval.get_columnwise(),\n",
    "    ('Evaluator', 'sd-qlt_[pairwise]'): eval.get_pairwise()\n",
    "}\n",
    "report_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is test_Evaluator[sd-qlt_[global]] save to csv...\n"
     ]
    }
   ],
   "source": [
    "from PETsARD.operator import ReporterOperator\n",
    "\n",
    "rpt = ReporterOperator(config=report_config)\n",
    "rpt.run(input={'data': report_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Evaluator[sd-qlt_[global]]':         risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  \\\n",
       " result   0.0          0.0      0.69281      0.32881          0.32881   \n",
       " \n",
       "         baseline_rate  baseline_rate_err  control_rate  control_rate_err  \n",
       " result        0.32881            0.32881       0.32881           0.32881  ,\n",
       " 'Evaluator[sd-qlt_[columnwise]]': None,\n",
       " 'Evaluator[sd-qlt_[pairwise]]': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpt.reporter.reporter.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpt.reporter.reporter.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module Loader\n",
      "Loader - Benchmarker: file benchmark\\adult.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "module Splitter\n",
      "module Preprocessor\n",
      "module Synthesizer\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0161 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 9.4189 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21462 rows (same as raw) in 1.5624 sec.\n",
      "module Postprocessor\n",
      "module Evaluator\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 74.03it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:05<00:00, 18.96it/s]\n",
      "\n",
      "Overall Score: 74.2%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 90.83%\n",
      "- Column Pair Trends: 57.56%\n",
      "module Reporter\n",
      "Now is Exec_Yaml_Loader[adult]_Splitter[0.8_[2-1]]_Preprocessor[missing-drop]_Synthesizer[sdv-gaussian] save to csv...\n",
      "Now is Exec_Yaml_Loader[adult]_Splitter[0.8_[2-1]]_Preprocessor[missing-drop]_Synthesizer[sdv-gaussian]_Postprocessor[missing-drop] save to csv...\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from PETsARD import Config, Status\n",
    "\n",
    "\n",
    "filename = 'Exec_Yaml.yaml'\n",
    "\n",
    "cfg = Config(filename=filename)\n",
    "sts: Status = Status(config=cfg)\n",
    "result = {}\n",
    "\n",
    "while cfg.config.qsize() > 0:\n",
    "    ops    = cfg.config.get()\n",
    "    module = cfg.module_flow.get()\n",
    "    expt   = cfg.expt_flow.get()\n",
    "    exclude_index: list = []\n",
    "\n",
    "    print(f\"module {module}\")\n",
    "\n",
    "    ops.run(ops.set_input(status=sts))\n",
    "\n",
    "    if module == 'Reporter':\n",
    "        break\n",
    "\n",
    "    sts.put(module, expt, ops)\n",
    "\n",
    "    if module == cfg.sequence[-1]:\n",
    "        full_expt = sts.get_full_expt()\n",
    "        full_expt_str = '_'.join(\n",
    "            [f\"{module}[{expt}]\" for module, expt in full_expt.items()]\n",
    "        )\n",
    "        result[full_expt_str] = deepcopy(sts.get_result(module=module))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('Loader', 'adult'), ('Splitter', '0.8_[1|2]_[train]_[validation]'), ('Preprocessor', 'missing-drop'), ('Synthesizer', 'sdv-gaussian'), ('Postprocessor', 'missing-drop'), ('Evaluator', 'sd-qlt_[global]_[columnwise]_[pairwise]')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops.set_input(status=sts)['data'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loader': {'expt': 'adult',\n",
       "  'operator': <PETsARD.operator.LoaderOperator at 0x209715b0b80>},\n",
       " 'Splitter': {'expt': '0.8_[1|2]',\n",
       "  'operator': <PETsARD.operator.SplitterOperator at 0x209715b28f0>},\n",
       " 'Preprocessor': {'expt': 'missing-drop',\n",
       "  'operator': <PETsARD.operator.PreprocessorOperator at 0x209358725c0>},\n",
       " 'Synthesizer': {'expt': 'sdv-gaussian',\n",
       "  'operator': <PETsARD.operator.SynthesizerOperator at 0x2093593cb80>},\n",
       " 'Postprocessor': {'expt': 'missing-drop',\n",
       "  'operator': <PETsARD.operator.PostprocessorOperator at 0x20935873370>},\n",
       " 'Evaluator': {'expt': 'sd-qlt',\n",
       "  'operator': <PETsARD.operator.EvaluatorOperator at 0x209358907f0>}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Reporter': 'missing-drop'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "module_idx = sts.sequence.index('Preprocessor') + 1\n",
    "sub_sequence = sts.sequence[:module_idx]\n",
    "{\n",
    "                module: sts.status[seq_module]['expt']\n",
    "                for seq_module in sub_sequence\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Reporter': 'sd-qlt'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "module: sts.status[seq_module]['expt']\n",
    "                for seq_module in sts.sequence if seq_module in sts.status\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\operator.py:509\u001b[0m, in \u001b[0;36mReporterOperator.set_input\u001b[1;34m(self, status)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m full_expt\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m--> 509\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mstatus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m     index_dict \u001b[38;5;241m=\u001b[39m status\u001b[38;5;241m.\u001b[39mget_full_expt(module\u001b[38;5;241m=\u001b[39mmodule)\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;66;03m# if module.get_result is a dict,\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;66;03m#   add key into expt_name: expt_name[key]\u001b[39;00m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\config.py:221\u001b[0m, in \u001b[0;36mStatus.get_result\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, module: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;28mdict\u001b[39m, pd\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[0;32m    218\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m    Retrieve the result of a specific module, optionally specifying a tag.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moperator\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget_result()\n",
      "\u001b[1;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "ops.set_input(status=sts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None: 'sd-qlt'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.get_full_expt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None: 'sd-qlt'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.get_full_expt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loader': 'adult',\n",
       " 'Splitter': '0.5_[2|2]',\n",
       " 'Preprocessor': 'missing-drop',\n",
       " 'Synthesizer': 'sdv-gaussian'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.get_full_expt('Synthesizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loader[adult]_Splitter[0.5_[2|2]]_Preprocessor[missing-drop]_Synthesizer[sdv-gaussian]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Evaluator', 'sd-qlt', 'columnwise'):                       Property        Metric     Score\n",
      "age              Column Shapes  KSComplement  0.939937\n",
      "workclass        Column Shapes  TVComplement  0.993062\n",
      "fnlwgt           Column Shapes  KSComplement  0.962958\n",
      "education        Column Shapes  TVComplement  0.550583\n",
      "educational-num  Column Shapes  KSComplement  0.793711\n",
      "marital-status   Column Shapes  TVComplement  0.971827\n",
      "occupation       Column Shapes  TVComplement  0.975564\n",
      "relationship     Column Shapes  TVComplement  0.964520\n",
      "race             Column Shapes  TVComplement  0.995613\n",
      "gender           Column Shapes  TVComplement  0.993206\n",
      "capital-gain     Column Shapes  KSComplement  0.919209\n",
      "capital-loss     Column Shapes  KSComplement  0.953401\n",
      "hours-per-week   Column Shapes  KSComplement  0.684535\n",
      "native-country   Column Shapes  TVComplement  0.992433\n",
      "income           Column Shapes  TVComplement  0.990853,\n",
      " ('Evaluator', 'sd-qlt', 'global'):            Score  Column Shapes  Column Pair Trends\n",
      "result  0.745747       0.912094              0.5794,\n",
      " ('Evaluator', 'sd-qlt', 'pairwise'):                                             Property                 Metric  \\\n",
      "(age, workclass)                  Column Pair Trends  ContingencySimilarity   \n",
      "(age, fnlwgt)                     Column Pair Trends  CorrelationSimilarity   \n",
      "(age, education)                  Column Pair Trends  ContingencySimilarity   \n",
      "(age, educational-num)            Column Pair Trends  CorrelationSimilarity   \n",
      "(age, marital-status)             Column Pair Trends  ContingencySimilarity   \n",
      "...                                              ...                    ...   \n",
      "(capital-loss, native-country)    Column Pair Trends  ContingencySimilarity   \n",
      "(capital-loss, income)            Column Pair Trends  ContingencySimilarity   \n",
      "(hours-per-week, native-country)  Column Pair Trends  ContingencySimilarity   \n",
      "(hours-per-week, income)          Column Pair Trends  ContingencySimilarity   \n",
      "(native-country, income)          Column Pair Trends  ContingencySimilarity   \n",
      "\n",
      "                                     Score  Real Correlation  \\\n",
      "(age, workclass)                  0.834666               NaN   \n",
      "(age, fnlwgt)                     0.994614         -0.074121   \n",
      "(age, education)                  0.491596               NaN   \n",
      "(age, educational-num)            0.980374          0.031542   \n",
      "(age, marital-status)             0.789737               NaN   \n",
      "...                                    ...               ...   \n",
      "(capital-loss, native-country)    0.011670               NaN   \n",
      "(capital-loss, income)            0.011711               NaN   \n",
      "(hours-per-week, native-country)  0.651246               NaN   \n",
      "(hours-per-week, income)          0.634232               NaN   \n",
      "(native-country, income)          0.974619               NaN   \n",
      "\n",
      "                                  Synthetic Correlation Error  \n",
      "(age, workclass)                                    NaN  None  \n",
      "(age, fnlwgt)                                 -0.063349  None  \n",
      "(age, education)                                    NaN  None  \n",
      "(age, educational-num)                         0.070793  None  \n",
      "(age, marital-status)                               NaN  None  \n",
      "...                                                 ...   ...  \n",
      "(capital-loss, native-country)                      NaN  None  \n",
      "(capital-loss, income)                              NaN  None  \n",
      "(hours-per-week, native-country)                    NaN  None  \n",
      "(hours-per-week, income)                            NaN  None  \n",
      "(native-country, income)                            NaN  None  \n",
      "\n",
      "[105 rows x 6 columns],\n",
      " ('Splitter', '0.5_[2|2]', 'train'):        age     workclass  fnlwgt     education  educational-num  \\\n",
      "0       25       Private  226802          11th                7   \n",
      "1       38       Private   89814       HS-grad                9   \n",
      "2       28     Local-gov  336951    Assoc-acdm               12   \n",
      "3       34       Private  198693          10th                6   \n",
      "4       24       Private  369667  Some-college               10   \n",
      "...    ...           ...     ...           ...              ...   \n",
      "24416   43       Private   84661     Assoc-voc               11   \n",
      "24417   22       Private  310152  Some-college               10   \n",
      "24418   40       Private  154374       HS-grad                9   \n",
      "24419   22       Private  201490       HS-grad                9   \n",
      "24420   52  Self-emp-inc  287927       HS-grad                9   \n",
      "\n",
      "           marital-status         occupation   relationship   race  gender  \\\n",
      "0           Never-married  Machine-op-inspct      Own-child  Black    Male   \n",
      "1      Married-civ-spouse    Farming-fishing        Husband  White    Male   \n",
      "2      Married-civ-spouse    Protective-serv        Husband  White    Male   \n",
      "3           Never-married      Other-service  Not-in-family  White    Male   \n",
      "4           Never-married      Other-service      Unmarried  White  Female   \n",
      "...                   ...                ...            ...    ...     ...   \n",
      "24416  Married-civ-spouse              Sales        Husband  White    Male   \n",
      "24417       Never-married    Protective-serv  Not-in-family  White    Male   \n",
      "24418  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
      "24419       Never-married       Adm-clerical      Own-child  White    Male   \n",
      "24420  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0                 0             0              40  United-States  <=50K  \n",
      "1                 0             0              50  United-States  <=50K  \n",
      "2                 0             0              40  United-States   >50K  \n",
      "3                 0             0              30  United-States  <=50K  \n",
      "4                 0             0              40  United-States  <=50K  \n",
      "...             ...           ...             ...            ...    ...  \n",
      "24416             0             0              45  United-States  <=50K  \n",
      "24417             0             0              40  United-States  <=50K  \n",
      "24418             0             0              40  United-States   >50K  \n",
      "24419             0             0              20  United-States  <=50K  \n",
      "24420         15024             0              40  United-States   >50K  \n",
      "\n",
      "[24421 rows x 15 columns],\n",
      " ('Splitter', '0.5_[2|2]', 'validation'):        age         workclass  fnlwgt     education  educational-num  \\\n",
      "0       44           Private  160323  Some-college               10   \n",
      "1       18               NaN  103497  Some-college               10   \n",
      "2       29               NaN  227026       HS-grad                9   \n",
      "3       63  Self-emp-not-inc  104626   Prof-school               15   \n",
      "4       65           Private  184454       HS-grad                9   \n",
      "...    ...               ...     ...           ...              ...   \n",
      "24416   43  Self-emp-not-inc   27242  Some-college               10   \n",
      "24417   32           Private  116138       Masters               14   \n",
      "24418   53           Private  321865       Masters               14   \n",
      "24419   27           Private  257302    Assoc-acdm               12   \n",
      "24420   58           Private  151910       HS-grad                9   \n",
      "\n",
      "           marital-status         occupation   relationship  \\\n",
      "0      Married-civ-spouse  Machine-op-inspct        Husband   \n",
      "1           Never-married                NaN      Own-child   \n",
      "2           Never-married                NaN      Unmarried   \n",
      "3      Married-civ-spouse     Prof-specialty        Husband   \n",
      "4      Married-civ-spouse  Machine-op-inspct        Husband   \n",
      "...                   ...                ...            ...   \n",
      "24416  Married-civ-spouse       Craft-repair        Husband   \n",
      "24417       Never-married       Tech-support  Not-in-family   \n",
      "24418  Married-civ-spouse    Exec-managerial        Husband   \n",
      "24419  Married-civ-spouse       Tech-support           Wife   \n",
      "24420             Widowed       Adm-clerical      Unmarried   \n",
      "\n",
      "                     race  gender  capital-gain  capital-loss  hours-per-week  \\\n",
      "0                   Black    Male          7688             0              40   \n",
      "1                   White  Female             0             0              30   \n",
      "2                   Black    Male             0             0              40   \n",
      "3                   White    Male          3103             0              32   \n",
      "4                   White    Male          6418             0              40   \n",
      "...                   ...     ...           ...           ...             ...   \n",
      "24416               White    Male             0             0              50   \n",
      "24417  Asian-Pac-Islander    Male             0             0              11   \n",
      "24418               White    Male             0             0              40   \n",
      "24419               White  Female             0             0              38   \n",
      "24420               White  Female             0             0              40   \n",
      "\n",
      "      native-country income  \n",
      "0      United-States   >50K  \n",
      "1      United-States  <=50K  \n",
      "2      United-States  <=50K  \n",
      "3      United-States   >50K  \n",
      "4      United-States   >50K  \n",
      "...              ...    ...  \n",
      "24416  United-States  <=50K  \n",
      "24417         Taiwan  <=50K  \n",
      "24418  United-States   >50K  \n",
      "24419  United-States  <=50K  \n",
      "24420  United-States  <=50K  \n",
      "\n",
      "[24421 rows x 15 columns]}\n"
     ]
    }
   ],
   "source": [
    "full_expt = sts.get_full_expt()\n",
    "sequence = sts.sequence\n",
    "\n",
    "input = {}\n",
    "for module, expt in full_expt.items():\n",
    "    result = sts.get_result(module=module)\n",
    "    if isinstance(result, dict):\n",
    "        for key, value in result.items():\n",
    "            index = (module, expt, key)\n",
    "            input[index] = deepcopy(value)\n",
    "    else:\n",
    "        index = (module, expt)\n",
    "        input[index] = deepcopy(result)\n",
    "\n",
    "\n",
    "source = ['Synthesizer', 'Evaluator', 'missing-drop']\n",
    "\n",
    "pp.pprint(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PETsARD import Reporter\n",
    "\n",
    "\n",
    "rpt = Reporter(\n",
    "    method='save_report'\n",
    ")\n",
    "rpt.create(data=eval.get_global())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from PETsARD.report import Reporter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Test: Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader - Benchmarker: file benchmark\\adult.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "Executor - Loader: adult loading time: 7.0139 sec.\n",
      "Executor - Splitter: 0.8 splitting time: 0.0689 sec.\n",
      "No self-defined config passed.  Generate a config automatically.\n",
      "Executor - Processor (preprocessing): drop-IQR-stanard-label processing time: 0.4141 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0469 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 7.8931 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21557 rows (same as raw) in 1.2511 sec.\n",
      "Executor - Synthesizer: GaussianCopula synthesizing time: 9.1911 sec.\n",
      "Executor - Processor (postprocessing): drop-IQR-stanard-label processing time: 0.0288 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.045 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n",
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 4.9866 sec.\n",
      "No self-defined config passed.  Generate a config automatically.\n",
      "Executor - Processor (preprocessing): drop-IQR-stanard-label processing time: 0.3603 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0228 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 7.7783 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21541 rows (same as raw) in 1.4599 sec.\n",
      "Executor - Synthesizer: GaussianCopula synthesizing time: 9.2625 sec.\n",
      "Executor - Processor (postprocessing): drop-IQR-stanard-label processing time: 0.0338 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0419 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n",
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 4.6758 sec.\n",
      "====== ====== ====== ====== ====== ======\n",
      "Executor (run - single process): Total execution time: 38.4373 sec.\n",
      "====== ====== ====== ====== ====== ======\n",
      "{'Attack_Rate': 0.3967253428113813,\n",
      " 'Attack_Rate_err': 0.3967253428113813,\n",
      " 'Baseline_Rate': 0.3967253428113813,\n",
      " 'Baseline_Rate_err': 0.3967253428113813,\n",
      " 'Control_Rate': 0.3967253428113813,\n",
      " 'Control_Rate_err': 0.3967253428113813,\n",
      " 'Risk': 0.0,\n",
      " 'Risk_CI_btm': 0.0,\n",
      " 'Risk_CI_top': 0.9300148011448004}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "\n",
    "para_Executor = {\n",
    "    'Loader': {\n",
    "        'adult': {\n",
    "            'filepath': 'benchmark://adult',\n",
    "            'na_values': {k: '?' for k in [\n",
    "                'workclass',\n",
    "                'occupation',\n",
    "                'native-country'\n",
    "            ]}\n",
    "        }\n",
    "    },\n",
    "    'Splitter': {\n",
    "        '0.8': {\n",
    "            'num_samples': 2,\n",
    "            'train_split_ratio': 0.8,\n",
    "        }\n",
    "    },\n",
    "    'Processor': {\n",
    "        'drop-IQR-stanard-label': {\n",
    "            'missing': {\n",
    "                'method': 'missing_drop',\n",
    "                'all': True\n",
    "            },\n",
    "            #'method': , # ValueError: y contains previously unseen labels:\n",
    "            'encoder': [\n",
    "                {'method': 'encoder_label',\n",
    "                 'include': ['education','marital-status','relationship','gender']\n",
    "                },\n",
    "                {'method': 'encoder_uniform',\n",
    "                 'include': ['workclass', 'occupation', 'race', 'native-country', 'income']\n",
    "                }\n",
    "            ],\n",
    "            'outlier': {\n",
    "                'method': 'outlier_iqr',\n",
    "                'include': 'hours-per-week'\n",
    "            },\n",
    "            'scaler': {\n",
    "                'method': 'scaler_standard',\n",
    "                'exclude': ['hours-per-week',\n",
    "                    'workclass', 'education', 'marital-status',\n",
    "                    'occupation', 'relationship', 'race', 'gender',\n",
    "                    'native-country', 'income'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'Synthesizer': {\n",
    "        'GaussianCopula': {\n",
    "            'synthesizing_method': 'sdv-singletable-gaussiancopula'\n",
    "        }\n",
    "    },\n",
    "    'Evaluator': {\n",
    "        'anonymeter-SinglingOut': {\n",
    "            'evaluating_method': 'anonymeter-singlingout-univariate',\n",
    "            'anonymeter_n_attacks': 1,  # 2000'\n",
    "            'anonymeter_num_samples': 2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "executor_single = PETsARD.Executor(**para_Executor)\n",
    "executor_single.run()\n",
    "pprint(\n",
    "    executor_single.evaluator[(\n",
    "        'adult',\n",
    "        '0.8',\n",
    "        1,\n",
    "        'drop-IQR-stanard-label',\n",
    "        'GaussianCopula',\n",
    "        'anonymeter-SinglingOut',\n",
    "        1\n",
    "    )].Evaluator.evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .run_parallel()\n",
    "Not applicable now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|          | 0/1 [00:20<?, ?it/s]s/it]\n",
      "Splitting: 100%|██████████| 1/1 [00:20<00:00, 20.74s/it]\n",
      "Loading: 100%|██████████| 1/1 [00:20<00:00, 20.74s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'Processor.__init__.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\process.py\", line 211, in _sendback_result\n    result_queue.put(_ResultItem(work_id, result=result,\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py\", line 371, in put\n    obj = _ForkingPickler.dumps(obj)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nAttributeError: Can't pickle local object 'Processor.__init__.<locals>.<lambda>'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 73\u001b[0m\n\u001b[0;32m     11\u001b[0m para_Executor \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoader\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     }\n\u001b[0;32m     69\u001b[0m }\n\u001b[0;32m     72\u001b[0m executor_parallel \u001b[38;5;241m=\u001b[39m PETsARD\u001b[38;5;241m.\u001b[39mExecutor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpara_Executor)\n\u001b[1;32m---> 73\u001b[0m \u001b[43mexecutor_parallel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m pprint(\n\u001b[0;32m     75\u001b[0m     executor_parallel\u001b[38;5;241m.\u001b[39mevaluator[(\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m     )]\u001b[38;5;241m.\u001b[39mEvaluator\u001b[38;5;241m.\u001b[39mevaluation\n\u001b[0;32m     84\u001b[0m )\n",
      "File \u001b[1;32mD:\\Dropbox\\89_其他應用\\GitHub\\PETsARD\\PETsARD\\Executor.py:541\u001b[0m, in \u001b[0;36mExecutor.run_parallel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    539\u001b[0m trials_till_proc \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proc_future \u001b[38;5;129;01min\u001b[39;00m as_completed(proc_futures):\n\u001b[1;32m--> 541\u001b[0m     proc_result \u001b[38;5;241m=\u001b[39m \u001b[43mproc_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m     proc_name \u001b[38;5;241m=\u001b[39m proc_futures[proc_future][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor[proc_name] \u001b[38;5;241m=\u001b[39m proc_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'Processor.__init__.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD')\n",
    "os.chdir('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD\\\\demo')\n",
    "\n",
    "import PETsARD\n",
    "\n",
    "\n",
    "para_Executor = {\n",
    "    'Loader': {\n",
    "        'adult': {\n",
    "            'filepath': 'benchmark://adult',\n",
    "            'na_values': {k: '?' for k in [\n",
    "                'workclass',\n",
    "                'occupation',\n",
    "                'native-country'\n",
    "            ]}\n",
    "        }\n",
    "    },\n",
    "    'Splitter': {\n",
    "        '0.8': {\n",
    "            'num_samples': 2,\n",
    "            'train_split_ratio': 0.8,\n",
    "        }\n",
    "    },\n",
    "    'Processor': {\n",
    "        'drop-IQR-stanard-label': {\n",
    "            'missingist': {\n",
    "                'method': 'missingist_drop',\n",
    "                'all': True\n",
    "            },\n",
    "            #'method': , # ValueError: y contains previously unseen labels:\n",
    "            'encoder': [\n",
    "                {'method': 'encoder_label',\n",
    "                 'include': ['education','marital-status','relationship','gender']\n",
    "                },\n",
    "                {'method': 'encoder_uniform',\n",
    "                 'include': ['workclass', 'occupation', 'race', 'native-country', 'income']\n",
    "                }\n",
    "            ],\n",
    "            'outlierist': {\n",
    "                'method': 'outlierist_iqr',\n",
    "                'include': 'hours-per-week'\n",
    "            },\n",
    "            'scaler': {\n",
    "                'method': 'scaler_standard',\n",
    "                'exclude': ['hours-per-week',\n",
    "                    'workclass', 'education', 'marital-status',\n",
    "                    'occupation', 'relationship', 'race', 'gender',\n",
    "                    'native-country', 'income'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'Synthesizer': {\n",
    "        'GaussianCopula': {\n",
    "            'synthesizing_method': 'sdv-singletable-gaussiancopula'\n",
    "        }\n",
    "    },\n",
    "    'Evaluator': {\n",
    "        'anonymeter-SinglingOut': {\n",
    "            'evaluating_method': 'anonymeter-singlingout-univariate',\n",
    "            'anonymeter_n_attacks': 1,  # 2000'\n",
    "            'anonymeter_num_samples': 2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Processor contains lambda function, but python couldn't pickle it.\n",
    "# so Processor .run_parallel() didn't valid after Processor migration.\n",
    "executor_parallel = PETsARD.Executor(**para_Executor)\n",
    "executor_parallel.run_parallel()\n",
    "pprint(\n",
    "    executor_parallel.evaluator[(\n",
    "        'adult',\n",
    "        '0.8',\n",
    "        1,\n",
    "        'drop-IQR-stanard-label',\n",
    "        'GaussianCopula',\n",
    "        'anonymeter-SinglingOut',\n",
    "        1\n",
    "    )].Evaluator.evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un arrangment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Result(__evaluator):\n",
    "    import numpy as np\n",
    "    __dict_result = {}\n",
    "    __para_to_handle = [('Risk', ['risk()', 'value']), ('Risk_CI_btm', ['risk()', 'ci[0]']), ('Risk_CI_top', ['risk()', 'ci[1]']), ('Attack_Rate', ['results()', 'attack_rate', 'value']), ('Attack_Rate_err', ['results()', 'attack_rate', 'error']), ('Baseline_Rate', ['results()', 'baseline_rate', 'value']), ('Baseline_Rate_err', ['results()', 'baseline_rate', 'error']), ('Control_Rate', ['results()', 'control_rate', 'value']), ('Control_Rate_err', ['results()', 'control_rate', 'error'])\n",
    "                        ]\n",
    "    for __key, __attrs in __para_to_handle:\n",
    "        try:\n",
    "            __attr_value = __evaluator\n",
    "            for __attr in __attrs:\n",
    "                if '()' in __attr:\n",
    "                    __method_name = __attr.split('(')[0]\n",
    "                    if hasattr(__attr_value, __method_name):\n",
    "                        __method = getattr(__attr_value, __method_name)\n",
    "                        if callable(__method):\n",
    "                            __attr_value = __method()\n",
    "                        else:\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                elif '[' in __attr:\n",
    "                    __attr_name = __attr.split('[')[0]\n",
    "                    __index = int(__attr.split('[')[1].rstrip(']'))\n",
    "                    if hasattr(__attr_value, __attr_name)\\\n",
    "                            and isinstance(getattr(__attr_value, __attr_name), (list, dict, tuple)):\n",
    "                        try:\n",
    "                            __attr_value = getattr(\n",
    "                                __attr_value, __attr_name)[__index]\n",
    "                        except (IndexError, KeyError):\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                else:\n",
    "                    __attr_value = getattr(__attr_value, __attr)\n",
    "            __dict_result[__key] = __attr_value\n",
    "        except Exception as e:\n",
    "            __dict_result[__key] = np.nan\n",
    "    return __dict_result\n",
    "\n",
    "\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    from anonymeter.evaluators import SinglingOutEvaluator\n",
    "    print(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\")\n",
    "    evaluator = SinglingOutEvaluator(ori=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), syn=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), control=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\"), n_attacks=2000\n",
    "                                     )\n",
    "    try:\n",
    "        evaluator.evaluate(mode='univariate')\n",
    "        print(Result(evaluator))\n",
    "    except RuntimeError as ex:\n",
    "        print(f\"Singling out evaluation failed with {ex}.\"\n",
    "              \"Please re-run this cell.\"\n",
    "              \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "              \"make the evaluation slower.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "for type in ['][Ori]', '][Ctrl]', '-1-1]Postproc']:\n",
    "    for combo in itertools.combinations(['01', '02', '03', '04', '05', '06'], 2):\n",
    "        df_a = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[0]}{type}.csv\")\n",
    "        df_b = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[1]}{type}.csv\")\n",
    "        if df_a.equals(df_b):\n",
    "            print(type+': '+str(combo))\n",
    "            print(\"They're same!!??\")\n",
    "        # else:\n",
    "            # print(type+': '+str(combo))\n",
    "            # print(\"They're different.\")\n",
    "print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Loader: adult loading time: 6.8097 sec.\n",
      "Executor - Splitter: 0.8 splitting time: 0.339 sec.\n",
      "Preprocessor - Outlierist (IQR): Dropped  1060 rows on fnlwgt         . Kept [-63981.5, 419234.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   227 rows on educational-num. Kept [3.0, 19.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  1705 rows on capital-loss   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  9432 rows on hours-per-week . Kept [32.5, 52.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   214 rows on age            . Kept [-0.5, 75.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  3030 rows on capital-gain   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Totally Dropped 13932 in 36207 rows.\n",
      "Preprocessor - Encoder (Label): Column native-country  been labelized from 0 to 39.\n",
      "Preprocessor - Encoder (Label): Column gender          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column race            been labelized from 0 to  4.\n",
      "Preprocessor - Encoder (Label): Column relationship    been labelized from 0 to  5.\n",
      "Preprocessor - Encoder (Label): Column education       been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column income          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column workclass       been labelized from 0 to  6.\n",
      "Preprocessor - Encoder (Label): Column occupation      been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column marital-status  been labelized from 0 to  6.\n",
      "Executor - Preprocessor: drop-IQR-stanard-NA preprocessing time: 0.0764 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.021 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula spent 12.1284 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCoupula # 22275 rows (same as raw) in 1.313 sec.\n",
      "Executor - Synthesizer: GaussianCoupula synthesizing time: 13.466 sec.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding native-country.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding gender.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding race.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding relationship.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding education.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding income.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding workclass.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding occupation.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding marital-status.\n",
      "Executor - Postprocessor: postprocessing time: 0.0142 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0404 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 765 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 131.365 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0322 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 802 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 2 trials evaluating time: 131.1331 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0336 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 830 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 3 trials evaluating time: 131.5346 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0356 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 794 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 4 trials evaluating time: 131.4821 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0351 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 821 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 5 trials evaluating time: 132.587 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.036 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 800 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 6 trials evaluating time: 131.8783 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0352 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 799 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Result(__evaluator):\n",
    "    import numpy as np\n",
    "    __dict_result = {}\n",
    "    __para_to_handle = [('Risk', ['risk()', 'value']), ('Risk_CI_btm', ['risk()', 'ci[0]']), ('Risk_CI_top', ['risk()', 'ci[1]']), ('Attack_Rate', ['results()', 'attack_rate', 'value']), ('Attack_Rate_err', ['results()', 'attack_rate', 'error']), ('Baseline_Rate', ['results()', 'baseline_rate', 'value']), ('Baseline_Rate_err', ['results()', 'baseline_rate', 'error']), ('Control_Rate', ['results()', 'control_rate', 'value']), ('Control_Rate_err', ['results()', 'control_rate', 'error'])\n",
    "                        ]\n",
    "    for __key, __attrs in __para_to_handle:\n",
    "        try:\n",
    "            __attr_value = __evaluator\n",
    "            for __attr in __attrs:\n",
    "                if '()' in __attr:\n",
    "                    __method_name = __attr.split('(')[0]\n",
    "                    if hasattr(__attr_value, __method_name):\n",
    "                        __method = getattr(__attr_value, __method_name)\n",
    "                        if callable(__method):\n",
    "                            __attr_value = __method()\n",
    "                        else:\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                elif '[' in __attr:\n",
    "                    __attr_name = __attr.split('[')[0]\n",
    "                    __index = int(__attr.split('[')[1].rstrip(']'))\n",
    "                    if hasattr(__attr_value, __attr_name)\\\n",
    "                            and isinstance(getattr(__attr_value, __attr_name), (list, dict, tuple)):\n",
    "                        try:\n",
    "                            __attr_value = getattr(\n",
    "                                __attr_value, __attr_name)[__index]\n",
    "                        except (IndexError, KeyError):\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                else:\n",
    "                    __attr_value = getattr(__attr_value, __attr)\n",
    "            __dict_result[__key] = __attr_value\n",
    "        except Exception as e:\n",
    "            __dict_result[__key] = np.nan\n",
    "    return __dict_result\n",
    "\n",
    "\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    from anonymeter.evaluators import SinglingOutEvaluator\n",
    "    print(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\")\n",
    "    evaluator = SinglingOutEvaluator(ori=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), syn=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), control=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\"), n_attacks=2000\n",
    "                                     )\n",
    "    try:\n",
    "        evaluator.evaluate(mode='univariate')\n",
    "        print(Result(evaluator))\n",
    "    except RuntimeError as ex:\n",
    "        print(f\"Singling out evaluation failed with {ex}.\"\n",
    "              \"Please re-run this cell.\"\n",
    "              \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "              \"make the evaluation slower.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    eval = PETsARD.Evaluator(evaluating_method='anonymeter-singlingout-univariate', data={'ori': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), 'syn': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), 'control': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\")\n",
    "                                                                                          }, anonymeter_n_attacks=500\n",
    "                             )\n",
    "    eval.eval()\n",
    "    print(eval.Evaluator.evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 7 trials evaluating time: 131.5421 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0354 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for type in ['][Ori]', '][Ctrl]', '-1-1]Postproc']:\n",
    "    for combo in itertools.combinations(['01', '02', '03', '04', '05', '06'], 2):\n",
    "        df_a = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[0]}{type}.csv\")\n",
    "        df_b = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[1]}{type}.csv\")\n",
    "        if df_a.equals(df_b):\n",
    "            print(type+': '+str(combo))\n",
    "            print(\"They're same!!??\")\n",
    "        # else:\n",
    "            # print(type+': '+str(combo))\n",
    "            # print(\"They're different.\")\n",
    "print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'Loader': {\n",
    "        'NHANES': {\n",
    "            'filepath': '../[sunset]/data/[NHANES] B.csv',\n",
    "            'header_exist': False,\n",
    "            'header_names': ['gen', 'age', 'race', 'edu', 'mar', 'bmi', 'dep', 'pir', 'gh', 'mets', 'qm', 'dia']\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
