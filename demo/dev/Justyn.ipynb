{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\demo\\dev\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "\n",
    "path_cwd = os.getcwd()\n",
    "print(path_cwd)\n",
    "path_petsard = os.path.dirname(os.path.dirname(path_cwd))\n",
    "print(path_petsard)\n",
    "sys.path.append(path_petsard)\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader - Benchmarker : Success download the benchmark dataset from https://petsard-benchmark.s3.amazonaws.com/ma2018.csv.\n",
      "Raw data (Loader) # rn = (7244, 24)\n",
      "Split data (Splitter) # rn = (5795, 24)\n",
      "Preproc data (Processor) # rn = (3394, 24)\n",
      "Synthesizer (SDV): Fitting GaussianCopula.\n",
      "Synthesizer (SDV): Fitting GaussianCopula spent 6.2944 sec.\n",
      "Synthesizer (SDV): Sampling GaussianCopula # 5795 rows (same as Splitter data) in 0.9261 sec.\n",
      "Syn data (Synthesizer) by Preproc data w/ Preproc Metadata # rn = (5795, 24)\n",
      "Postproc data (Processor) # rn = (5795, 24)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Describer' object has no attribute 'create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPostproc data (Processor) # rn = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpostproc_data\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m desc \u001b[38;5;241m=\u001b[39m Describer(config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescribe\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_na_count\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[1;32m---> 36\u001b[0m \u001b[43mdesc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m(data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: postproc_data})\n\u001b[0;32m     37\u001b[0m desc\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Describer' object has no attribute 'create'"
     ]
    }
   ],
   "source": [
    "from PETsARD import (\n",
    "    Loader,\n",
    "    Splitter,\n",
    "    Processor,\n",
    "    Synthesizer,\n",
    "    Describer,\n",
    ")\n",
    "from PETsARD.util import safe_round\n",
    "\n",
    "\n",
    "load = Loader(\n",
    "    filepath='benchmark://nist-ma2018',\n",
    "    na_values='N',\n",
    ")\n",
    "load.load()\n",
    "print(f\"Raw data (Loader) # rn = {load.data.shape}\")\n",
    "\n",
    "split = Splitter(train_split_ratio=0.8, random_state=42)\n",
    "split.split(data=load.data, metadata=load.metadata)\n",
    "print(f\"Split data (Splitter) # rn = {split.data[1]['train'].shape}\")\n",
    "\n",
    "proc = Processor(metadata=split.metadata)\n",
    "proc.fit(data=split.data[1]['train'])\n",
    "preproc_data = proc.transform(data=split.data[1]['train'])\n",
    "print(f\"Preproc data (Processor) # rn = {preproc_data.shape}\")\n",
    "\n",
    "syn = Synthesizer(method='default')\n",
    "syn.create(data=preproc_data, metadata=proc._metadata)\n",
    "syn.fit_sample()\n",
    "print(f\"Syn data (Synthesizer) by Preproc data w/ Preproc Metadata # rn = {syn.data_syn.shape}\")\n",
    "\n",
    "postproc_data = proc.inverse_transform(data=syn.data_syn)\n",
    "print(f\"Postproc data (Processor) # rn = {postproc_data.shape}\")\n",
    "\n",
    "desc = Describer(config={'method': 'custom', 'describe': ['global_na_count']})\n",
    "desc.create(data={'data': postproc_data})\n",
    "desc.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from PETsARD import Executor\n",
    "\n",
    "\n",
    "yaml_text: str = \"\"\"---\n",
    "Loader:\n",
    "    default:\n",
    "        method: default\n",
    "Splitter:\n",
    "    p0.8:\n",
    "        train_split_ratio: 0.8\n",
    "Preprocessor:\n",
    "    default:\n",
    "        method: default\n",
    "Synthesizer:\n",
    "    default:\n",
    "        method: default\n",
    "Postprocessor:\n",
    "    default:\n",
    "        method: default\n",
    "Evaluator:\n",
    "    stats:\n",
    "        method: stats\n",
    "    anony-singling:\n",
    "        method: anonymeter-singlingout\n",
    "        n_attacks: 10\n",
    "    anony-link:\n",
    "        method: anonymeter-linkability\n",
    "        n_attacks: 10\n",
    "        aux_cols:\n",
    "            - - age\n",
    "            - - race\n",
    "    anony-infer:\n",
    "        method: anonymeter-inference\n",
    "        n_attacks: 10\n",
    "        secret: age\n",
    "    mlutility-classification:\n",
    "        method: mlutility-regression\n",
    "        target: age\n",
    "    mlutility-cluster:\n",
    "        method: mlutility-cluster\n",
    "    mlutility-regression:\n",
    "        method: mlutility-regression\n",
    "        target: age\n",
    "Reporter:\n",
    "    save_report:\n",
    "        method: save_report\n",
    "        granularity: global\n",
    "        output: temp_eval\n",
    "...\"\"\"\n",
    "\n",
    "# pp.pprint(yaml_text)\n",
    "\n",
    "cfg = yaml.safe_load(yaml_text)\n",
    "pp.pprint(cfg)\n",
    "\n",
    "yaml_file: str = f'temp_eval.yaml'\n",
    "with open(yaml_file, 'w') as f:\n",
    "    f.write(yaml_text)\n",
    "\n",
    "exec = Executor(config=yaml_file)\n",
    "exec.run()\n",
    "\n",
    "os.remove(yaml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Test: import PETsARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PETsARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Test: Module-by-Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader - Benchmarker: file benchmark\\adult.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "   age workclass  fnlwgt education  educational-num marital-status  \\\n",
      "0   25   Private  226802      11th                7  Never-married   \n",
      "\n",
      "          occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Machine-op-inspct    Own-child  Black   Male             0             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              40  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "from PETsARD import Loader\n",
    "\n",
    "\n",
    "load = Loader(\n",
    "    filepath='benchmark://adult',\n",
    "    na_values={k: '?' for k in [\n",
    "        'workclass',\n",
    "        'occupation',\n",
    "        'native-country'\n",
    "    ]}\n",
    ")\n",
    "load.load()\n",
    "print(load.data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col': {'age': {...},\n",
      "         'capital-gain': {...},\n",
      "         'capital-loss': {...},\n",
      "         'education': {...},\n",
      "         'educational-num': {...},\n",
      "         'fnlwgt': {...},\n",
      "         'gender': {...},\n",
      "         'hours-per-week': {...},\n",
      "         'income': {...},\n",
      "         'marital-status': {...},\n",
      "         'native-country': {...},\n",
      "         'occupation': {...},\n",
      "         'race': {...},\n",
      "         'relationship': {...},\n",
      "         'workclass': {...}},\n",
      " 'global': {'col_num': 15,\n",
      "            'na_percentage': 0.07411653904426518,\n",
      "            'row_num': 48842}}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(load.metadata.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4884\n",
      "43958\n",
      "   age workclass  fnlwgt education  educational-num      marital-status  \\\n",
      "0   48   Private  279724   HS-grad                9  Married-civ-spouse   \n",
      "\n",
      "          occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Machine-op-inspct      Husband  White   Male          3103             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              48  United-States   >50K  \n",
      "   age workclass  fnlwgt education  educational-num marital-status  \\\n",
      "0   25   Private  226802      11th                7  Never-married   \n",
      "\n",
      "          occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Machine-op-inspct    Own-child  Black   Male             0             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              40  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "from PETsARD import Splitter\n",
    "\n",
    "\n",
    "split = Splitter(\n",
    "    num_samples=30,\n",
    "    train_split_ratio=0.1\n",
    ")\n",
    "split.split(data=load.data)\n",
    "print(split.data[1]['train'].shape[0])\n",
    "print(split.data[1]['validation'].shape[0])\n",
    "print(split.data[1]['train'].head(1))\n",
    "print(split.data[1]['validation'].head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor: transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PETsARD import Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal - for SDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0 -0.327236   0.524368  0.469244   0.330675        -0.028052        0.469522   \n",
      "\n",
      "   occupation  relationship      race   gender  capital-gain  capital-loss  \\\n",
      "0    0.674606      0.762601  0.860857  0.93286     -0.147893     -0.231477   \n",
      "\n",
      "   hours-per-week  native-country   income  \n",
      "0       -0.424355        0.634371  0.56599  \n"
     ]
    }
   ],
   "source": [
    "proc = Processor(\n",
    "    metadata=load.metadata,\n",
    ")\n",
    "proc.fit(\n",
    "    data=split.data[1]['train'],\n",
    ")\n",
    "preproc_data = proc.transform(\n",
    "    data=split.data[1]['train']\n",
    ")\n",
    "print(preproc_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretizing - for SmartNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0  0.0          3     0.0         15              0.0               4   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0           7             3     2       0           0.0           0.0   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0             0.0              35       0  \n"
     ]
    }
   ],
   "source": [
    "proc_discretizing = Processor(\n",
    "    metadata=load.metadata,\n",
    ")\n",
    "proc_discretizing.fit(\n",
    "    data=split.data[1]['train'],\n",
    "    sequence=[\n",
    "        'missing',\n",
    "        'outlier',\n",
    "        'scaler',\n",
    "        'discretizing'\n",
    "    ]\n",
    ")\n",
    "preproc_discretizing_data = proc_discretizing.transform(\n",
    "    data=split.data[1]['train']\n",
    ")\n",
    "print(preproc_discretizing_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PETsARD import Synthesizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal - for SDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing method: sdv-single_table-copulagan\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.123 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting CopulaGAN.\n",
      "Synthesizer (SDV - SingleTable): Fitting  CopulaGAN spent 199.4804 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling CopulaGAN # 2643 rows (same as raw) in 0.9981 sec.\n",
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0 -1.056908   0.012349 -1.128603   0.270852          0.02078        0.001947   \n",
      "\n",
      "   occupation  relationship      race    gender  capital-gain  capital-loss  \\\n",
      "0    0.432105      0.544103  0.447702  0.270797     -0.147893     -0.231477   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0       -0.039528        0.923296  0.839931  \n",
      "Synthesizing method: sdv-single_table-ctgan\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0336 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting CTGAN.\n",
      "Synthesizer (SDV - SingleTable): Fitting  CTGAN spent 145.9321 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling CTGAN # 2643 rows (same as raw) in 0.3086 sec.\n",
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0 -0.408121   0.307495 -0.721871   0.188372         1.141136         0.06782   \n",
      "\n",
      "   occupation  relationship     race    gender  capital-gain  capital-loss  \\\n",
      "0    0.255583      0.700959  0.84903  0.962119     -0.147893     -0.231477   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0       -0.010666        0.475191  0.999798  \n",
      "Synthesizing method: sdv-single_table-gaussiancopula\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0172 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 2.0016 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 2643 rows (same as raw) in 0.3178 sec.\n",
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0  1.569424    0.32833 -0.577706   0.524281          1.97408        0.265126   \n",
      "\n",
      "   occupation  relationship      race    gender  capital-gain  capital-loss  \\\n",
      "0    0.426243      0.340534  0.318979  0.469878     -0.147893     -0.231477   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0        0.167677        0.556317  0.417283  \n",
      "Synthesizing method: sdv-single_table-tvae\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0173 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting TVAE.\n",
      "Synthesizer (SDV - SingleTable): Fitting  TVAE spent 69.4564 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.47354771 -0.15692338 -0.2666682  ...  0.01381046  0.31199011\n",
      "  0.18086678]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.14446778  0.04980333  0.18927578 ...  0.01388443 -0.25316479\n",
      " -0.00742286]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.08707042 -0.18812113 -0.16607611 ... -0.00837583 -0.41367255\n",
      " -0.15436004]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.04667318  0.16324879 -0.45100723 ... -0.14740025 -0.0363695\n",
      " -0.46130144]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.01236667  0.00624882 -0.00884074 ... -0.02175978  0.01963441\n",
      "  0.0072603 ]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.06569877  0.29643492  0.07795528 ... -0.30075862  0.30579127\n",
      " -0.18823824]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.21203084 -0.24778889  0.28437911 ... -0.31455424 -0.52395587\n",
      " -0.29736268]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.32759766  0.05155033  0.01633515 ... -0.12423823 -0.28763242\n",
      "  0.32296557]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.37805336 -0.0539582  -0.1582798  ... -0.62544595 -0.00949151\n",
      " -0.16366007]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.13984735 -0.07397268 -0.31499222 ...  0.34689447  0.16609879\n",
      " -0.20436868]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.00482864 -0.00106662  0.0179062  ...  0.00893329 -0.01145447\n",
      "  0.01401906]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 8.93471399e-03 -7.29684013e-05 -1.06148631e-02 ...  1.61365597e-04\n",
      "  1.14039022e-02  7.51375113e-03]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.18243902 -0.01141475  0.16120299 ...  0.17890461 -0.12030171\n",
      " -0.14025288]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.0344336   0.18862524  0.09029313 ... -0.16641122  0.18343334\n",
      " -0.31491735]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\ctgan\\data_transformer.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.03592544  0.00501373 -0.0552274  ... -0.1242557  -0.19422145\n",
      " -0.29228422]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  data.iloc[:, 0] = selected_normalized_value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizer (SDV - SingleTable): Sampling TVAE # 2643 rows (same as raw) in 0.6674 sec.\n",
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0 -0.067829   0.076006 -0.114669   0.095181        -0.420508        0.087769   \n",
      "\n",
      "   occupation  relationship      race    gender  capital-gain  capital-loss  \\\n",
      "0    0.811419      0.013165  0.529466  0.276131     -0.147893     -0.231477   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0       -0.020715        0.286213  0.706544  \n"
     ]
    }
   ],
   "source": [
    "sdv_methods = [\n",
    "    'sdv-single_table-copulagan',\n",
    "    'sdv-single_table-ctgan',\n",
    "    'sdv-single_table-gaussiancopula',\n",
    "    'sdv-single_table-tvae'\n",
    "]\n",
    "\n",
    "for synthesizing_method in sdv_methods:\n",
    "    print(f\"Synthesizing method: {synthesizing_method}\")\n",
    "    syn = Synthesizer(\n",
    "        method=synthesizing_method,\n",
    "        epsilon=10.0,\n",
    "    )\n",
    "    syn.create(data=preproc_data)\n",
    "    syn.fit_sample()\n",
    "    print(syn.data_syn.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "smartnoise_methods = [\n",
    "]\n",
    "\n",
    "# See Issue332.ipynb\n",
    "#\n",
    "# 'smartnoise-aim',\n",
    "#     可能由於版本限制，無法執行 aim\n",
    "# 'smartnoise-mwem',\n",
    "#     MemoryError: Unable to allocate 4.32 TiB for an array with shape (594261577728,) and data type int64\n",
    "# 'smartnoise-mst',\n",
    "#     Please install mbi with:\n",
    "#        pip install git+https://github.com/ryan112358/private-pgm.git\n",
    "# 'smartnoise-pacsynth',\n",
    "#     ValueError: The transformer appears to have some continuous columns. Please provide only categorical or ordinal.\n",
    "#\n",
    "# GAN系未支援\n",
    "#     'smartnoise-dpctgan',\n",
    "#     'smartnoise-patectgan',\n",
    "#     'smartnoise-dpgan',\n",
    "#     'smartnoise-pategan',\n",
    "\n",
    "for synthesizing_method in smartnoise_methods:\n",
    "    print(f\"Synthesizing method: {synthesizing_method}\")\n",
    "    syn_smartnoise = Synthesizer(\n",
    "        method=synthesizing_method,\n",
    "        epsilon=10.0,\n",
    "    )\n",
    "    syn_smartnoise.create(data=preproc_discretizing_data)\n",
    "    syn_smartnoise.fit_sample()\n",
    "    print(syn_smartnoise.data_syn.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module Loader\n",
      "Loader - Benchmarker: file benchmark\\adult.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "module Splitter\n",
      "module Preprocessor\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from PETsARD import Config, Status\n",
    "\n",
    "\n",
    "filename = 'Exec_Yaml.yaml'\n",
    "cfg = Config(filename=filename)\n",
    "sts: Status = Status(config=cfg)\n",
    "result = {}\n",
    "\n",
    "while cfg.config.qsize() > 0:\n",
    "    ops    = cfg.config.get()\n",
    "    module = cfg.module_flow.get()\n",
    "    expt   = cfg.expt_flow.get()\n",
    "    exclude_index: list = []\n",
    "\n",
    "    print(f\"module {module}\")\n",
    "\n",
    "    if module == 'Preprocessor':\n",
    "        break\n",
    "\n",
    "    ops.run(ops.set_input(status=sts))\n",
    "\n",
    "    sts.put(module, expt, ops)\n",
    "\n",
    "\n",
    "    if module == cfg.sequence[-1]:\n",
    "        full_expt = sts.get_full_expt()\n",
    "        full_expt_str = '_'.join(\n",
    "            [f\"{module}[{expt}]\" for module, expt in full_expt.items()]\n",
    "        )\n",
    "        result[full_expt_str] = deepcopy(sts.get_result(module=module))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.config.config.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data':        age         workclass  fnlwgt     education  educational-num  \\\n",
       " 0       25           Private  226802          11th                7   \n",
       " 1       28         Local-gov  336951    Assoc-acdm               12   \n",
       " 2       18               NaN  103497  Some-college               10   \n",
       " 3       29               NaN  227026       HS-grad                9   \n",
       " 4       63  Self-emp-not-inc  104626   Prof-school               15   \n",
       " ...    ...               ...     ...           ...              ...   \n",
       " 39068   27           Private  257302    Assoc-acdm               12   \n",
       " 39069   40           Private  154374       HS-grad                9   \n",
       " 39070   58           Private  151910       HS-grad                9   \n",
       " 39071   22           Private  201490       HS-grad                9   \n",
       " 39072   52      Self-emp-inc  287927       HS-grad                9   \n",
       " \n",
       "            marital-status         occupation relationship   race  gender  \\\n",
       " 0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
       " 1      Married-civ-spouse    Protective-serv      Husband  White    Male   \n",
       " 2           Never-married                NaN    Own-child  White  Female   \n",
       " 3           Never-married                NaN    Unmarried  Black    Male   \n",
       " 4      Married-civ-spouse     Prof-specialty      Husband  White    Male   \n",
       " ...                   ...                ...          ...    ...     ...   \n",
       " 39068  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
       " 39069  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
       " 39070             Widowed       Adm-clerical    Unmarried  White  Female   \n",
       " 39071       Never-married       Adm-clerical    Own-child  White    Male   \n",
       " 39072  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
       " \n",
       "        capital-gain  capital-loss  hours-per-week native-country income  \n",
       " 0                 0             0              40  United-States  <=50K  \n",
       " 1                 0             0              40  United-States   >50K  \n",
       " 2                 0             0              30  United-States  <=50K  \n",
       " 3                 0             0              40  United-States  <=50K  \n",
       " 4              3103             0              32  United-States   >50K  \n",
       " ...             ...           ...             ...            ...    ...  \n",
       " 39068             0             0              38  United-States  <=50K  \n",
       " 39069             0             0              40  United-States   >50K  \n",
       " 39070             0             0              40  United-States  <=50K  \n",
       " 39071             0             0              20  United-States  <=50K  \n",
       " 39072         15024             0              40  United-States   >50K  \n",
       " \n",
       " [39073 rows x 15 columns],\n",
       " 'metadata': <PETsARD.loader.metadata.Metadata at 0x15f723c5750>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops.set_input(status=sts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretizing - for SmartNoise\n",
    "for mst, pacsynth in smartnoise\n",
    "\n",
    "`ValueError: The transformer appears to have some continuous columns. Please provide only categorical or ordinal.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0   34          3  238588         15               10               4   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0           7             3     2       0             0             0   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0              35              35       0  \n"
     ]
    }
   ],
   "source": [
    "proc_cate = Processor(\n",
    "    metadata=load.metadata,\n",
    ")\n",
    "\n",
    "metadata_col = load.metadata.metadata['col']\n",
    "colnames_discrete = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "proc_cate.update_config(\n",
    "    {'encoder': {col: 'encoder_label' if col in colnames_discrete else None for col in metadata_col},\n",
    "     'scaler': {col: None for col in metadata_col},\n",
    "     }\n",
    ")\n",
    "\n",
    "proc_cate.fit(\n",
    "    data=split.data[1]['train'],\n",
    "    sequence=None\n",
    ")\n",
    "preproc_data_cate = proc_cate.transform(\n",
    "    data=split.data[1]['train']\n",
    ")\n",
    "print(preproc_data_cate.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing method: smartnoise-mst\n",
      "Please install mbi with:\n",
      "   pip install git+https://github.com/ryan112358/private-pgm.git\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'disjoint_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSynthesizing method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msynthesizing_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m synthesizer_cate \u001b[38;5;241m=\u001b[39m PETsARD\u001b[38;5;241m.\u001b[39mSynthesizer(\n\u001b[0;32m     12\u001b[0m     method\u001b[38;5;241m=\u001b[39msynthesizing_method,\n\u001b[0;32m     13\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m \u001b[43msynthesizer_cate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreproc_data_cate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m synthesizer_cate\u001b[38;5;241m.\u001b[39mfit_sample()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(synthesizer_cate\u001b[38;5;241m.\u001b[39mdata_syn\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\synthesizer\\synthesizer.py:84\u001b[0m, in \u001b[0;36mSynthesizer.create\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSynthesizer \u001b[38;5;241m=\u001b[39m SDVFactory(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m SynthesizerMap\u001b[38;5;241m.\u001b[39mSMARTNOISE:\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSynthesizer \u001b[38;5;241m=\u001b[39m SmartNoiseFactory(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedMethodError\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\synthesizer\\smartnoise.py:151\u001b[0m, in \u001b[0;36mSmartNoiseFactory.__init__\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m epsilon: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m5.0\u001b[39m)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmartnoise-\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSynthesizer \u001b[38;5;241m=\u001b[39m \u001b[43mSmartNoiseCreator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedMethodError\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\synthesizer\\smartnoise.py:185\u001b[0m, in \u001b[0;36mSmartNoiseCreator.__init__\u001b[1;34m(self, data, method, epsilon, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn_method: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m method\n\u001b[1;32m--> 185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Synthesizer \u001b[38;5;241m=\u001b[39m \u001b[43mSNSyn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\base.py:214\u001b[0m, in \u001b[0;36mSynthesizer.create\u001b[1;34m(cls, synth, epsilon, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m synth_class \u001b[38;5;241m=\u001b[39m synth_map[synth][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    213\u001b[0m synth_module, synth_class \u001b[38;5;241m=\u001b[39m synth_class\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 214\u001b[0m synth_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msynth_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfromlist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msynth_class\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m synth_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(synth_module, synth_class)\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m synth_class(epsilon\u001b[38;5;241m=\u001b[39mepsilon, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmst\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSTSynthesizer\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSTSynthesizer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install mbi with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   pip install git+https://github.com/ryan112358/private-pgm.git\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdisjoint_set\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DisjointSet\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'disjoint_set'"
     ]
    }
   ],
   "source": [
    "smartnoise_methods_cate = [\n",
    "]\n",
    "\n",
    "for col in preproc_data_cate.columns:\n",
    "    preproc_data_cate[col] = preproc_data_cate[col].astype('category')\n",
    "\n",
    "for synthesizing_method in smartnoise_methods_cate:\n",
    "    print(f\"Synthesizing method: {synthesizing_method}\")\n",
    "    synthesizer_cate = PETsARD.Synthesizer(\n",
    "        method=synthesizing_method,\n",
    "        epsilon=1.0,\n",
    "    )\n",
    "    synthesizer_cate.create(data=preproc_data_cate)\n",
    "    synthesizer_cate.fit_sample()\n",
    "    print(synthesizer_cate.data_syn.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor: inverse_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age workclass         fnlwgt     education  educational-num  \\\n",
      "0  40.257969   Private  119697.654351  Some-college        14.405845   \n",
      "\n",
      "  marital-status        occupation relationship   race gender  capital-gain  \\\n",
      "0  Never-married  Transport-moving      Husband  White   Male  1.136868e-13   \n",
      "\n",
      "   capital-loss  hours-per-week native-country income  \n",
      "0           0.0       41.055941  United-States   >50K  \n"
     ]
    }
   ],
   "source": [
    "postproc_data = proc.inverse_transform(\n",
    "    data=syn.data_syn\n",
    ")\n",
    "print(postproc_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\anonymeter\\stats\\confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.32880988624667346, baseline = 0.32880988624667346. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risk</th>\n",
       "      <th>risk_CI_btm</th>\n",
       "      <th>risk_CI_top</th>\n",
       "      <th>attack_rate</th>\n",
       "      <th>attack_rate_err</th>\n",
       "      <th>baseline_rate</th>\n",
       "      <th>baseline_rate_err</th>\n",
       "      <th>control_rate</th>\n",
       "      <th>control_rate_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69281</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  \\\n",
       "result   0.0          0.0      0.69281      0.32881          0.32881   \n",
       "\n",
       "        baseline_rate  baseline_rate_err  control_rate  control_rate_err  \n",
       "result        0.32881            0.32881       0.32881           0.32881  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PETsARD import Evaluator\n",
    "\n",
    "\n",
    "eval = Evaluator(\n",
    "    method='anonymeter-singlingout_univariate',\n",
    "    n_attacks=2 # 2000\n",
    ")\n",
    "eval.create(\n",
    "    data={\n",
    "        'ori': split.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': split.data[1]['validation']\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.get_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\anonymeter\\stats\\confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.32880988624667346, baseline = 0.32880988624667346. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risk</th>\n",
       "      <th>risk_CI_btm</th>\n",
       "      <th>risk_CI_top</th>\n",
       "      <th>attack_rate</th>\n",
       "      <th>attack_rate_err</th>\n",
       "      <th>baseline_rate</th>\n",
       "      <th>baseline_rate_err</th>\n",
       "      <th>control_rate</th>\n",
       "      <th>control_rate_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69281</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  \\\n",
       "result   0.0          0.0      0.69281      0.32881          0.32881   \n",
       "\n",
       "        baseline_rate  baseline_rate_err  control_rate  control_rate_err  \n",
       "result        0.32881            0.32881       0.32881           0.32881  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    method='anonymeter-linkability',\n",
    "    n_attacks=2, # 2000,\n",
    "    n_neighbors=10,\n",
    "    aux_cols=[\n",
    "        ['age', 'fnlwgt', 'race', 'gender', 'native-country'],\n",
    "        ['workclass', 'education', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    ]\n",
    ")\n",
    "eval.create(\n",
    "    data={\n",
    "        'ori': split.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': split.data[1]['validation']\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.get_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\anonymeter\\stats\\confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.32880988624667346, baseline = 0.32880988624667346. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risk</th>\n",
       "      <th>risk_CI_btm</th>\n",
       "      <th>risk_CI_top</th>\n",
       "      <th>attack_rate</th>\n",
       "      <th>attack_rate_err</th>\n",
       "      <th>baseline_rate</th>\n",
       "      <th>baseline_rate_err</th>\n",
       "      <th>control_rate</th>\n",
       "      <th>control_rate_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69281</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "      <td>0.32881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  \\\n",
       "result   0.0          0.0      0.69281      0.32881          0.32881   \n",
       "\n",
       "        baseline_rate  baseline_rate_err  control_rate  control_rate_err  \n",
       "result        0.32881            0.32881       0.32881           0.32881  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    method='anonymeter-inference',\n",
    "    n_attacks=2, #2000,\n",
    "    secret='age'\n",
    ")\n",
    "eval.create(\n",
    "    data={\n",
    "        'ori': split.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': split.data[1]['validation']\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.get_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: :   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 63.06it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:02<00:00, 38.04it/s]\n",
      "\n",
      "Overall Score: 74.44%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 87.95%\n",
      "- Column Pair Trends: 60.93%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Column Shapes</th>\n",
       "      <th>Column Pair Trends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.744405</td>\n",
       "      <td>0.879508</td>\n",
       "      <td>0.609302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Score  Column Shapes  Column Pair Trends\n",
       "result  0.744405       0.879508            0.609302"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    method='sdmetrics-single_table-qualityreport',\n",
    ")\n",
    "eval.create(\n",
    "    data={\n",
    "        'ori': split.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.get_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|██████████| 15/15 [00:00<00:00, 646.26it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|██████████| 1/1 [00:00<00:00, 174.82it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Data Validity</th>\n",
       "      <th>Data Structure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score  Data Validity  Data Structure\n",
       "result    1.0            1.0             1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    method='sdmetrics-single_table-diagnosticreport',\n",
    ")\n",
    "eval.create(\n",
    "    data={\n",
    "        'ori': split.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.get_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>col_count</th>\n",
       "      <th>na_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4884</td>\n",
       "      <td>15</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_count  col_count  na_count\n",
       "0       4884         15       369"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PETsARD import Describer\n",
    "\n",
    "desc = PETsARD.Describer(\n",
    "    config={'method': 'default'},\n",
    ")\n",
    "desc.create(\n",
    "    data={\n",
    "        'data': split.data[1]['train'],\n",
    "    }\n",
    ")\n",
    "desc.eval()\n",
    "desc.get_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global':    row_count  col_count  na_count\n",
       " 0       4884         15       369,\n",
       " 'columnwise':                           mean    median            std      min        max  \\\n",
       " age                  38.572891      37.0      13.549109     17.0       90.0   \n",
       " fnlwgt           187399.196970  177120.5  102840.990508  19793.0  1455435.0   \n",
       " educational-num      10.044431      10.0       2.558085      1.0       16.0   \n",
       " capital-gain        883.443284       0.0    5883.267006      0.0    99999.0   \n",
       " capital-loss         87.815930       0.0     406.972818      0.0     4356.0   \n",
       " hours-per-week       40.210688      40.0      12.376924      1.0       99.0   \n",
       " workclass                  NaN       NaN            NaN      NaN        NaN   \n",
       " education                  NaN       NaN            NaN      NaN        NaN   \n",
       " marital-status             NaN       NaN            NaN      NaN        NaN   \n",
       " occupation                 NaN       NaN            NaN      NaN        NaN   \n",
       " relationship               NaN       NaN            NaN      NaN        NaN   \n",
       " race                       NaN       NaN            NaN      NaN        NaN   \n",
       " gender                     NaN       NaN            NaN      NaN        NaN   \n",
       " native-country             NaN       NaN            NaN      NaN        NaN   \n",
       " income                     NaN       NaN            NaN      NaN        NaN   \n",
       " \n",
       "                    kurtosis       skew        q1         q3  na_count  nunique  \n",
       " age               -0.178965   0.560403      28.0      48.00         0      NaN  \n",
       " fnlwgt             7.502092   1.477560  116601.0  234700.75         0      NaN  \n",
       " educational-num    0.513784  -0.279693       9.0      12.00         0      NaN  \n",
       " capital-gain     229.391240  14.111253       0.0       0.00         0      NaN  \n",
       " capital-loss      21.242718   4.645728       0.0       0.00         0      NaN  \n",
       " hours-per-week     3.043167   0.201892      40.0      45.00         0      NaN  \n",
       " workclass               NaN        NaN       NaN        NaN       288      8.0  \n",
       " education               NaN        NaN       NaN        NaN         0     16.0  \n",
       " marital-status          NaN        NaN       NaN        NaN         0      7.0  \n",
       " occupation              NaN        NaN       NaN        NaN       289     14.0  \n",
       " relationship            NaN        NaN       NaN        NaN         0      6.0  \n",
       " race                    NaN        NaN       NaN        NaN         0      5.0  \n",
       " gender                  NaN        NaN       NaN        NaN         0      2.0  \n",
       " native-country          NaN        NaN       NaN        NaN        83     39.0  \n",
       " income                  NaN        NaN       NaN        NaN         0      2.0  ,\n",
       " 'pairwise':                                      corr\n",
       " age             age              1.000000\n",
       " fnlwgt          age             -0.081350\n",
       " educational-num age              0.019272\n",
       " capital-gain    age              0.080164\n",
       " capital-loss    age              0.058298\n",
       " hours-per-week  age              0.065291\n",
       " fnlwgt          fnlwgt           1.000000\n",
       " educational-num fnlwgt          -0.028311\n",
       " capital-gain    fnlwgt           0.001275\n",
       " capital-loss    fnlwgt          -0.017446\n",
       " hours-per-week  fnlwgt          -0.018517\n",
       " educational-num educational-num  1.000000\n",
       " capital-gain    educational-num  0.134103\n",
       " capital-loss    educational-num  0.078068\n",
       " hours-per-week  educational-num  0.128306\n",
       " capital-gain    capital-gain     1.000000\n",
       " capital-loss    capital-gain    -0.032408\n",
       " hours-per-week  capital-gain     0.075328\n",
       " capital-loss    capital-loss     1.000000\n",
       " hours-per-week  capital-loss     0.059843\n",
       "                 hours-per-week   1.000000}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PETsARD.operator import DescriberOperator\n",
    "\n",
    "desc = DescriberOperator(\n",
    "    config={'method': 'default'},\n",
    ")\n",
    "desc.run(input={'data': {'data': split.data[1]['train']}})\n",
    "desc.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "path_petsard = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(path_petsard)\n",
    "sys.path.append(path_petsard)\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\anonymeter\\stats\\confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.32880988624667346, baseline = 0.32880988624667346. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    }
   ],
   "source": [
    "from PETsARD import Loader, Evaluator\n",
    "\n",
    "\n",
    "load_ori = Loader(filepath='../ori.csv')\n",
    "load_syn = Loader(filepath='../syn.csv')\n",
    "load_control = Loader(filepath='../control.csv')\n",
    "\n",
    "load_ori.load()\n",
    "load_syn.load()\n",
    "load_control.load()\n",
    "\n",
    "eval_data = {\n",
    "    'ori': load_ori.data,\n",
    "    'syn': load_syn.data,\n",
    "    'control': load_control.data\n",
    "}\n",
    "eval = Evaluator(method='anonymeter-singlingout_univariate', n_attacks=2)\n",
    "eval.create(data=eval_data)\n",
    "eval.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Evaluator',\n",
       "  'sd-qlt_[global]'):         risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  \\\n",
       " result   0.0          0.0      0.69281      0.32881          0.32881   \n",
       " \n",
       "         baseline_rate  baseline_rate_err  control_rate  control_rate_err  \n",
       " result        0.32881            0.32881       0.32881           0.32881  ,\n",
       " ('Evaluator', 'sd-qlt_[columnwise]'): None,\n",
       " ('Evaluator', 'sd-qlt_[pairwise]'): None,\n",
       " 'exist_report': {}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_data = {\n",
    "    ('Evaluator', 'sd-qlt_[global]'): eval.get_global(),\n",
    "    ('Evaluator', 'sd-qlt_[columnwise]'): eval.get_columnwise(),\n",
    "    ('Evaluator', 'sd-qlt_[pairwise]'): eval.get_pairwise()\n",
    "}\n",
    "\n",
    "report_config = {\n",
    "    'method': 'save_report',\n",
    "    'output': 'DevTest',\n",
    "    'granularity': 'global',\n",
    "    'eval': 'sd-qlt'\n",
    "}\n",
    "exist_report = {}\n",
    "report_data['exist_report'] = exist_report\n",
    "\n",
    "report_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  \\\n",
      "result   0.0          0.0      0.69281      0.32881          0.32881   \n",
      "\n",
      "        baseline_rate  baseline_rate_err  control_rate  control_rate_err  \n",
      "result        0.32881            0.32881       0.32881           0.32881  \n",
      "Now is DevTest[Report]_sd-qlt_[global] save to csv...\n"
     ]
    }
   ],
   "source": [
    "from PETsARD.operator import ReporterOperator\n",
    "\n",
    "rpt = ReporterOperator(config=report_config)\n",
    "rpt.run(input={'data': report_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  \\\n",
      "result   0.0          0.0      0.69281      0.32881          0.32881   \n",
      "\n",
      "        baseline_rate  baseline_rate_err  control_rate  control_rate_err  \n",
      "result        0.32881            0.32881       0.32881           0.32881  \n",
      "Now is DevTest[Report]_sd-qlt_[global] save to csv...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Reporter': {'full_expt_name': 'Evaluator[sd-qlt_[global]]',\n",
       "  'eval_expt_name': 'sd-qlt_[global]',\n",
       "  'expt_name': 'sd-qlt',\n",
       "  'granularity': 'global',\n",
       "  'report':         risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  \\\n",
       "  result   0.0          0.0      0.69281      0.32881          0.32881   \n",
       "  \n",
       "          baseline_rate  baseline_rate_err  control_rate  control_rate_err  \n",
       "  result        0.32881            0.32881       0.32881           0.32881  }}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PETsARD.reporter.reporter import ReporterSaveReport\n",
    "\n",
    "\n",
    "rpt = ReporterSaveReport(config=report_config)\n",
    "rpt.create(data=report_data)\n",
    "rpt.report()\n",
    "rpt.report_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module Loader\n",
      "Loader - Benchmarker: file benchmark\\adult.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "module Splitter\n",
      "module Preprocessor\n",
      "module Synthesizer\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.025 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 9.1393 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21478 rows (same as raw) in 1.4834 sec.\n",
      "module Postprocessor\n",
      "module Evaluator\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 62.63it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:04<00:00, 22.76it/s]\n",
      "\n",
      "Overall Score: 74.16%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 90.78%\n",
      "- Column Pair Trends: 57.54%\n",
      "module Reporter\n",
      "Now is Exec_Yaml_Loader[adult]_Splitter[0.8_[2-1]]_Preprocessor[missing-drop]_Synthesizer[sdv-gaussian] save to csv...\n",
      "Now is Exec_Yaml_Loader[adult]_Splitter[0.8_[2-1]]_Preprocessor[missing-drop]_Synthesizer[sdv-gaussian]_Postprocessor[missing-drop] save to csv...\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from PETsARD import Config, Status\n",
    "\n",
    "\n",
    "filename = 'Exec_Yaml.yaml'\n",
    "\n",
    "cfg = Config(filename=filename)\n",
    "sts: Status = Status(config=cfg)\n",
    "result = {}\n",
    "\n",
    "while cfg.config.qsize() > 0:\n",
    "    ops    = cfg.config.get()\n",
    "    module = cfg.module_flow.get()\n",
    "    expt   = cfg.expt_flow.get()\n",
    "    exclude_index: list = []\n",
    "\n",
    "    print(f\"module {module}\")\n",
    "\n",
    "    ops.run(ops.set_input(status=sts))\n",
    "\n",
    "    sts.put(module, expt, ops)\n",
    "\n",
    "    if module == 'Reporter':\n",
    "        break\n",
    "\n",
    "    if module == cfg.sequence[-1]:\n",
    "        full_expt = sts.get_full_expt()\n",
    "        full_expt_str = '_'.join(\n",
    "            [f\"{module}[{expt}]\" for module, expt in full_expt.items()]\n",
    "        )\n",
    "        result[full_expt_str] = deepcopy(sts.get_result(module=module))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'save_report',\n",
       " 'output': 'Exec_Yaml',\n",
       " 'granularity': 'global',\n",
       " 'eval': 'sd-qlt'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops.set_input(status=sts).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\reporter\\reporter.py:101\u001b[0m, in \u001b[0;36mReporter.create\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Creates a report using the specified data.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m        data (dict): The data used for creating the report.\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreporter\u001b[38;5;241m.\u001b[39mreport_data\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\reporter\\reporter.py:358\u001b[0m, in \u001b[0;36mcreate\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    356\u001b[0m report_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_expt_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m eval_expt_name\n\u001b[0;32m    357\u001b[0m report_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpt_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m\n\u001b[1;32m--> 358\u001b[0m report_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgranularity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m granularity\n\u001b[0;32m    360\u001b[0m \u001b[38;5;66;03m# reset index to represent column\u001b[39;00m\n\u001b[0;32m    361\u001b[0m granularity_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgranularity_code\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "ops.reporter.create(data=ops.set_input(status=sts)['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\operator.py:526\u001b[0m, in \u001b[0;36mReporterOperator.run\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    520\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m    Runs the Reporter to create and generate reports.\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \n\u001b[0;32m    523\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03m        input (dict): Input data for the Reporter.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 526\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreporter\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreporter\u001b[38;5;241m.\u001b[39mreport()\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReporter\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreporter\u001b[38;5;241m.\u001b[39mreport_data:\n\u001b[0;32m    529\u001b[0m         \u001b[38;5;66;03m# ReporterSaveReport\u001b[39;00m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\reporter\\reporter.py:101\u001b[0m, in \u001b[0;36mReporter.create\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Creates a report using the specified data.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m        data (dict): The data used for creating the report.\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreporter\u001b[38;5;241m.\u001b[39mreport_data\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\reporter\\reporter.py:358\u001b[0m, in \u001b[0;36mcreate\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    356\u001b[0m report_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_expt_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m eval_expt_name\n\u001b[0;32m    357\u001b[0m report_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpt_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m\n\u001b[1;32m--> 358\u001b[0m report_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgranularity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m granularity\n\u001b[0;32m    360\u001b[0m \u001b[38;5;66;03m# reset index to represent column\u001b[39;00m\n\u001b[0;32m    361\u001b[0m granularity_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgranularity_code\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "ops.run(ops.set_input(status=sts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module Reporter\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m exclude_index: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m sts\u001b[38;5;241m.\u001b[39mput(module, expt, ops)\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\operator.py:526\u001b[0m, in \u001b[0;36mReporterOperator.run\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    520\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m    Runs the Reporter to create and generate reports.\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \n\u001b[0;32m    523\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03m        input (dict): Input data for the Reporter.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 526\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreporter\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreporter\u001b[38;5;241m.\u001b[39mreport()\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReporter\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreporter\u001b[38;5;241m.\u001b[39mreport_data:\n\u001b[0;32m    529\u001b[0m         \u001b[38;5;66;03m# ReporterSaveReport\u001b[39;00m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\reporter\\reporter.py:101\u001b[0m, in \u001b[0;36mReporter.create\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Creates a report using the specified data.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m        data (dict): The data used for creating the report.\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreporter\u001b[38;5;241m.\u001b[39mreport_data\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\reporter\\reporter.py:358\u001b[0m, in \u001b[0;36mcreate\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    356\u001b[0m report_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_expt_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m eval_expt_name\n\u001b[0;32m    357\u001b[0m report_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpt_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m\n\u001b[1;32m--> 358\u001b[0m report_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgranularity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m granularity\n\u001b[0;32m    360\u001b[0m \u001b[38;5;66;03m# reset index to represent column\u001b[39;00m\n\u001b[0;32m    361\u001b[0m granularity_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgranularity_code\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "\n",
    "ops    = cfg.config.get()\n",
    "module = cfg.module_flow.get()\n",
    "expt   = cfg.expt_flow.get()\n",
    "exclude_index: list = []\n",
    "\n",
    "print(f\"module {module}\")\n",
    "\n",
    "ops.run(ops.set_input(status=sts))\n",
    "\n",
    "sts.put(module, expt, ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None: 'sd-qlt'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.get_full_expt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Evaluator', 'sd-qlt', 'columnwise'):                       Property        Metric     Score\n",
      "age              Column Shapes  KSComplement  0.939937\n",
      "workclass        Column Shapes  TVComplement  0.993062\n",
      "fnlwgt           Column Shapes  KSComplement  0.962958\n",
      "education        Column Shapes  TVComplement  0.550583\n",
      "educational-num  Column Shapes  KSComplement  0.793711\n",
      "marital-status   Column Shapes  TVComplement  0.971827\n",
      "occupation       Column Shapes  TVComplement  0.975564\n",
      "relationship     Column Shapes  TVComplement  0.964520\n",
      "race             Column Shapes  TVComplement  0.995613\n",
      "gender           Column Shapes  TVComplement  0.993206\n",
      "capital-gain     Column Shapes  KSComplement  0.919209\n",
      "capital-loss     Column Shapes  KSComplement  0.953401\n",
      "hours-per-week   Column Shapes  KSComplement  0.684535\n",
      "native-country   Column Shapes  TVComplement  0.992433\n",
      "income           Column Shapes  TVComplement  0.990853,\n",
      " ('Evaluator', 'sd-qlt', 'global'):            Score  Column Shapes  Column Pair Trends\n",
      "result  0.745747       0.912094              0.5794,\n",
      " ('Evaluator', 'sd-qlt', 'pairwise'):                                             Property                 Metric  \\\n",
      "(age, workclass)                  Column Pair Trends  ContingencySimilarity   \n",
      "(age, fnlwgt)                     Column Pair Trends  CorrelationSimilarity   \n",
      "(age, education)                  Column Pair Trends  ContingencySimilarity   \n",
      "(age, educational-num)            Column Pair Trends  CorrelationSimilarity   \n",
      "(age, marital-status)             Column Pair Trends  ContingencySimilarity   \n",
      "...                                              ...                    ...   \n",
      "(capital-loss, native-country)    Column Pair Trends  ContingencySimilarity   \n",
      "(capital-loss, income)            Column Pair Trends  ContingencySimilarity   \n",
      "(hours-per-week, native-country)  Column Pair Trends  ContingencySimilarity   \n",
      "(hours-per-week, income)          Column Pair Trends  ContingencySimilarity   \n",
      "(native-country, income)          Column Pair Trends  ContingencySimilarity   \n",
      "\n",
      "                                     Score  Real Correlation  \\\n",
      "(age, workclass)                  0.834666               NaN   \n",
      "(age, fnlwgt)                     0.994614         -0.074121   \n",
      "(age, education)                  0.491596               NaN   \n",
      "(age, educational-num)            0.980374          0.031542   \n",
      "(age, marital-status)             0.789737               NaN   \n",
      "...                                    ...               ...   \n",
      "(capital-loss, native-country)    0.011670               NaN   \n",
      "(capital-loss, income)            0.011711               NaN   \n",
      "(hours-per-week, native-country)  0.651246               NaN   \n",
      "(hours-per-week, income)          0.634232               NaN   \n",
      "(native-country, income)          0.974619               NaN   \n",
      "\n",
      "                                  Synthetic Correlation Error  \n",
      "(age, workclass)                                    NaN  None  \n",
      "(age, fnlwgt)                                 -0.063349  None  \n",
      "(age, education)                                    NaN  None  \n",
      "(age, educational-num)                         0.070793  None  \n",
      "(age, marital-status)                               NaN  None  \n",
      "...                                                 ...   ...  \n",
      "(capital-loss, native-country)                      NaN  None  \n",
      "(capital-loss, income)                              NaN  None  \n",
      "(hours-per-week, native-country)                    NaN  None  \n",
      "(hours-per-week, income)                            NaN  None  \n",
      "(native-country, income)                            NaN  None  \n",
      "\n",
      "[105 rows x 6 columns],\n",
      " ('Splitter', '0.5_[2|2]', 'train'):        age     workclass  fnlwgt     education  educational-num  \\\n",
      "0       25       Private  226802          11th                7   \n",
      "1       38       Private   89814       HS-grad                9   \n",
      "2       28     Local-gov  336951    Assoc-acdm               12   \n",
      "3       34       Private  198693          10th                6   \n",
      "4       24       Private  369667  Some-college               10   \n",
      "...    ...           ...     ...           ...              ...   \n",
      "24416   43       Private   84661     Assoc-voc               11   \n",
      "24417   22       Private  310152  Some-college               10   \n",
      "24418   40       Private  154374       HS-grad                9   \n",
      "24419   22       Private  201490       HS-grad                9   \n",
      "24420   52  Self-emp-inc  287927       HS-grad                9   \n",
      "\n",
      "           marital-status         occupation   relationship   race  gender  \\\n",
      "0           Never-married  Machine-op-inspct      Own-child  Black    Male   \n",
      "1      Married-civ-spouse    Farming-fishing        Husband  White    Male   \n",
      "2      Married-civ-spouse    Protective-serv        Husband  White    Male   \n",
      "3           Never-married      Other-service  Not-in-family  White    Male   \n",
      "4           Never-married      Other-service      Unmarried  White  Female   \n",
      "...                   ...                ...            ...    ...     ...   \n",
      "24416  Married-civ-spouse              Sales        Husband  White    Male   \n",
      "24417       Never-married    Protective-serv  Not-in-family  White    Male   \n",
      "24418  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
      "24419       Never-married       Adm-clerical      Own-child  White    Male   \n",
      "24420  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0                 0             0              40  United-States  <=50K  \n",
      "1                 0             0              50  United-States  <=50K  \n",
      "2                 0             0              40  United-States   >50K  \n",
      "3                 0             0              30  United-States  <=50K  \n",
      "4                 0             0              40  United-States  <=50K  \n",
      "...             ...           ...             ...            ...    ...  \n",
      "24416             0             0              45  United-States  <=50K  \n",
      "24417             0             0              40  United-States  <=50K  \n",
      "24418             0             0              40  United-States   >50K  \n",
      "24419             0             0              20  United-States  <=50K  \n",
      "24420         15024             0              40  United-States   >50K  \n",
      "\n",
      "[24421 rows x 15 columns],\n",
      " ('Splitter', '0.5_[2|2]', 'validation'):        age         workclass  fnlwgt     education  educational-num  \\\n",
      "0       44           Private  160323  Some-college               10   \n",
      "1       18               NaN  103497  Some-college               10   \n",
      "2       29               NaN  227026       HS-grad                9   \n",
      "3       63  Self-emp-not-inc  104626   Prof-school               15   \n",
      "4       65           Private  184454       HS-grad                9   \n",
      "...    ...               ...     ...           ...              ...   \n",
      "24416   43  Self-emp-not-inc   27242  Some-college               10   \n",
      "24417   32           Private  116138       Masters               14   \n",
      "24418   53           Private  321865       Masters               14   \n",
      "24419   27           Private  257302    Assoc-acdm               12   \n",
      "24420   58           Private  151910       HS-grad                9   \n",
      "\n",
      "           marital-status         occupation   relationship  \\\n",
      "0      Married-civ-spouse  Machine-op-inspct        Husband   \n",
      "1           Never-married                NaN      Own-child   \n",
      "2           Never-married                NaN      Unmarried   \n",
      "3      Married-civ-spouse     Prof-specialty        Husband   \n",
      "4      Married-civ-spouse  Machine-op-inspct        Husband   \n",
      "...                   ...                ...            ...   \n",
      "24416  Married-civ-spouse       Craft-repair        Husband   \n",
      "24417       Never-married       Tech-support  Not-in-family   \n",
      "24418  Married-civ-spouse    Exec-managerial        Husband   \n",
      "24419  Married-civ-spouse       Tech-support           Wife   \n",
      "24420             Widowed       Adm-clerical      Unmarried   \n",
      "\n",
      "                     race  gender  capital-gain  capital-loss  hours-per-week  \\\n",
      "0                   Black    Male          7688             0              40   \n",
      "1                   White  Female             0             0              30   \n",
      "2                   Black    Male             0             0              40   \n",
      "3                   White    Male          3103             0              32   \n",
      "4                   White    Male          6418             0              40   \n",
      "...                   ...     ...           ...           ...             ...   \n",
      "24416               White    Male             0             0              50   \n",
      "24417  Asian-Pac-Islander    Male             0             0              11   \n",
      "24418               White    Male             0             0              40   \n",
      "24419               White  Female             0             0              38   \n",
      "24420               White  Female             0             0              40   \n",
      "\n",
      "      native-country income  \n",
      "0      United-States   >50K  \n",
      "1      United-States  <=50K  \n",
      "2      United-States  <=50K  \n",
      "3      United-States   >50K  \n",
      "4      United-States   >50K  \n",
      "...              ...    ...  \n",
      "24416  United-States  <=50K  \n",
      "24417         Taiwan  <=50K  \n",
      "24418  United-States   >50K  \n",
      "24419  United-States  <=50K  \n",
      "24420  United-States  <=50K  \n",
      "\n",
      "[24421 rows x 15 columns]}\n"
     ]
    }
   ],
   "source": [
    "full_expt = sts.get_full_expt()\n",
    "sequence = sts.sequence\n",
    "\n",
    "input = {}\n",
    "for module, expt in full_expt.items():\n",
    "    result = sts.get_result(module=module)\n",
    "    if isinstance(result, dict):\n",
    "        for key, value in result.items():\n",
    "            index = (module, expt, key)\n",
    "            input[index] = deepcopy(value)\n",
    "    else:\n",
    "        index = (module, expt)\n",
    "        input[index] = deepcopy(result)\n",
    "\n",
    "\n",
    "source = ['Synthesizer', 'Evaluator', 'missing-drop']\n",
    "\n",
    "pp.pprint(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PETsARD import Reporter\n",
    "\n",
    "\n",
    "rpt = Reporter(\n",
    "    method='save_report'\n",
    ")\n",
    "rpt.create(data=eval.get_global())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from PETsARD.report import Reporter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Test: Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader - Benchmarker: file benchmark\\adult.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "Executor - Loader: adult loading time: 7.0139 sec.\n",
      "Executor - Splitter: 0.8 splitting time: 0.0689 sec.\n",
      "No self-defined config passed.  Generate a config automatically.\n",
      "Executor - Processor (preprocessing): drop-IQR-stanard-label processing time: 0.4141 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0469 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 7.8931 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21557 rows (same as raw) in 1.2511 sec.\n",
      "Executor - Synthesizer: GaussianCopula synthesizing time: 9.1911 sec.\n",
      "Executor - Processor (postprocessing): drop-IQR-stanard-label processing time: 0.0288 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.045 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n",
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 4.9866 sec.\n",
      "No self-defined config passed.  Generate a config automatically.\n",
      "Executor - Processor (preprocessing): drop-IQR-stanard-label processing time: 0.3603 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0228 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 7.7783 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21541 rows (same as raw) in 1.4599 sec.\n",
      "Executor - Synthesizer: GaussianCopula synthesizing time: 9.2625 sec.\n",
      "Executor - Processor (postprocessing): drop-IQR-stanard-label processing time: 0.0338 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0419 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n",
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 4.6758 sec.\n",
      "====== ====== ====== ====== ====== ======\n",
      "Executor (run - single process): Total execution time: 38.4373 sec.\n",
      "====== ====== ====== ====== ====== ======\n",
      "{'Attack_Rate': 0.3967253428113813,\n",
      " 'Attack_Rate_err': 0.3967253428113813,\n",
      " 'Baseline_Rate': 0.3967253428113813,\n",
      " 'Baseline_Rate_err': 0.3967253428113813,\n",
      " 'Control_Rate': 0.3967253428113813,\n",
      " 'Control_Rate_err': 0.3967253428113813,\n",
      " 'Risk': 0.0,\n",
      " 'Risk_CI_btm': 0.0,\n",
      " 'Risk_CI_top': 0.9300148011448004}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "\n",
    "para_Executor = {\n",
    "    'Loader': {\n",
    "        'adult': {\n",
    "            'filepath': 'benchmark://adult',\n",
    "            'na_values': {k: '?' for k in [\n",
    "                'workclass',\n",
    "                'occupation',\n",
    "                'native-country'\n",
    "            ]}\n",
    "        }\n",
    "    },\n",
    "    'Splitter': {\n",
    "        '0.8': {\n",
    "            'num_samples': 2,\n",
    "            'train_split_ratio': 0.8,\n",
    "        }\n",
    "    },\n",
    "    'Processor': {\n",
    "        'drop-IQR-stanard-label': {\n",
    "            'missing': {\n",
    "                'method': 'missing_drop',\n",
    "                'all': True\n",
    "            },\n",
    "            #'method': , # ValueError: y contains previously unseen labels:\n",
    "            'encoder': [\n",
    "                {'method': 'encoder_label',\n",
    "                 'include': ['education','marital-status','relationship','gender']\n",
    "                },\n",
    "                {'method': 'encoder_uniform',\n",
    "                 'include': ['workclass', 'occupation', 'race', 'native-country', 'income']\n",
    "                }\n",
    "            ],\n",
    "            'outlier': {\n",
    "                'method': 'outlier_iqr',\n",
    "                'include': 'hours-per-week'\n",
    "            },\n",
    "            'scaler': {\n",
    "                'method': 'scaler_standard',\n",
    "                'exclude': ['hours-per-week',\n",
    "                    'workclass', 'education', 'marital-status',\n",
    "                    'occupation', 'relationship', 'race', 'gender',\n",
    "                    'native-country', 'income'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'Synthesizer': {\n",
    "        'GaussianCopula': {\n",
    "            'synthesizing_method': 'sdv-singletable-gaussiancopula'\n",
    "        }\n",
    "    },\n",
    "    'Evaluator': {\n",
    "        'anonymeter-SinglingOut': {\n",
    "            'evaluating_method': 'anonymeter-singlingout-univariate',\n",
    "            'anonymeter_n_attacks': 1,  # 2000'\n",
    "            'anonymeter_num_samples': 2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "executor_single = PETsARD.Executor(**para_Executor)\n",
    "executor_single.run()\n",
    "pprint(\n",
    "    executor_single.evaluator[(\n",
    "        'adult',\n",
    "        '0.8',\n",
    "        1,\n",
    "        'drop-IQR-stanard-label',\n",
    "        'GaussianCopula',\n",
    "        'anonymeter-SinglingOut',\n",
    "        1\n",
    "    )].Evaluator.evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .run_parallel()\n",
    "Not applicable now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|          | 0/1 [00:20<?, ?it/s]s/it]\n",
      "Splitting: 100%|██████████| 1/1 [00:20<00:00, 20.74s/it]\n",
      "Loading: 100%|██████████| 1/1 [00:20<00:00, 20.74s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'Processor.__init__.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\process.py\", line 211, in _sendback_result\n    result_queue.put(_ResultItem(work_id, result=result,\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py\", line 371, in put\n    obj = _ForkingPickler.dumps(obj)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nAttributeError: Can't pickle local object 'Processor.__init__.<locals>.<lambda>'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 73\u001b[0m\n\u001b[0;32m     11\u001b[0m para_Executor \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoader\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     }\n\u001b[0;32m     69\u001b[0m }\n\u001b[0;32m     72\u001b[0m executor_parallel \u001b[38;5;241m=\u001b[39m PETsARD\u001b[38;5;241m.\u001b[39mExecutor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpara_Executor)\n\u001b[1;32m---> 73\u001b[0m \u001b[43mexecutor_parallel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m pprint(\n\u001b[0;32m     75\u001b[0m     executor_parallel\u001b[38;5;241m.\u001b[39mevaluator[(\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m     )]\u001b[38;5;241m.\u001b[39mEvaluator\u001b[38;5;241m.\u001b[39mevaluation\n\u001b[0;32m     84\u001b[0m )\n",
      "File \u001b[1;32mD:\\Dropbox\\89_其他應用\\GitHub\\PETsARD\\PETsARD\\Executor.py:541\u001b[0m, in \u001b[0;36mExecutor.run_parallel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    539\u001b[0m trials_till_proc \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proc_future \u001b[38;5;129;01min\u001b[39;00m as_completed(proc_futures):\n\u001b[1;32m--> 541\u001b[0m     proc_result \u001b[38;5;241m=\u001b[39m \u001b[43mproc_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m     proc_name \u001b[38;5;241m=\u001b[39m proc_futures[proc_future][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor[proc_name] \u001b[38;5;241m=\u001b[39m proc_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'Processor.__init__.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD')\n",
    "os.chdir('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD\\\\demo')\n",
    "\n",
    "import PETsARD\n",
    "\n",
    "\n",
    "para_Executor = {\n",
    "    'Loader': {\n",
    "        'adult': {\n",
    "            'filepath': 'benchmark://adult',\n",
    "            'na_values': {k: '?' for k in [\n",
    "                'workclass',\n",
    "                'occupation',\n",
    "                'native-country'\n",
    "            ]}\n",
    "        }\n",
    "    },\n",
    "    'Splitter': {\n",
    "        '0.8': {\n",
    "            'num_samples': 2,\n",
    "            'train_split_ratio': 0.8,\n",
    "        }\n",
    "    },\n",
    "    'Processor': {\n",
    "        'drop-IQR-stanard-label': {\n",
    "            'missingist': {\n",
    "                'method': 'missingist_drop',\n",
    "                'all': True\n",
    "            },\n",
    "            #'method': , # ValueError: y contains previously unseen labels:\n",
    "            'encoder': [\n",
    "                {'method': 'encoder_label',\n",
    "                 'include': ['education','marital-status','relationship','gender']\n",
    "                },\n",
    "                {'method': 'encoder_uniform',\n",
    "                 'include': ['workclass', 'occupation', 'race', 'native-country', 'income']\n",
    "                }\n",
    "            ],\n",
    "            'outlierist': {\n",
    "                'method': 'outlierist_iqr',\n",
    "                'include': 'hours-per-week'\n",
    "            },\n",
    "            'scaler': {\n",
    "                'method': 'scaler_standard',\n",
    "                'exclude': ['hours-per-week',\n",
    "                    'workclass', 'education', 'marital-status',\n",
    "                    'occupation', 'relationship', 'race', 'gender',\n",
    "                    'native-country', 'income'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'Synthesizer': {\n",
    "        'GaussianCopula': {\n",
    "            'synthesizing_method': 'sdv-singletable-gaussiancopula'\n",
    "        }\n",
    "    },\n",
    "    'Evaluator': {\n",
    "        'anonymeter-SinglingOut': {\n",
    "            'evaluating_method': 'anonymeter-singlingout-univariate',\n",
    "            'anonymeter_n_attacks': 1,  # 2000'\n",
    "            'anonymeter_num_samples': 2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Processor contains lambda function, but python couldn't pickle it.\n",
    "# so Processor .run_parallel() didn't valid after Processor migration.\n",
    "executor_parallel = PETsARD.Executor(**para_Executor)\n",
    "executor_parallel.run_parallel()\n",
    "pprint(\n",
    "    executor_parallel.evaluator[(\n",
    "        'adult',\n",
    "        '0.8',\n",
    "        1,\n",
    "        'drop-IQR-stanard-label',\n",
    "        'GaussianCopula',\n",
    "        'anonymeter-SinglingOut',\n",
    "        1\n",
    "    )].Evaluator.evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un arrangment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Result(__evaluator):\n",
    "    import numpy as np\n",
    "    __dict_result = {}\n",
    "    __para_to_handle = [('Risk', ['risk()', 'value']), ('Risk_CI_btm', ['risk()', 'ci[0]']), ('Risk_CI_top', ['risk()', 'ci[1]']), ('Attack_Rate', ['results()', 'attack_rate', 'value']), ('Attack_Rate_err', ['results()', 'attack_rate', 'error']), ('Baseline_Rate', ['results()', 'baseline_rate', 'value']), ('Baseline_Rate_err', ['results()', 'baseline_rate', 'error']), ('Control_Rate', ['results()', 'control_rate', 'value']), ('Control_Rate_err', ['results()', 'control_rate', 'error'])\n",
    "                        ]\n",
    "    for __key, __attrs in __para_to_handle:\n",
    "        try:\n",
    "            __attr_value = __evaluator\n",
    "            for __attr in __attrs:\n",
    "                if '()' in __attr:\n",
    "                    __method_name = __attr.split('(')[0]\n",
    "                    if hasattr(__attr_value, __method_name):\n",
    "                        __method = getattr(__attr_value, __method_name)\n",
    "                        if callable(__method):\n",
    "                            __attr_value = __method()\n",
    "                        else:\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                elif '[' in __attr:\n",
    "                    __attr_name = __attr.split('[')[0]\n",
    "                    __index = int(__attr.split('[')[1].rstrip(']'))\n",
    "                    if hasattr(__attr_value, __attr_name)\\\n",
    "                            and isinstance(getattr(__attr_value, __attr_name), (list, dict, tuple)):\n",
    "                        try:\n",
    "                            __attr_value = getattr(\n",
    "                                __attr_value, __attr_name)[__index]\n",
    "                        except (IndexError, KeyError):\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                else:\n",
    "                    __attr_value = getattr(__attr_value, __attr)\n",
    "            __dict_result[__key] = __attr_value\n",
    "        except Exception as e:\n",
    "            __dict_result[__key] = np.nan\n",
    "    return __dict_result\n",
    "\n",
    "\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    from anonymeter.evaluators import SinglingOutEvaluator\n",
    "    print(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\")\n",
    "    evaluator = SinglingOutEvaluator(ori=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), syn=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), control=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\"), n_attacks=2000\n",
    "                                     )\n",
    "    try:\n",
    "        evaluator.evaluate(mode='univariate')\n",
    "        print(Result(evaluator))\n",
    "    except RuntimeError as ex:\n",
    "        print(f\"Singling out evaluation failed with {ex}.\"\n",
    "              \"Please re-run this cell.\"\n",
    "              \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "              \"make the evaluation slower.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "for type in ['][Ori]', '][Ctrl]', '-1-1]Postproc']:\n",
    "    for combo in itertools.combinations(['01', '02', '03', '04', '05', '06'], 2):\n",
    "        df_a = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[0]}{type}.csv\")\n",
    "        df_b = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[1]}{type}.csv\")\n",
    "        if df_a.equals(df_b):\n",
    "            print(type+': '+str(combo))\n",
    "            print(\"They're same!!??\")\n",
    "        # else:\n",
    "            # print(type+': '+str(combo))\n",
    "            # print(\"They're different.\")\n",
    "print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Loader: adult loading time: 6.8097 sec.\n",
      "Executor - Splitter: 0.8 splitting time: 0.339 sec.\n",
      "Preprocessor - Outlierist (IQR): Dropped  1060 rows on fnlwgt         . Kept [-63981.5, 419234.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   227 rows on educational-num. Kept [3.0, 19.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  1705 rows on capital-loss   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  9432 rows on hours-per-week . Kept [32.5, 52.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   214 rows on age            . Kept [-0.5, 75.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  3030 rows on capital-gain   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Totally Dropped 13932 in 36207 rows.\n",
      "Preprocessor - Encoder (Label): Column native-country  been labelized from 0 to 39.\n",
      "Preprocessor - Encoder (Label): Column gender          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column race            been labelized from 0 to  4.\n",
      "Preprocessor - Encoder (Label): Column relationship    been labelized from 0 to  5.\n",
      "Preprocessor - Encoder (Label): Column education       been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column income          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column workclass       been labelized from 0 to  6.\n",
      "Preprocessor - Encoder (Label): Column occupation      been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column marital-status  been labelized from 0 to  6.\n",
      "Executor - Preprocessor: drop-IQR-stanard-NA preprocessing time: 0.0764 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.021 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula spent 12.1284 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCoupula # 22275 rows (same as raw) in 1.313 sec.\n",
      "Executor - Synthesizer: GaussianCoupula synthesizing time: 13.466 sec.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding native-country.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding gender.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding race.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding relationship.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding education.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding income.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding workclass.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding occupation.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding marital-status.\n",
      "Executor - Postprocessor: postprocessing time: 0.0142 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0404 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 765 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 131.365 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0322 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 802 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 2 trials evaluating time: 131.1331 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0336 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 830 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 3 trials evaluating time: 131.5346 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0356 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 794 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 4 trials evaluating time: 131.4821 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0351 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 821 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 5 trials evaluating time: 132.587 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.036 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 800 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 6 trials evaluating time: 131.8783 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0352 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 799 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Result(__evaluator):\n",
    "    import numpy as np\n",
    "    __dict_result = {}\n",
    "    __para_to_handle = [('Risk', ['risk()', 'value']), ('Risk_CI_btm', ['risk()', 'ci[0]']), ('Risk_CI_top', ['risk()', 'ci[1]']), ('Attack_Rate', ['results()', 'attack_rate', 'value']), ('Attack_Rate_err', ['results()', 'attack_rate', 'error']), ('Baseline_Rate', ['results()', 'baseline_rate', 'value']), ('Baseline_Rate_err', ['results()', 'baseline_rate', 'error']), ('Control_Rate', ['results()', 'control_rate', 'value']), ('Control_Rate_err', ['results()', 'control_rate', 'error'])\n",
    "                        ]\n",
    "    for __key, __attrs in __para_to_handle:\n",
    "        try:\n",
    "            __attr_value = __evaluator\n",
    "            for __attr in __attrs:\n",
    "                if '()' in __attr:\n",
    "                    __method_name = __attr.split('(')[0]\n",
    "                    if hasattr(__attr_value, __method_name):\n",
    "                        __method = getattr(__attr_value, __method_name)\n",
    "                        if callable(__method):\n",
    "                            __attr_value = __method()\n",
    "                        else:\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                elif '[' in __attr:\n",
    "                    __attr_name = __attr.split('[')[0]\n",
    "                    __index = int(__attr.split('[')[1].rstrip(']'))\n",
    "                    if hasattr(__attr_value, __attr_name)\\\n",
    "                            and isinstance(getattr(__attr_value, __attr_name), (list, dict, tuple)):\n",
    "                        try:\n",
    "                            __attr_value = getattr(\n",
    "                                __attr_value, __attr_name)[__index]\n",
    "                        except (IndexError, KeyError):\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                else:\n",
    "                    __attr_value = getattr(__attr_value, __attr)\n",
    "            __dict_result[__key] = __attr_value\n",
    "        except Exception as e:\n",
    "            __dict_result[__key] = np.nan\n",
    "    return __dict_result\n",
    "\n",
    "\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    from anonymeter.evaluators import SinglingOutEvaluator\n",
    "    print(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\")\n",
    "    evaluator = SinglingOutEvaluator(ori=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), syn=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), control=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\"), n_attacks=2000\n",
    "                                     )\n",
    "    try:\n",
    "        evaluator.evaluate(mode='univariate')\n",
    "        print(Result(evaluator))\n",
    "    except RuntimeError as ex:\n",
    "        print(f\"Singling out evaluation failed with {ex}.\"\n",
    "              \"Please re-run this cell.\"\n",
    "              \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "              \"make the evaluation slower.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    eval = PETsARD.Evaluator(evaluating_method='anonymeter-singlingout-univariate', data={'ori': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), 'syn': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), 'control': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\")\n",
    "                                                                                          }, anonymeter_n_attacks=500\n",
    "                             )\n",
    "    eval.eval()\n",
    "    print(eval.Evaluator.evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 7 trials evaluating time: 131.5421 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0354 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for type in ['][Ori]', '][Ctrl]', '-1-1]Postproc']:\n",
    "    for combo in itertools.combinations(['01', '02', '03', '04', '05', '06'], 2):\n",
    "        df_a = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[0]}{type}.csv\")\n",
    "        df_b = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[1]}{type}.csv\")\n",
    "        if df_a.equals(df_b):\n",
    "            print(type+': '+str(combo))\n",
    "            print(\"They're same!!??\")\n",
    "        # else:\n",
    "            # print(type+': '+str(combo))\n",
    "            # print(\"They're different.\")\n",
    "print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'Loader': {\n",
    "        'NHANES': {\n",
    "            'filepath': '../[sunset]/data/[NHANES] B.csv',\n",
    "            'header_exist': False,\n",
    "            'header_names': ['gen', 'age', 'race', 'edu', 'mar', 'bmi', 'dep', 'pir', 'gh', 'mets', 'qm', 'dia']\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
