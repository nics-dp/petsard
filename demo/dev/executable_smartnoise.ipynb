{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\n"
     ]
    }
   ],
   "source": [
    "# %cd /Users/alex/PETsARD\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "path_petsard = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(path_petsard)\n",
    "sys.path.append(path_petsard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader - Benchmarker : Success download the benchmark dataset from https://petsard-benchmark.s3.amazonaws.com/adult-income.csv.\n"
     ]
    }
   ],
   "source": [
    "from PETsARD import (\n",
    "    Loader,\n",
    "    Processor,\n",
    "    Synthesizer\n",
    ")\n",
    "\n",
    "\n",
    "load = Loader(\n",
    "    filepath='benchmark://adult-income',\n",
    "    na_values={k: '?' for k in [\n",
    "        'workclass',\n",
    "        'occupation',\n",
    "        'native-country'\n",
    "    ]}\n",
    ")\n",
    "load.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load.data = load.data.loc[:1000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "\n",
    "def issue332(\n",
    "        load: Loader,\n",
    "        synthesizing_method: str,\n",
    "        scaler_inhibit: bool = False\n",
    "):\n",
    "    pp = pprint.PrettyPrinter(depth=2)\n",
    "\n",
    "    proc_discretizing = Processor(\n",
    "        metadata=load.metadata,\n",
    "    )\n",
    "\n",
    "    if scaler_inhibit:\n",
    "        print(\"Preproc config of Scaler before update as ...\")\n",
    "        pp.pprint(proc_discretizing.get_config()['scaler'])\n",
    "        proc_discretizing.update_config(\n",
    "            {'scaler': {\n",
    "                col: None for col in load.data.columns\n",
    "            }}\n",
    "        )\n",
    "        print(\"Preproc config of Scaler before after as ...\")\n",
    "        pp.pprint(proc_discretizing.get_config()['scaler'])\n",
    "\n",
    "    proc_discretizing.fit(\n",
    "        data=load.data,\n",
    "        sequence=[\n",
    "            'missing',\n",
    "            'outlier',\n",
    "            'scaler',\n",
    "            'discretizing'\n",
    "        ]\n",
    "    )\n",
    "    preproc_discretizing_data = proc_discretizing.transform(\n",
    "        data=load.data\n",
    "    )\n",
    "    print(\"Preproc data as ...\")\n",
    "    print(preproc_discretizing_data.head(1))\n",
    "\n",
    "\n",
    "    syn = Synthesizer(\n",
    "        method=synthesizing_method,\n",
    "        epsilon=10.0,\n",
    "    )\n",
    "    syn.create(data=preproc_discretizing_data)\n",
    "    syn.fit_sample()\n",
    "    print(\"Sync data as ...\")\n",
    "    print(syn.data_syn.head(1))\n",
    "    postproc_discretizing_data = proc_discretizing.inverse_transform(\n",
    "        data=syn.data_syn\n",
    "    )\n",
    "    print(postproc_discretizing_data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "\n",
    "def issue332_gan(\n",
    "        load: Loader,\n",
    "        synthesizing_method: str,\n",
    "        scaler_inhibit: bool = False,\n",
    "        outlier_inhibit: bool = False\n",
    "):\n",
    "    pp = pprint.PrettyPrinter(depth=2)\n",
    "\n",
    "    proc_discretizing = Processor(\n",
    "        metadata=load.metadata,\n",
    "    )\n",
    "\n",
    "    if scaler_inhibit:\n",
    "        print(\"Preproc config of Scaler before update as ...\")\n",
    "        pp.pprint(proc_discretizing.get_config()['scaler'])\n",
    "        proc_discretizing.update_config(\n",
    "            {'scaler': {\n",
    "                col: None for col in load.data.columns\n",
    "            }}\n",
    "        )\n",
    "        print(\"Preproc config of Scaler before after as ...\")\n",
    "        pp.pprint(proc_discretizing.get_config()['scaler'])\n",
    "\n",
    "    if outlier_inhibit:\n",
    "        print(\"Preproc config of Outlier before update as ...\")\n",
    "        pp.pprint(proc_discretizing.get_config()['scaler'])\n",
    "        proc_discretizing.update_config(\n",
    "            {'outlier': {\n",
    "                col: None for col in load.data.columns\n",
    "            }}\n",
    "        )\n",
    "        print(\"Preproc config of Outlier before after as ...\")\n",
    "        pp.pprint(proc_discretizing.get_config()['scaler'])\n",
    "\n",
    "\n",
    "    proc_discretizing.fit(\n",
    "        data=load.data,\n",
    "        sequence=[\n",
    "            'missing',\n",
    "            'outlier',\n",
    "            'encoder',\n",
    "            'scaler'\n",
    "        ]\n",
    "    )\n",
    "    preproc_discretizing_data = proc_discretizing.transform(\n",
    "        data=load.data\n",
    "    )\n",
    "    print(\"Preproc data as ...\")\n",
    "    print(preproc_discretizing_data.head(1))\n",
    "\n",
    "\n",
    "    syn = Synthesizer(\n",
    "        method=synthesizing_method,\n",
    "        epsilon=10.0,\n",
    "    )\n",
    "    syn.create(data=preproc_discretizing_data)\n",
    "    syn.fit_sample()\n",
    "    print(\"Sync data as ...\")\n",
    "    print(syn.data_syn.head(1))\n",
    "    postproc_discretizing_data = proc_discretizing.inverse_transform(\n",
    "        data=syn.data_syn\n",
    "    )\n",
    "    print(postproc_discretizing_data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preproc data as ...\n",
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0  0.0          2     0.0          1              0.0               4   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0           6             3     2       1           0.0           0.0   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0             0.0              25       0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\mbi\\__init__.py:15: UserWarning: MixtureInference disabled, please install jax and jaxlib\n",
      "  warnings.warn('MixtureInference disabled, please install jax and jaxlib')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizer (SmartNoise): Fitting aim.\n",
      "15\n",
      "Initial Sigma 11.056041228448832\n",
      "Synthesizer (SmartNoise): Fitting  aim spent 270.8398 sec.\n",
      "Synthesizer (SmartNoise): Sampling aim # 558 rows (same as raw) in 0.5135 sec.\n",
      "Sync data as ...\n",
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0  0.0          2     0.0          4              0.0               2   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0           6             0     4       1           0.0           0.0   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0             0.0              25       1  \n",
      "          age workclass        fnlwgt education  educational-num  \\\n",
      "0  371.264583   Private  8.479563e+09   5th-6th         16.57591   \n",
      "\n",
      "       marital-status         occupation relationship   race gender  \\\n",
      "0  Married-civ-spouse  Machine-op-inspct      Husband  White   Male   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0  9.268677e+07  96578.239577       172.18284  United-States   >50K  \n"
     ]
    }
   ],
   "source": [
    "issue332(\n",
    "    load=load,\n",
    "    synthesizing_method='smartnoise-aim'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述執行會出現 `RuntimeError: all elements of input should be between 0 and 1`，原因是 input 中含有 NA 值，來自於前處理過程中將離群值去除掉，導致 `capital-gain`, `capital-loss` 兩個欄位的值皆相同，在 `smartnoise` 中進行 `MinMaxTransformer` 時會讓運算結果為 NA （分母為 0）。因此針對 adult 資料集，將其中的 `outlier` 前處理拿掉，就可以正常運行了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preproc data as ...\n",
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0  0.0          2     0.0          1              0.0               4   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0           6             3     2       1           0.0           0.0   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0             0.0              25       0  \n",
      "Synthesizer (SmartNoise): Fitting mst.\n",
      "Synthesizer (SmartNoise): Fitting  mst spent 113.5179 sec.\n",
      "Synthesizer (SmartNoise): Sampling mst # 558 rows (same as raw) in 0.4945 sec.\n",
      "Sync data as ...\n",
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0  0.0          0     0.0          9              0.0               2   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0          11             0     4       1           0.0           0.0   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0             0.0              25       0  \n",
      "          age    workclass        fnlwgt  education  educational-num  \\\n",
      "0  371.264583  Federal-gov  8.479563e+09  Bachelors         16.57591   \n",
      "\n",
      "       marital-status occupation relationship   race gender  capital-gain  \\\n",
      "0  Married-civ-spouse      Sales      Husband  White   Male  9.268677e+07   \n",
      "\n",
      "   capital-loss  hours-per-week native-country income  \n",
      "0  96578.239577       172.18284  United-States  <=50K  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:241: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[~mask, col] = idx[df.loc[~mask, col]]\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:241: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0 2 2 0 1 2 2 2 1 2 1 2 2 2 0 2 2 2 2 1 2 2 2 2 2 4 2 2 2 0 2 3 2 4 2 2 4\n",
      " 2 2 2 2 3 2 2 2 2 2 5 2 2 2 2 2 2 2 2 5 2 2 2 2 2 3 4 2 2 2 2 2 2 2 2 5 5\n",
      " 2 2 2 2 3 2 4 0 2 2 2 2 3 2 2 2 2 4 2 2 0 2 0 2 2 2 2 1 1 2 2 5 2 2 2 2 1\n",
      " 2 1 2 2 2 2 2 2 4 3 2 2 5 5 2 2 2 2 1 2 2 2 4 2 5 2 2 2 2 2 2 2 2 2 2 5 2\n",
      " 2 5 2 3 5 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 0 4 2 2 2 2 3 2 1\n",
      " 1 5 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 4 2 5 2 1 2 2 2 1 2 2 2 2 2 1\n",
      " 2 1 3 2 2 0 3 5 4 2 2 2 1 2 2 2 2 2 2 2 2 2 2 3 2 2 0 4 2 0 2 2 2 2 1 2 1\n",
      " 2 2 2 2 2 2 2 2 2 2 2 0 2 2 1 2 2 2 5 2 2 4 2 2 5 2 2 2 2 2 2 2 2 2 3 2 5\n",
      " 2 2 2 2 2 4 1 2 1 2 3 2 2 5 2 1 2 2 2 2 2 2 2 0 1 2 2 5 2 2 2 5 2 5 2 0 2\n",
      " 2 0 5 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 5 2 2 2 2 2 2 2 5 2\n",
      " 2 4 2 1 2 4 2 2 2 2 2 2 2 3 2 3 2 2 2 2 2 2 2 1 2 2 5 2 2 2 2 2 2 2 2 2 3\n",
      " 4 2 2 4 2 1 2 2 4 2 5 2 2 2 2 2 4 2 2 2 5 2 2 2 3 2 2 2 1 2 4 2 1 2 2 2 2\n",
      " 2 1 2 2 2 2 2 2 2 2 2 4 4 3 4 0 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2 1 1 2 2 2 1\n",
      " 4 2 1 2 3 2 1 2 2 2 2 0 4 2 2 4 2 2 1 2 2 2 2 2 1 0 2 2 2 2 0 2 2 4 1 2 1\n",
      " 2 2 2 3 2 2 2 2 2 4 1 2 2 2 2 2 2 1 0 2 1 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 0 2]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[~mask, col] = idx[df.loc[~mask, col]]\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:241: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[~mask, col] = idx[df.loc[~mask, col]]\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:240: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[ 9 12  5 12  9  3  3  4  3  5  5  5  3  2  4 12  3  5  2  3 12  9  2  9\n",
      "  5 12 12  9  9  5  5 12 12 12  2  2  9 12 12]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, col] = np.random.choice(extra, mask.sum())\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:241: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[~mask, col] = idx[df.loc[~mask, col]]\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:240: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[5 2 2 2 5 5 2 2 2 2 5 2 5 2 5 5]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, col] = np.random.choice(extra, mask.sum())\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:240: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1 8 1 1 1 1 1 4 1 4 1 1 8 1 1 8]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, col] = np.random.choice(extra, mask.sum())\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:241: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0 0 0 0 0 0 0 1 0 5 2 0 1 0 3 0 0 0 0 2 0 4 3 0 1 1 4 1 4 0 0 0 5 0 0 0 3\n",
      " 1 0 4 1 1 3 0 1 4 1 0 3 1 3 1 0 0 0 1 3 0 2 4 0 1 3 0 0 0 1 1 0 0 0 4 1 1\n",
      " 3 4 1 5 1 2 1 0 1 3 1 4 3 4 0 3 0 1 5 0 0 0 1 1 4 0 0 0 1 1 1 1 5 5 0 0 1\n",
      " 3 4 0 2 0 0 1 2 4 5 1 0 3 0 1 1 0 0 0 1 0 5 0 0 1 5 0 1 5 1 1 3 0 0 4 0 0\n",
      " 0 1 0 1 2 5 1 3 1 0 0 3 4 4 3 0 0 0 4 4 1 5 0 0 0 0 1 1 4 0 0 0 1 0 0 0 1\n",
      " 0 4 0 3 1 1 4 3 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 3 2 0 1 0 0 0 0 1 0 0 1 0\n",
      " 4 3 3 1 0 4 0 3 1 0 3 3 0 3 0 0 1 0 3 1 0 0 0 3 0 4 4 1 0 0 1 1 4 0 0 5 3\n",
      " 0 1 3 3 4 1 0 3 1 1 5 0 0 2 4 0 0 1 0 0 0 4 3 5 3 0 3 1 3 0 0 3 3 1 0 0 0\n",
      " 3 3 0 3 1 0 1 0 1 4 0 0 0 1 0 0 1 1 0 1 0 3 0 0 4 1 0 0 1 0 1 3 0 3 3 1 1\n",
      " 2 1 3 1 0 0 4 4 0 0 1 1 0 1 0 0 0 0 4 0 3 1 0 2 5 0 0 1 0 3 2 1 1 0 0 0 5\n",
      " 4 1 4 1 0 3 1 3 4 0 3 0 0 1 0 1 0 3 0 3 1 3 0 3 2 0 3 1 4 1 0 0 2 3 1 1 0\n",
      " 0 0 1 0 1 0 0 0 1 0 4 1 1 0 1 3 0 4 1 0 5 1 1 4 0 1 0 0 0 1 1 4 1 0 1 1 3\n",
      " 4 3 3 0 0 2 0 0 0 1 0 4 0 2 0 4 1 3 0 0 3 1 1 0 3 1 0 0 3 3 0 0 1 1 0 1 1\n",
      " 4 0 3 1 0 0 1 5 0 0 3 3 3 4 4 4 3 1 1 0 1 4 4 1 1 0 1 0 3 5 1 0 0 0 4 0 0\n",
      " 0 1 4 4 0 0 3 4 0 2 1 1 0 1 0 1 3 0 0 1 4 1 5 0 3 1 1 1 3 0 0 3 1 1 0 4 0\n",
      " 0 0 0]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[~mask, col] = idx[df.loc[~mask, col]]\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:240: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[3 1 0 3 3 1 3 1 0 0 1 0 1 1 3 3 1 0 0 3 3 0 3 3]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, col] = np.random.choice(extra, mask.sum())\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:241: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1\n",
      " 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
      " 1 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0\n",
      " 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1\n",
      " 1 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1\n",
      " 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0\n",
      " 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0\n",
      " 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0\n",
      " 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0\n",
      " 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1\n",
      " 1 1 1]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[~mask, col] = idx[df.loc[~mask, col]]\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:241: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[~mask, col] = idx[df.loc[~mask, col]]\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:241: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[~mask, col] = idx[df.loc[~mask, col]]\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:241: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[~mask, col] = idx[df.loc[~mask, col]]\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:240: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[13 16  8 20 11 10 11  6 15  9 17  9 10 20  4  3 15  1 17 14 16 15 18 18\n",
      "  7  3 20 18  7 16 11  4  0 20 15 14 12 20 14 14 18 12  1 12  9]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, col] = np.random.choice(extra, mask.sum())\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:241: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[~mask, col] = idx[df.loc[~mask, col]]\n"
     ]
    }
   ],
   "source": [
    "issue332(\n",
    "    load=load,\n",
    "    synthesizing_method='smartnoise-mst'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preproc data as ...\n",
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0  0.0          2     0.0          1              0.0               4   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0           6             3     2       1           0.0           0.0   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0             0.0              25       0  \n",
      "Synthesizer (SmartNoise): Fitting pacsynth.\n",
      "Synthesizer (SmartNoise): Fitting  pacsynth spent 0.2158 sec.\n",
      "Synthesizer (SmartNoise): Sampling pacsynth # 558 rows (same as raw) in 1.6921 sec.\n",
      "Sync data as ...\n",
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0  0.0        2.0     0.0       11.0              0.0             2.0   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0         6.0           0.0   4.0     1.0           0.0           0.0   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0             0.0            25.0     0.0  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43missue332\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynthesizing_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msmartnoise-pacsynth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 50\u001b[0m, in \u001b[0;36missue332\u001b[1;34m(load, synthesizing_method, scaler_inhibit)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSync data as ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(syn\u001b[38;5;241m.\u001b[39mdata_syn\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 50\u001b[0m postproc_discretizing_data \u001b[38;5;241m=\u001b[39m \u001b[43mproc_discretizing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msyn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_syn\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(postproc_discretizing_data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\processor\\base.py:483\u001b[0m, in \u001b[0;36mProcessor.inverse_transform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 483\u001b[0m         transformed[col] \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocessor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inverse transformation done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;66;03m# if the processor is not a string,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;66;03m# it should be a mediator, which transforms the data directly.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\processor\\discretizing.py:81\u001b[0m, in \u001b[0;36mDiscretizingHandler.inverse_transform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_fitted:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnfittedError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe object is not fitted. Use .fit() first.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\processor\\discretizing.py:152\u001b[0m, in \u001b[0;36mDiscretizingKBins._inverse_transform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inverse_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: pd\u001b[38;5;241m.\u001b[39mSeries) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m    Inverse the transformed data to the numerical data.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03m        (np.ndarray): The inverse transformed data.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:430\u001b[0m, in \u001b[0;36mKBinsDiscretizer.inverse_transform\u001b[1;34m(self, Xt)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monehot\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode:\n\u001b[0;32m    428\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoder\u001b[38;5;241m.\u001b[39minverse_transform(Xt)\n\u001b[1;32m--> 430\u001b[0m Xinv \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_bins_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Xinv\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m n_features:\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1046\u001b[0m     )\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1049\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "issue332(\n",
    "    load=load,\n",
    "    synthesizing_method='smartnoise-pacsynth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preproc config of Outlier before update as ...\n",
      "{'age': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F484229F90>,\n",
      " 'capital-gain': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F48422B3D0>,\n",
      " 'capital-loss': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F4842384F0>,\n",
      " 'education': None,\n",
      " 'educational-num': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F484229F60>,\n",
      " 'fnlwgt': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F484228C70>,\n",
      " 'gender': None,\n",
      " 'hours-per-week': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F4842385B0>,\n",
      " 'income': None,\n",
      " 'marital-status': None,\n",
      " 'native-country': None,\n",
      " 'occupation': None,\n",
      " 'race': None,\n",
      " 'relationship': None,\n",
      " 'workclass': None}\n",
      "Preproc config of Outlier before after as ...\n",
      "{'age': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F484229F90>,\n",
      " 'capital-gain': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F48422B3D0>,\n",
      " 'capital-loss': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F4842384F0>,\n",
      " 'education': None,\n",
      " 'educational-num': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F484229F60>,\n",
      " 'fnlwgt': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F484228C70>,\n",
      " 'gender': None,\n",
      " 'hours-per-week': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F4842385B0>,\n",
      " 'income': None,\n",
      " 'marital-status': None,\n",
      " 'native-country': None,\n",
      " 'occupation': None,\n",
      " 'race': None,\n",
      " 'relationship': None,\n",
      " 'workclass': None}\n",
      "Preproc data as ...\n",
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0 -0.953119   0.366136  0.409053   0.776959        -1.152735        0.810663   \n",
      "\n",
      "   occupation  relationship      race   gender  capital-gain  capital-loss  \\\n",
      "0     0.74892      0.757864  0.955584  0.48598     -0.159918     -0.219043   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0       -0.044504        0.216869  0.212391  \n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\opacus\\privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\opacus\\privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1352: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.7107, Loss D: 1.3900\n",
      "epsilon is 0.08246410416899833, alpha is 63.0\n",
      "Epoch 2, Loss G: 0.7097, Loss D: 1.3898\n",
      "epsilon is 0.6154321240229542, alpha is 21.0\n",
      "Epoch 3, Loss G: 0.7048, Loss D: 1.3908\n",
      "epsilon is 0.8717652885709554, alpha is 16.0\n",
      "Epoch 4, Loss G: 0.7016, Loss D: 1.3897\n",
      "epsilon is 1.0734433928301887, alpha is 14.0\n",
      "Epoch 5, Loss G: 0.7059, Loss D: 1.3874\n",
      "epsilon is 1.2474424384805656, alpha is 12.0\n",
      "Epoch 6, Loss G: 0.7015, Loss D: 1.3895\n",
      "epsilon is 1.403078289939324, alpha is 10.9\n",
      "Epoch 7, Loss G: 0.6987, Loss D: 1.3876\n",
      "epsilon is 1.5430774752709655, alpha is 10.6\n",
      "Epoch 8, Loss G: 0.6922, Loss D: 1.3928\n",
      "epsilon is 1.6748565545536702, alpha is 10.0\n",
      "Epoch 9, Loss G: 0.6947, Loss D: 1.3898\n",
      "epsilon is 1.7986930762464894, alpha is 9.4\n",
      "Epoch 10, Loss G: 0.6898, Loss D: 1.3850\n",
      "epsilon is 1.9160035051686128, alpha is 9.0\n",
      "Epoch 11, Loss G: 0.6888, Loss D: 1.3885\n",
      "epsilon is 2.027907968415127, alpha is 8.7\n",
      "Epoch 12, Loss G: 0.6854, Loss D: 1.3891\n",
      "epsilon is 2.135121781113915, alpha is 8.3\n",
      "Epoch 13, Loss G: 0.6822, Loss D: 1.3884\n",
      "epsilon is 2.2382637160168204, alpha is 8.1\n",
      "Epoch 14, Loss G: 0.6828, Loss D: 1.3872\n",
      "epsilon is 2.337827882631375, alpha is 7.8\n",
      "Epoch 15, Loss G: 0.6835, Loss D: 1.3950\n",
      "epsilon is 2.434237194672732, alpha is 7.6\n",
      "Epoch 16, Loss G: 0.6794, Loss D: 1.3912\n",
      "epsilon is 2.5278163462034815, alpha is 7.4\n",
      "Epoch 17, Loss G: 0.6722, Loss D: 1.3944\n",
      "epsilon is 2.6188388524326234, alpha is 7.2\n",
      "Epoch 18, Loss G: 0.6723, Loss D: 1.3989\n",
      "epsilon is 2.7076108306108346, alpha is 7.0\n",
      "Epoch 19, Loss G: 0.6683, Loss D: 1.3920\n",
      "epsilon is 2.7940664707675626, alpha is 6.9\n",
      "Epoch 20, Loss G: 0.6670, Loss D: 1.3951\n",
      "epsilon is 2.878763468386405, alpha is 6.8\n",
      "Epoch 21, Loss G: 0.6687, Loss D: 1.3902\n",
      "epsilon is 2.961464297854409, alpha is 6.6\n",
      "Epoch 22, Loss G: 0.6657, Loss D: 1.3872\n",
      "epsilon is 3.0425452652856495, alpha is 6.5\n",
      "Epoch 23, Loss G: 0.6616, Loss D: 1.3926\n",
      "epsilon is 3.122103446988952, alpha is 6.4\n",
      "Epoch 24, Loss G: 0.6631, Loss D: 1.3951\n",
      "epsilon is 3.200208539731727, alpha is 6.3\n",
      "Epoch 25, Loss G: 0.6614, Loss D: 1.3910\n",
      "epsilon is 3.2769350559807005, alpha is 6.2\n",
      "Epoch 26, Loss G: 0.6637, Loss D: 1.3855\n",
      "epsilon is 3.3523628060835255, alpha is 6.1\n",
      "Epoch 27, Loss G: 0.6664, Loss D: 1.3881\n",
      "epsilon is 3.4265774389666657, alpha is 6.0\n",
      "Epoch 28, Loss G: 0.6632, Loss D: 1.3884\n",
      "epsilon is 3.4996710497868895, alpha is 5.9\n",
      "Epoch 29, Loss G: 0.6609, Loss D: 1.3892\n",
      "epsilon is 3.5717428643995515, alpha is 5.8\n",
      "Epoch 30, Loss G: 0.6594, Loss D: 1.3910\n",
      "epsilon is 3.6428935706241528, alpha is 5.8\n",
      "Epoch 31, Loss G: 0.6567, Loss D: 1.3863\n",
      "epsilon is 3.712751905883079, alpha is 5.7\n",
      "Epoch 32, Loss G: 0.6577, Loss D: 1.3827\n",
      "epsilon is 3.7818141415719784, alpha is 5.6\n",
      "Epoch 33, Loss G: 0.6609, Loss D: 1.3858\n",
      "epsilon is 3.850205948937656, alpha is 5.5\n",
      "Epoch 34, Loss G: 0.6532, Loss D: 1.3819\n",
      "epsilon is 3.917468189518828, alpha is 5.5\n",
      "Epoch 35, Loss G: 0.6551, Loss D: 1.3896\n",
      "epsilon is 3.9840352850839897, alpha is 5.4\n",
      "Epoch 36, Loss G: 0.6527, Loss D: 1.3815\n",
      "epsilon is 4.050006670613625, alpha is 5.4\n",
      "Epoch 37, Loss G: 0.6516, Loss D: 1.3873\n",
      "epsilon is 4.114903091238218, alpha is 5.3\n",
      "Epoch 38, Loss G: 0.6477, Loss D: 1.3901\n",
      "epsilon is 4.179582102216282, alpha is 5.2\n",
      "Epoch 39, Loss G: 0.6504, Loss D: 1.3830\n",
      "epsilon is 4.242979684763249, alpha is 5.2\n",
      "Epoch 40, Loss G: 0.6503, Loss D: 1.3904\n",
      "epsilon is 4.306336090935168, alpha is 5.1\n",
      "Epoch 41, Loss G: 0.6467, Loss D: 1.3944\n",
      "epsilon is 4.368450711228463, alpha is 5.1\n",
      "Epoch 42, Loss G: 0.6481, Loss D: 1.3939\n",
      "epsilon is 4.430565331521756, alpha is 5.1\n",
      "Epoch 43, Loss G: 0.6474, Loss D: 1.3883\n",
      "epsilon is 4.491519093988257, alpha is 5.0\n",
      "Epoch 44, Loss G: 0.6422, Loss D: 1.3922\n",
      "epsilon is 4.552353368662634, alpha is 5.0\n",
      "Epoch 45, Loss G: 0.6401, Loss D: 1.3860\n",
      "epsilon is 4.612407286797646, alpha is 4.9\n",
      "Epoch 46, Loss G: 0.6392, Loss D: 1.3932\n",
      "epsilon is 4.671963825364106, alpha is 4.9\n",
      "Epoch 47, Loss G: 0.6358, Loss D: 1.3937\n",
      "epsilon is 4.731359885691218, alpha is 4.8\n",
      "Epoch 48, Loss G: 0.6367, Loss D: 1.3966\n",
      "epsilon is 4.789641290552096, alpha is 4.8\n",
      "Epoch 49, Loss G: 0.6344, Loss D: 1.4051\n",
      "epsilon is 4.847922695412973, alpha is 4.8\n",
      "Epoch 50, Loss G: 0.6350, Loss D: 1.4007\n",
      "epsilon is 4.905655535140821, alpha is 4.7\n",
      "Epoch 51, Loss G: 0.6294, Loss D: 1.4034\n",
      "epsilon is 4.9626644016048695, alpha is 4.7\n",
      "Epoch 52, Loss G: 0.6293, Loss D: 1.3913\n",
      "epsilon is 5.0196732680689164, alpha is 4.7\n",
      "Epoch 53, Loss G: 0.6228, Loss D: 1.4126\n",
      "epsilon is 5.0760439796888255, alpha is 4.6\n",
      "Epoch 54, Loss G: 0.6300, Loss D: 1.4028\n",
      "epsilon is 5.131782895986607, alpha is 4.6\n",
      "Epoch 55, Loss G: 0.6118, Loss D: 1.4130\n",
      "epsilon is 5.1875218122843885, alpha is 4.6\n",
      "Epoch 56, Loss G: 0.6162, Loss D: 1.4176\n",
      "epsilon is 5.242864373609633, alpha is 4.5\n",
      "Epoch 57, Loss G: 0.6124, Loss D: 1.4177\n",
      "epsilon is 5.297335920908565, alpha is 4.5\n",
      "Epoch 58, Loss G: 0.6036, Loss D: 1.4231\n",
      "epsilon is 5.351807468207497, alpha is 4.5\n",
      "Epoch 59, Loss G: 0.6017, Loss D: 1.4224\n",
      "epsilon is 5.406279015506429, alpha is 4.5\n",
      "Epoch 60, Loss G: 0.6025, Loss D: 1.4320\n",
      "epsilon is 5.4597004033036685, alpha is 4.4\n",
      "Epoch 61, Loss G: 0.5997, Loss D: 1.4292\n",
      "epsilon is 5.512907155723584, alpha is 4.4\n",
      "Epoch 62, Loss G: 0.5974, Loss D: 1.4378\n",
      "epsilon is 5.566113908143499, alpha is 4.4\n",
      "Epoch 63, Loss G: 0.5980, Loss D: 1.4396\n",
      "epsilon is 5.619296859313559, alpha is 4.3\n",
      "Epoch 64, Loss G: 0.5923, Loss D: 1.4463\n",
      "epsilon is 5.671241383942272, alpha is 4.3\n",
      "Epoch 65, Loss G: 0.5817, Loss D: 1.4429\n",
      "epsilon is 5.723185908570986, alpha is 4.3\n",
      "Epoch 66, Loss G: 0.5879, Loss D: 1.4591\n",
      "epsilon is 5.775130433199701, alpha is 4.3\n",
      "Epoch 67, Loss G: 0.5835, Loss D: 1.4501\n",
      "epsilon is 5.827074957828414, alpha is 4.3\n",
      "Epoch 68, Loss G: 0.5829, Loss D: 1.4513\n",
      "epsilon is 5.877966017103227, alpha is 4.2\n",
      "Epoch 69, Loss G: 0.5753, Loss D: 1.4468\n",
      "epsilon is 5.928650874011896, alpha is 4.2\n",
      "Epoch 70, Loss G: 0.5799, Loss D: 1.4541\n",
      "epsilon is 5.979335730920565, alpha is 4.2\n",
      "Epoch 71, Loss G: 0.5725, Loss D: 1.4617\n",
      "epsilon is 6.030020587829234, alpha is 4.2\n",
      "Epoch 72, Loss G: 0.5712, Loss D: 1.4637\n",
      "epsilon is 6.080411733176044, alpha is 4.1\n",
      "Epoch 73, Loss G: 0.5642, Loss D: 1.4602\n",
      "epsilon is 6.129839475434501, alpha is 4.1\n",
      "Epoch 74, Loss G: 0.5707, Loss D: 1.4774\n",
      "epsilon is 6.17926721769296, alpha is 4.1\n",
      "Epoch 75, Loss G: 0.5642, Loss D: 1.4687\n",
      "epsilon is 6.228694959951418, alpha is 4.1\n",
      "Epoch 76, Loss G: 0.5691, Loss D: 1.4757\n",
      "epsilon is 6.278122702209876, alpha is 4.1\n",
      "Epoch 77, Loss G: 0.5707, Loss D: 1.4758\n",
      "epsilon is 6.327357790594008, alpha is 4.0\n",
      "Epoch 78, Loss G: 0.5639, Loss D: 1.4835\n",
      "epsilon is 6.375530964286589, alpha is 4.0\n",
      "Epoch 79, Loss G: 0.5652, Loss D: 1.4719\n",
      "epsilon is 6.42370413797917, alpha is 4.0\n",
      "Epoch 80, Loss G: 0.5628, Loss D: 1.4748\n",
      "epsilon is 6.471877311671752, alpha is 4.0\n",
      "Epoch 81, Loss G: 0.5608, Loss D: 1.4772\n",
      "epsilon is 6.520050485364332, alpha is 4.0\n",
      "Epoch 82, Loss G: 0.5557, Loss D: 1.4777\n",
      "epsilon is 6.568223659056913, alpha is 4.0\n",
      "Epoch 83, Loss G: 0.5670, Loss D: 1.4892\n",
      "epsilon is 6.615734837571576, alpha is 3.9\n",
      "Epoch 84, Loss G: 0.5594, Loss D: 1.4800\n",
      "epsilon is 6.662655981812787, alpha is 3.9\n",
      "Epoch 85, Loss G: 0.5555, Loss D: 1.4830\n",
      "epsilon is 6.709577126053995, alpha is 3.9\n",
      "Epoch 86, Loss G: 0.5576, Loss D: 1.4863\n",
      "epsilon is 6.7564982702952046, alpha is 3.9\n",
      "Epoch 87, Loss G: 0.5547, Loss D: 1.4850\n",
      "epsilon is 6.803419414536414, alpha is 3.9\n",
      "Epoch 88, Loss G: 0.5603, Loss D: 1.4947\n",
      "epsilon is 6.850340558777624, alpha is 3.9\n",
      "Epoch 89, Loss G: 0.5570, Loss D: 1.4874\n",
      "epsilon is 6.896912311217361, alpha is 3.8\n",
      "Epoch 90, Loss G: 0.5555, Loss D: 1.4854\n",
      "epsilon is 6.942583958167586, alpha is 3.8\n",
      "Epoch 91, Loss G: 0.5516, Loss D: 1.4906\n",
      "epsilon is 6.98825560511781, alpha is 3.8\n",
      "Epoch 92, Loss G: 0.5562, Loss D: 1.4936\n",
      "epsilon is 7.033927252068035, alpha is 3.8\n",
      "Epoch 93, Loss G: 0.5531, Loss D: 1.4931\n",
      "epsilon is 7.079598899018261, alpha is 3.8\n",
      "Epoch 94, Loss G: 0.5540, Loss D: 1.4899\n",
      "epsilon is 7.125270545968486, alpha is 3.8\n",
      "Epoch 95, Loss G: 0.5474, Loss D: 1.4922\n",
      "epsilon is 7.170942192918711, alpha is 3.8\n",
      "Epoch 96, Loss G: 0.5483, Loss D: 1.4962\n",
      "epsilon is 7.216225114747892, alpha is 3.7\n",
      "Epoch 97, Loss G: 0.5495, Loss D: 1.4945\n",
      "epsilon is 7.260649789629172, alpha is 3.7\n",
      "Epoch 98, Loss G: 0.5478, Loss D: 1.4869\n",
      "epsilon is 7.305074464510453, alpha is 3.7\n",
      "Epoch 99, Loss G: 0.5472, Loss D: 1.4911\n",
      "epsilon is 7.349499139391733, alpha is 3.7\n",
      "Epoch 100, Loss G: 0.5532, Loss D: 1.4938\n",
      "epsilon is 7.3939238142730135, alpha is 3.7\n",
      "Epoch 101, Loss G: 0.5451, Loss D: 1.4891\n",
      "epsilon is 7.4383484891542935, alpha is 3.7\n",
      "Epoch 102, Loss G: 0.5529, Loss D: 1.4897\n",
      "epsilon is 7.482773164035574, alpha is 3.7\n",
      "Epoch 103, Loss G: 0.5484, Loss D: 1.4863\n",
      "epsilon is 7.527197838916854, alpha is 3.7\n",
      "Epoch 104, Loss G: 0.5478, Loss D: 1.4795\n",
      "epsilon is 7.570985182837946, alpha is 3.6\n",
      "Epoch 105, Loss G: 0.5577, Loss D: 1.4863\n",
      "epsilon is 7.614165403949305, alpha is 3.6\n",
      "Epoch 106, Loss G: 0.5572, Loss D: 1.4800\n",
      "epsilon is 7.657345625060665, alpha is 3.6\n",
      "Epoch 107, Loss G: 0.5546, Loss D: 1.4823\n",
      "epsilon is 7.700525846172025, alpha is 3.6\n",
      "Epoch 108, Loss G: 0.5574, Loss D: 1.4715\n",
      "epsilon is 7.743706067283383, alpha is 3.6\n",
      "Epoch 109, Loss G: 0.5554, Loss D: 1.4778\n",
      "epsilon is 7.786886288394741, alpha is 3.6\n",
      "Epoch 110, Loss G: 0.5621, Loss D: 1.4794\n",
      "epsilon is 7.830066509506101, alpha is 3.6\n",
      "Epoch 111, Loss G: 0.5558, Loss D: 1.4784\n",
      "epsilon is 7.873246730617461, alpha is 3.6\n",
      "Epoch 112, Loss G: 0.5632, Loss D: 1.4766\n",
      "epsilon is 7.916426951728819, alpha is 3.6\n",
      "Epoch 113, Loss G: 0.5602, Loss D: 1.4731\n",
      "epsilon is 7.95868193355541, alpha is 3.5\n",
      "Epoch 114, Loss G: 0.5532, Loss D: 1.4708\n",
      "epsilon is 8.000620212289654, alpha is 3.5\n",
      "Epoch 115, Loss G: 0.5629, Loss D: 1.4671\n",
      "epsilon is 8.042558491023897, alpha is 3.5\n",
      "Epoch 116, Loss G: 0.5605, Loss D: 1.4703\n",
      "epsilon is 8.084496769758141, alpha is 3.5\n",
      "Epoch 117, Loss G: 0.5661, Loss D: 1.4603\n",
      "epsilon is 8.126435048492386, alpha is 3.5\n",
      "Epoch 118, Loss G: 0.5667, Loss D: 1.4750\n",
      "epsilon is 8.168373327226629, alpha is 3.5\n",
      "Epoch 119, Loss G: 0.5659, Loss D: 1.4663\n",
      "epsilon is 8.210311605960872, alpha is 3.5\n",
      "Epoch 120, Loss G: 0.5597, Loss D: 1.4697\n",
      "epsilon is 8.252249884695114, alpha is 3.5\n",
      "Epoch 121, Loss G: 0.5606, Loss D: 1.4597\n",
      "epsilon is 8.294188163429357, alpha is 3.5\n",
      "Epoch 122, Loss G: 0.5615, Loss D: 1.4584\n",
      "epsilon is 8.336126442163602, alpha is 3.5\n",
      "Epoch 123, Loss G: 0.5618, Loss D: 1.4627\n",
      "epsilon is 8.377016439122203, alpha is 3.4\n",
      "Epoch 124, Loss G: 0.5616, Loss D: 1.4609\n",
      "epsilon is 8.417715279980845, alpha is 3.4\n",
      "Epoch 125, Loss G: 0.5624, Loss D: 1.4777\n",
      "epsilon is 8.458414120839487, alpha is 3.4\n",
      "Epoch 126, Loss G: 0.5613, Loss D: 1.4678\n",
      "epsilon is 8.49911296169813, alpha is 3.4\n",
      "Epoch 127, Loss G: 0.5576, Loss D: 1.4605\n",
      "epsilon is 8.539811802556772, alpha is 3.4\n",
      "Epoch 128, Loss G: 0.5654, Loss D: 1.4663\n",
      "epsilon is 8.580510643415414, alpha is 3.4\n",
      "Epoch 129, Loss G: 0.5651, Loss D: 1.4615\n",
      "epsilon is 8.621209484274056, alpha is 3.4\n",
      "Epoch 130, Loss G: 0.5654, Loss D: 1.4641\n",
      "epsilon is 8.661908325132698, alpha is 3.4\n",
      "Epoch 131, Loss G: 0.5639, Loss D: 1.4569\n",
      "epsilon is 8.702607165991338, alpha is 3.4\n",
      "Epoch 132, Loss G: 0.5672, Loss D: 1.4536\n",
      "epsilon is 8.74330600684998, alpha is 3.4\n",
      "Epoch 133, Loss G: 0.5713, Loss D: 1.4582\n",
      "epsilon is 8.784004847708623, alpha is 3.4\n",
      "Epoch 134, Loss G: 0.5650, Loss D: 1.4524\n",
      "epsilon is 8.823944600709858, alpha is 3.3\n",
      "Epoch 135, Loss G: 0.5589, Loss D: 1.4599\n",
      "epsilon is 8.863406501319506, alpha is 3.3\n",
      "Epoch 136, Loss G: 0.5631, Loss D: 1.4620\n",
      "epsilon is 8.902868401929158, alpha is 3.3\n",
      "Epoch 137, Loss G: 0.5668, Loss D: 1.4641\n",
      "epsilon is 8.94233030253881, alpha is 3.3\n",
      "Epoch 138, Loss G: 0.5698, Loss D: 1.4604\n",
      "epsilon is 8.98179220314846, alpha is 3.3\n",
      "Epoch 139, Loss G: 0.5650, Loss D: 1.4606\n",
      "epsilon is 9.02125410375811, alpha is 3.3\n",
      "Epoch 140, Loss G: 0.5700, Loss D: 1.4558\n",
      "epsilon is 9.060716004367762, alpha is 3.3\n",
      "Epoch 141, Loss G: 0.5640, Loss D: 1.4623\n",
      "epsilon is 9.100177904977413, alpha is 3.3\n",
      "Epoch 142, Loss G: 0.5664, Loss D: 1.4496\n",
      "epsilon is 9.139639805587063, alpha is 3.3\n",
      "Epoch 143, Loss G: 0.5707, Loss D: 1.4586\n",
      "epsilon is 9.179101706196715, alpha is 3.3\n",
      "Epoch 144, Loss G: 0.5654, Loss D: 1.4485\n",
      "epsilon is 9.218563606806365, alpha is 3.3\n",
      "Epoch 145, Loss G: 0.5691, Loss D: 1.4478\n",
      "epsilon is 9.258025507416015, alpha is 3.3\n",
      "Epoch 146, Loss G: 0.5750, Loss D: 1.4537\n",
      "epsilon is 9.297487408025667, alpha is 3.3\n",
      "Epoch 147, Loss G: 0.5737, Loss D: 1.4539\n",
      "epsilon is 9.33595966014038, alpha is 3.2\n",
      "Epoch 148, Loss G: 0.5714, Loss D: 1.4532\n",
      "epsilon is 9.374187111269075, alpha is 3.2\n",
      "Epoch 149, Loss G: 0.5723, Loss D: 1.4538\n",
      "epsilon is 9.41241456239777, alpha is 3.2\n",
      "Epoch 150, Loss G: 0.5719, Loss D: 1.4523\n",
      "epsilon is 9.450642013526464, alpha is 3.2\n",
      "Epoch 151, Loss G: 0.5674, Loss D: 1.4542\n",
      "epsilon is 9.48886946465516, alpha is 3.2\n",
      "Epoch 152, Loss G: 0.5661, Loss D: 1.4573\n",
      "epsilon is 9.527096915783854, alpha is 3.2\n",
      "Epoch 153, Loss G: 0.5722, Loss D: 1.4540\n",
      "epsilon is 9.56532436691255, alpha is 3.2\n",
      "Epoch 154, Loss G: 0.5742, Loss D: 1.4563\n",
      "epsilon is 9.603551818041245, alpha is 3.2\n",
      "Epoch 155, Loss G: 0.5725, Loss D: 1.4476\n",
      "epsilon is 9.64177926916994, alpha is 3.2\n",
      "Epoch 156, Loss G: 0.5703, Loss D: 1.4535\n",
      "epsilon is 9.680006720298634, alpha is 3.2\n",
      "Epoch 157, Loss G: 0.5690, Loss D: 1.4478\n",
      "epsilon is 9.71823417142733, alpha is 3.2\n",
      "Epoch 158, Loss G: 0.5698, Loss D: 1.4475\n",
      "epsilon is 9.756461622556024, alpha is 3.2\n",
      "Epoch 159, Loss G: 0.5766, Loss D: 1.4464\n",
      "epsilon is 9.79468907368472, alpha is 3.2\n",
      "Epoch 160, Loss G: 0.5784, Loss D: 1.4552\n",
      "epsilon is 9.832916524813415, alpha is 3.2\n",
      "Epoch 161, Loss G: 0.5751, Loss D: 1.4438\n",
      "epsilon is 9.871016847131145, alpha is 3.1\n",
      "Epoch 162, Loss G: 0.5799, Loss D: 1.4512\n",
      "epsilon is 9.908012332703517, alpha is 3.1\n",
      "Epoch 163, Loss G: 0.5725, Loss D: 1.4488\n",
      "epsilon is 9.94500781827589, alpha is 3.1\n",
      "Epoch 164, Loss G: 0.5762, Loss D: 1.4466\n",
      "epsilon is 9.982003303848263, alpha is 3.1\n",
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 115.4473 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 927 rows (same as raw) in 0.4688 sec.\n",
      "Sync data as ...\n",
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0  3.663019   0.997224  4.606915   0.747578         2.269901        0.984679   \n",
      "\n",
      "   occupation  relationship      race    gender  capital-gain  capital-loss  \\\n",
      "0    0.990903       0.95497  0.806221  0.997782     -0.159918     -0.219043   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0        2.634771         0.88122  0.993726  \n",
      "         age    workclass         fnlwgt education  educational-num  \\\n",
      "0  88.295354  Federal-gov  647932.096102   Masters        15.972689   \n",
      "\n",
      "  marital-status       occupation relationship   race  gender  capital-gain  \\\n",
      "0        Widowed  Protective-serv         Wife  White  Female           0.0   \n",
      "\n",
      "   capital-loss  hours-per-week native-country income  \n",
      "0           0.0       72.657481  United-States   >50K  \n"
     ]
    }
   ],
   "source": [
    "issue332_gan(\n",
    "        load = load,\n",
    "        synthesizing_method = 'smartnoise-dpctgan',\n",
    "        outlier_inhibit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preproc config of Outlier before update as ...\n",
      "{'age': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F485D4CB20>,\n",
      " 'capital-gain': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F485D4C100>,\n",
      " 'capital-loss': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F485D4C2B0>,\n",
      " 'education': None,\n",
      " 'educational-num': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F485D4DFF0>,\n",
      " 'fnlwgt': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F485D4D480>,\n",
      " 'gender': None,\n",
      " 'hours-per-week': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F485D4C670>,\n",
      " 'income': None,\n",
      " 'marital-status': None,\n",
      " 'native-country': None,\n",
      " 'occupation': None,\n",
      " 'race': None,\n",
      " 'relationship': None,\n",
      " 'workclass': None}\n",
      "Preproc config of Outlier before after as ...\n",
      "{'age': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F485D4CB20>,\n",
      " 'capital-gain': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F485D4C100>,\n",
      " 'capital-loss': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F485D4C2B0>,\n",
      " 'education': None,\n",
      " 'educational-num': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F485D4DFF0>,\n",
      " 'fnlwgt': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F485D4D480>,\n",
      " 'gender': None,\n",
      " 'hours-per-week': <PETsARD.processor.scaler.ScalerStandard object at 0x000001F485D4C670>,\n",
      " 'income': None,\n",
      " 'marital-status': None,\n",
      " 'native-country': None,\n",
      " 'occupation': None,\n",
      " 'race': None,\n",
      " 'relationship': None,\n",
      " 'workclass': None}\n",
      "Preproc data as ...\n",
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0 -0.953119   0.006814  0.409053   0.780317        -1.152735        0.507641   \n",
      "\n",
      "   occupation  relationship      race    gender  capital-gain  capital-loss  \\\n",
      "0    0.750354      0.787001  0.864054  0.199314     -0.159918     -0.219043   \n",
      "\n",
      "   hours-per-week  native-country   income  \n",
      "0       -0.044504        0.099702  0.61332  \n",
      "Synthesizer (SmartNoise): Fitting patectgan.\n",
      "using loss cross_entropy and regularization None\n",
      "eps: 0.102479 \t G: 0.713781 \t D: 0.716145\n",
      "eps: 0.457732 \t G: 0.713048 \t D: 0.712165\n",
      "eps: 0.650248 \t G: 0.689282 \t D: 0.698435\n",
      "eps: 0.799151 \t G: 0.698342 \t D: 0.710174\n",
      "eps: 0.925562 \t G: 0.716226 \t D: 0.704634\n",
      "eps: 1.037397 \t G: 0.750504 \t D: 0.704282\n",
      "eps: 1.139329 \t G: 0.733702 \t D: 0.708267\n",
      "eps: 1.232819 \t G: 0.742357 \t D: 0.711618\n",
      "eps: 1.320496 \t G: 0.698668 \t D: 0.703252\n",
      "eps: 1.403195 \t G: 0.737517 \t D: 0.699576\n",
      "eps: 1.481995 \t G: 0.681477 \t D: 0.705583\n",
      "eps: 1.556995 \t G: 0.672663 \t D: 0.702600\n",
      "eps: 1.628302 \t G: 0.745140 \t D: 0.694179\n",
      "eps: 1.698302 \t G: 0.690847 \t D: 0.712576\n",
      "eps: 1.763994 \t G: 0.727325 \t D: 0.703433\n",
      "eps: 1.828994 \t G: 0.709237 \t D: 0.703511\n",
      "eps: 1.891630 \t G: 0.708808 \t D: 0.702042\n",
      "eps: 1.951630 \t G: 0.691537 \t D: 0.697599\n",
      "eps: 2.011630 \t G: 0.701870 \t D: 0.706488\n",
      "eps: 2.069793 \t G: 0.688349 \t D: 0.699278\n",
      "eps: 2.124793 \t G: 0.709717 \t D: 0.701455\n",
      "eps: 2.179793 \t G: 0.694322 \t D: 0.691404\n",
      "eps: 2.234793 \t G: 0.686912 \t D: 0.701100\n",
      "eps: 2.288659 \t G: 0.705043 \t D: 0.700311\n",
      "eps: 2.338659 \t G: 0.707292 \t D: 0.703666\n",
      "eps: 2.388659 \t G: 0.694569 \t D: 0.690330\n",
      "eps: 2.438659 \t G: 0.684587 \t D: 0.698427\n",
      "eps: 2.488659 \t G: 0.697387 \t D: 0.699607\n",
      "eps: 2.538659 \t G: 0.687134 \t D: 0.700899\n",
      "eps: 2.585991 \t G: 0.693586 \t D: 0.695336\n",
      "eps: 2.630991 \t G: 0.739123 \t D: 0.693745\n",
      "eps: 2.675991 \t G: 0.700363 \t D: 0.697010\n",
      "eps: 2.720991 \t G: 0.689431 \t D: 0.697749\n",
      "eps: 2.765991 \t G: 0.693986 \t D: 0.690283\n",
      "eps: 2.810991 \t G: 0.673590 \t D: 0.695922\n",
      "eps: 2.855991 \t G: 0.671324 \t D: 0.701141\n",
      "eps: 2.900991 \t G: 0.677591 \t D: 0.695007\n",
      "eps: 2.943990 \t G: 0.656642 \t D: 0.694972\n",
      "eps: 2.983990 \t G: 0.723366 \t D: 0.697270\n",
      "eps: 3.023990 \t G: 0.700119 \t D: 0.699537\n",
      "eps: 3.063990 \t G: 0.674124 \t D: 0.694819\n",
      "eps: 3.103990 \t G: 0.686734 \t D: 0.694975\n",
      "eps: 3.143990 \t G: 0.687309 \t D: 0.695707\n",
      "eps: 3.183990 \t G: 0.692782 \t D: 0.692781\n",
      "eps: 3.223990 \t G: 0.714057 \t D: 0.697382\n",
      "eps: 3.263990 \t G: 0.664547 \t D: 0.689004\n",
      "eps: 3.303990 \t G: 0.700300 \t D: 0.702808\n",
      "eps: 3.343990 \t G: 0.707063 \t D: 0.694165\n",
      "eps: 3.383990 \t G: 0.705744 \t D: 0.693704\n",
      "eps: 3.422988 \t G: 0.704281 \t D: 0.697706\n",
      "eps: 3.457988 \t G: 0.691522 \t D: 0.698151\n",
      "eps: 3.492988 \t G: 0.698668 \t D: 0.692005\n",
      "eps: 3.527988 \t G: 0.686467 \t D: 0.699543\n",
      "eps: 3.562988 \t G: 0.684231 \t D: 0.689239\n",
      "eps: 3.597988 \t G: 0.698439 \t D: 0.695944\n",
      "eps: 3.632988 \t G: 0.679470 \t D: 0.694834\n",
      "eps: 3.667988 \t G: 0.685383 \t D: 0.690702\n",
      "eps: 3.702988 \t G: 0.681760 \t D: 0.700023\n",
      "eps: 3.737988 \t G: 0.678823 \t D: 0.693228\n",
      "eps: 3.772988 \t G: 0.688883 \t D: 0.694677\n",
      "eps: 3.807988 \t G: 0.707548 \t D: 0.695333\n",
      "eps: 3.842988 \t G: 0.696041 \t D: 0.689088\n",
      "eps: 3.877988 \t G: 0.679329 \t D: 0.698854\n",
      "eps: 3.912988 \t G: 0.711865 \t D: 0.694357\n",
      "eps: 3.947988 \t G: 0.690228 \t D: 0.692709\n",
      "eps: 3.982988 \t G: 0.698592 \t D: 0.694288\n",
      "eps: 4.017988 \t G: 0.689543 \t D: 0.688812\n",
      "eps: 4.052988 \t G: 0.705020 \t D: 0.691620\n",
      "eps: 4.087988 \t G: 0.688093 \t D: 0.697707\n",
      "eps: 4.119586 \t G: 0.690063 \t D: 0.694527\n",
      "eps: 4.149586 \t G: 0.695651 \t D: 0.690567\n",
      "eps: 4.179586 \t G: 0.705636 \t D: 0.696383\n",
      "eps: 4.209586 \t G: 0.700525 \t D: 0.691312\n",
      "eps: 4.239586 \t G: 0.676271 \t D: 0.694654\n",
      "eps: 4.269586 \t G: 0.688563 \t D: 0.698388\n",
      "eps: 4.299586 \t G: 0.681526 \t D: 0.698504\n",
      "eps: 4.329586 \t G: 0.693433 \t D: 0.692396\n",
      "eps: 4.359586 \t G: 0.678946 \t D: 0.693821\n",
      "eps: 4.389586 \t G: 0.704079 \t D: 0.695138\n",
      "eps: 4.419586 \t G: 0.711130 \t D: 0.693717\n",
      "eps: 4.449586 \t G: 0.692445 \t D: 0.697196\n",
      "eps: 4.479586 \t G: 0.684903 \t D: 0.697392\n",
      "eps: 4.509586 \t G: 0.697194 \t D: 0.697828\n",
      "eps: 4.539586 \t G: 0.687639 \t D: 0.695808\n",
      "eps: 4.569586 \t G: 0.702698 \t D: 0.688421\n",
      "eps: 4.599586 \t G: 0.677394 \t D: 0.691671\n",
      "eps: 4.629586 \t G: 0.676998 \t D: 0.694079\n",
      "eps: 4.659586 \t G: 0.692468 \t D: 0.697231\n",
      "eps: 4.689586 \t G: 0.705954 \t D: 0.693673\n",
      "eps: 4.719586 \t G: 0.714168 \t D: 0.694783\n",
      "eps: 4.749586 \t G: 0.692832 \t D: 0.694862\n",
      "eps: 4.779586 \t G: 0.684127 \t D: 0.696356\n",
      "eps: 4.809586 \t G: 0.697125 \t D: 0.699097\n",
      "eps: 4.839586 \t G: 0.690293 \t D: 0.694361\n",
      "eps: 4.869586 \t G: 0.696844 \t D: 0.697206\n",
      "eps: 4.899586 \t G: 0.696491 \t D: 0.692738\n",
      "eps: 4.929586 \t G: 0.705306 \t D: 0.693927\n",
      "eps: 4.959586 \t G: 0.701349 \t D: 0.694641\n",
      "eps: 4.989586 \t G: 0.716760 \t D: 0.692627\n",
      "eps: 5.019586 \t G: 0.706580 \t D: 0.697327\n",
      "eps: 5.049586 \t G: 0.694923 \t D: 0.694328\n",
      "eps: 5.079586 \t G: 0.683924 \t D: 0.692442\n",
      "eps: 5.109586 \t G: 0.687853 \t D: 0.697842\n",
      "eps: 5.136983 \t G: 0.678175 \t D: 0.694115\n",
      "eps: 5.161983 \t G: 0.687122 \t D: 0.695188\n",
      "eps: 5.186983 \t G: 0.710870 \t D: 0.692395\n",
      "eps: 5.211983 \t G: 0.706316 \t D: 0.697591\n",
      "eps: 5.236983 \t G: 0.694138 \t D: 0.693994\n",
      "eps: 5.261983 \t G: 0.682083 \t D: 0.691040\n",
      "eps: 5.286983 \t G: 0.687905 \t D: 0.694451\n",
      "eps: 5.311983 \t G: 0.673862 \t D: 0.696650\n",
      "eps: 5.336983 \t G: 0.692831 \t D: 0.694289\n",
      "eps: 5.361983 \t G: 0.704120 \t D: 0.693669\n",
      "eps: 5.386983 \t G: 0.704646 \t D: 0.701262\n",
      "eps: 5.411983 \t G: 0.691776 \t D: 0.698044\n",
      "eps: 5.436983 \t G: 0.704596 \t D: 0.698575\n",
      "eps: 5.461983 \t G: 0.692580 \t D: 0.692944\n",
      "eps: 5.486983 \t G: 0.682725 \t D: 0.692538\n",
      "eps: 5.511983 \t G: 0.697214 \t D: 0.694453\n",
      "eps: 5.536983 \t G: 0.710158 \t D: 0.695539\n",
      "eps: 5.561983 \t G: 0.701455 \t D: 0.692305\n",
      "eps: 5.586983 \t G: 0.691797 \t D: 0.697904\n",
      "eps: 5.611983 \t G: 0.690916 \t D: 0.692865\n",
      "eps: 5.636983 \t G: 0.690258 \t D: 0.694387\n",
      "eps: 5.661983 \t G: 0.688663 \t D: 0.691113\n",
      "eps: 5.686983 \t G: 0.662851 \t D: 0.692329\n",
      "eps: 5.711983 \t G: 0.688278 \t D: 0.694166\n",
      "eps: 5.736983 \t G: 0.686217 \t D: 0.695744\n",
      "eps: 5.761983 \t G: 0.691149 \t D: 0.697361\n",
      "eps: 5.786983 \t G: 0.688824 \t D: 0.698891\n",
      "eps: 5.811983 \t G: 0.693033 \t D: 0.696105\n",
      "eps: 5.836983 \t G: 0.696277 \t D: 0.693473\n",
      "eps: 5.861983 \t G: 0.693802 \t D: 0.693498\n",
      "eps: 5.886983 \t G: 0.714150 \t D: 0.696003\n",
      "eps: 5.911983 \t G: 0.721983 \t D: 0.694278\n",
      "eps: 5.936983 \t G: 0.725168 \t D: 0.690415\n",
      "eps: 5.961983 \t G: 0.726327 \t D: 0.691595\n",
      "eps: 5.986983 \t G: 0.721982 \t D: 0.697985\n",
      "eps: 6.011982 \t G: 0.689813 \t D: 0.698034\n",
      "eps: 6.036982 \t G: 0.670720 \t D: 0.697906\n",
      "eps: 6.061982 \t G: 0.676116 \t D: 0.692406\n",
      "eps: 6.086982 \t G: 0.668123 \t D: 0.695680\n",
      "eps: 6.111982 \t G: 0.690715 \t D: 0.698138\n",
      "eps: 6.136982 \t G: 0.698641 \t D: 0.700861\n",
      "eps: 6.161982 \t G: 0.694157 \t D: 0.697574\n",
      "eps: 6.186982 \t G: 0.711598 \t D: 0.694706\n",
      "eps: 6.211982 \t G: 0.706662 \t D: 0.698498\n",
      "eps: 6.236982 \t G: 0.695758 \t D: 0.695270\n",
      "eps: 6.261982 \t G: 0.712754 \t D: 0.695887\n",
      "eps: 6.286982 \t G: 0.710169 \t D: 0.694539\n",
      "eps: 6.311982 \t G: 0.707389 \t D: 0.691145\n",
      "eps: 6.336982 \t G: 0.697499 \t D: 0.699215\n",
      "eps: 6.361982 \t G: 0.688263 \t D: 0.693412\n",
      "eps: 6.386982 \t G: 0.692656 \t D: 0.692965\n",
      "eps: 6.411982 \t G: 0.677513 \t D: 0.692228\n",
      "eps: 6.436982 \t G: 0.690053 \t D: 0.696777\n",
      "eps: 6.461982 \t G: 0.684045 \t D: 0.694823\n",
      "eps: 6.486982 \t G: 0.693844 \t D: 0.696127\n",
      "eps: 6.511982 \t G: 0.717999 \t D: 0.698269\n",
      "eps: 6.536982 \t G: 0.701669 \t D: 0.697028\n",
      "eps: 6.561982 \t G: 0.706614 \t D: 0.693551\n",
      "eps: 6.586982 \t G: 0.690939 \t D: 0.692773\n",
      "eps: 6.611982 \t G: 0.678489 \t D: 0.697274\n",
      "eps: 6.636982 \t G: 0.696240 \t D: 0.693872\n",
      "eps: 6.661982 \t G: 0.691522 \t D: 0.693280\n",
      "eps: 6.686982 \t G: 0.700351 \t D: 0.691683\n",
      "eps: 6.711982 \t G: 0.702936 \t D: 0.694047\n",
      "eps: 6.736982 \t G: 0.701172 \t D: 0.696587\n",
      "eps: 6.761982 \t G: 0.709572 \t D: 0.694403\n",
      "eps: 6.786982 \t G: 0.693866 \t D: 0.697633\n",
      "eps: 6.811982 \t G: 0.689262 \t D: 0.695713\n",
      "eps: 6.835977 \t G: 0.706019 \t D: 0.693791\n",
      "eps: 6.855977 \t G: 0.713628 \t D: 0.694795\n",
      "eps: 6.875977 \t G: 0.686985 \t D: 0.694983\n",
      "eps: 6.895977 \t G: 0.678707 \t D: 0.696975\n",
      "eps: 6.915977 \t G: 0.688420 \t D: 0.691135\n",
      "eps: 6.935977 \t G: 0.691864 \t D: 0.696182\n",
      "eps: 6.955977 \t G: 0.713413 \t D: 0.698038\n",
      "eps: 6.975977 \t G: 0.708330 \t D: 0.694529\n",
      "eps: 6.995977 \t G: 0.701740 \t D: 0.700547\n",
      "eps: 7.015977 \t G: 0.696532 \t D: 0.694873\n",
      "eps: 7.035977 \t G: 0.721527 \t D: 0.693872\n",
      "eps: 7.055977 \t G: 0.711696 \t D: 0.694538\n",
      "eps: 7.075977 \t G: 0.701369 \t D: 0.694573\n",
      "eps: 7.095977 \t G: 0.710693 \t D: 0.690452\n",
      "eps: 7.115977 \t G: 0.714807 \t D: 0.695867\n",
      "eps: 7.135977 \t G: 0.703928 \t D: 0.697142\n",
      "eps: 7.155977 \t G: 0.697978 \t D: 0.697099\n",
      "eps: 7.175977 \t G: 0.711146 \t D: 0.691293\n",
      "eps: 7.195977 \t G: 0.689744 \t D: 0.693730\n",
      "eps: 7.215977 \t G: 0.679122 \t D: 0.697585\n",
      "eps: 7.235977 \t G: 0.665163 \t D: 0.687304\n",
      "eps: 7.255977 \t G: 0.688261 \t D: 0.694644\n",
      "eps: 7.275977 \t G: 0.700061 \t D: 0.698768\n",
      "eps: 7.295977 \t G: 0.722397 \t D: 0.694110\n",
      "eps: 7.315977 \t G: 0.706579 \t D: 0.697697\n",
      "eps: 7.335977 \t G: 0.698369 \t D: 0.693160\n",
      "eps: 7.355977 \t G: 0.707676 \t D: 0.699921\n",
      "eps: 7.375977 \t G: 0.699110 \t D: 0.693009\n",
      "eps: 7.395977 \t G: 0.693671 \t D: 0.700002\n",
      "eps: 7.415977 \t G: 0.702207 \t D: 0.699121\n",
      "eps: 7.435977 \t G: 0.690763 \t D: 0.697587\n",
      "eps: 7.455977 \t G: 0.693543 \t D: 0.693346\n",
      "eps: 7.475977 \t G: 0.690964 \t D: 0.698946\n",
      "eps: 7.495977 \t G: 0.691772 \t D: 0.694487\n",
      "eps: 7.515977 \t G: 0.696903 \t D: 0.696523\n",
      "eps: 7.535977 \t G: 0.714085 \t D: 0.693842\n",
      "eps: 7.555977 \t G: 0.705241 \t D: 0.693571\n",
      "eps: 7.575977 \t G: 0.710959 \t D: 0.693134\n",
      "eps: 7.595977 \t G: 0.695932 \t D: 0.693888\n",
      "eps: 7.615977 \t G: 0.688465 \t D: 0.691797\n",
      "eps: 7.635977 \t G: 0.687585 \t D: 0.696887\n",
      "eps: 7.655977 \t G: 0.692846 \t D: 0.695367\n",
      "eps: 7.675977 \t G: 0.689350 \t D: 0.694941\n",
      "eps: 7.695977 \t G: 0.695852 \t D: 0.697276\n",
      "eps: 7.715977 \t G: 0.702350 \t D: 0.693447\n",
      "eps: 7.735977 \t G: 0.695321 \t D: 0.690365\n",
      "eps: 7.755977 \t G: 0.680467 \t D: 0.698033\n",
      "eps: 7.775977 \t G: 0.687057 \t D: 0.692665\n",
      "eps: 7.795977 \t G: 0.700203 \t D: 0.695803\n",
      "eps: 7.815977 \t G: 0.715794 \t D: 0.696600\n",
      "eps: 7.835977 \t G: 0.703528 \t D: 0.698830\n",
      "eps: 7.855977 \t G: 0.725885 \t D: 0.697341\n",
      "eps: 7.875977 \t G: 0.682234 \t D: 0.698131\n",
      "eps: 7.895977 \t G: 0.677728 \t D: 0.693323\n",
      "eps: 7.915977 \t G: 0.681669 \t D: 0.698836\n",
      "eps: 7.935977 \t G: 0.692163 \t D: 0.699217\n",
      "eps: 7.955977 \t G: 0.683420 \t D: 0.693969\n",
      "eps: 7.975977 \t G: 0.692033 \t D: 0.694492\n",
      "eps: 7.995977 \t G: 0.728577 \t D: 0.700214\n",
      "eps: 8.015977 \t G: 0.728052 \t D: 0.693331\n",
      "eps: 8.035977 \t G: 0.730739 \t D: 0.694320\n",
      "eps: 8.055977 \t G: 0.719204 \t D: 0.696886\n",
      "eps: 8.075977 \t G: 0.708894 \t D: 0.694114\n",
      "eps: 8.095977 \t G: 0.697646 \t D: 0.696363\n",
      "eps: 8.115977 \t G: 0.692623 \t D: 0.691135\n",
      "eps: 8.135977 \t G: 0.677301 \t D: 0.695693\n",
      "eps: 8.155977 \t G: 0.690436 \t D: 0.695203\n",
      "eps: 8.175977 \t G: 0.716764 \t D: 0.693985\n",
      "eps: 8.195977 \t G: 0.708261 \t D: 0.691021\n",
      "eps: 8.215977 \t G: 0.697452 \t D: 0.693978\n",
      "eps: 8.235977 \t G: 0.693953 \t D: 0.697357\n",
      "eps: 8.255977 \t G: 0.701943 \t D: 0.694999\n",
      "eps: 8.275977 \t G: 0.701976 \t D: 0.696045\n",
      "eps: 8.295977 \t G: 0.679231 \t D: 0.692849\n",
      "eps: 8.315977 \t G: 0.687471 \t D: 0.695532\n",
      "eps: 8.335977 \t G: 0.688215 \t D: 0.695305\n",
      "eps: 8.355977 \t G: 0.684386 \t D: 0.697067\n",
      "eps: 8.375977 \t G: 0.682844 \t D: 0.694733\n",
      "eps: 8.395977 \t G: 0.706065 \t D: 0.696155\n",
      "eps: 8.415977 \t G: 0.699171 \t D: 0.698522\n",
      "eps: 8.435977 \t G: 0.694558 \t D: 0.695058\n",
      "eps: 8.455977 \t G: 0.698595 \t D: 0.695299\n",
      "eps: 8.475977 \t G: 0.702856 \t D: 0.694437\n",
      "eps: 8.495977 \t G: 0.693910 \t D: 0.699749\n",
      "eps: 8.515977 \t G: 0.688224 \t D: 0.694186\n",
      "eps: 8.535977 \t G: 0.688795 \t D: 0.695863\n",
      "eps: 8.555977 \t G: 0.705883 \t D: 0.694558\n",
      "eps: 8.575977 \t G: 0.724274 \t D: 0.696720\n",
      "eps: 8.595977 \t G: 0.718322 \t D: 0.692502\n",
      "eps: 8.615977 \t G: 0.709645 \t D: 0.694721\n",
      "eps: 8.635977 \t G: 0.708987 \t D: 0.696772\n",
      "eps: 8.655977 \t G: 0.701214 \t D: 0.692546\n",
      "eps: 8.675977 \t G: 0.711924 \t D: 0.696422\n",
      "eps: 8.695977 \t G: 0.707368 \t D: 0.692554\n",
      "eps: 8.715977 \t G: 0.709598 \t D: 0.695780\n",
      "eps: 8.735977 \t G: 0.680445 \t D: 0.699557\n",
      "eps: 8.755977 \t G: 0.675816 \t D: 0.692951\n",
      "eps: 8.775977 \t G: 0.682221 \t D: 0.692445\n",
      "eps: 8.795977 \t G: 0.707273 \t D: 0.695885\n",
      "eps: 8.815977 \t G: 0.693460 \t D: 0.694252\n",
      "eps: 8.835977 \t G: 0.680995 \t D: 0.695839\n",
      "eps: 8.855977 \t G: 0.670298 \t D: 0.693365\n",
      "eps: 8.875977 \t G: 0.681427 \t D: 0.694136\n",
      "eps: 8.895977 \t G: 0.698069 \t D: 0.697778\n",
      "eps: 8.915977 \t G: 0.701808 \t D: 0.696195\n",
      "eps: 8.935977 \t G: 0.709960 \t D: 0.697699\n",
      "eps: 8.955977 \t G: 0.713283 \t D: 0.696481\n",
      "eps: 8.975977 \t G: 0.702262 \t D: 0.691180\n",
      "eps: 8.995977 \t G: 0.699221 \t D: 0.693380\n",
      "eps: 9.015977 \t G: 0.714084 \t D: 0.695818\n",
      "eps: 9.035977 \t G: 0.699903 \t D: 0.696171\n",
      "eps: 9.055977 \t G: 0.697011 \t D: 0.696874\n",
      "eps: 9.075977 \t G: 0.708921 \t D: 0.691218\n",
      "eps: 9.095977 \t G: 0.714847 \t D: 0.692894\n",
      "eps: 9.115977 \t G: 0.700553 \t D: 0.697870\n",
      "eps: 9.135977 \t G: 0.704466 \t D: 0.692195\n",
      "eps: 9.155977 \t G: 0.716214 \t D: 0.693401\n",
      "eps: 9.175977 \t G: 0.706705 \t D: 0.694446\n",
      "eps: 9.195977 \t G: 0.690804 \t D: 0.692994\n",
      "eps: 9.215977 \t G: 0.701547 \t D: 0.694552\n",
      "eps: 9.235977 \t G: 0.715766 \t D: 0.697340\n",
      "eps: 9.255977 \t G: 0.694500 \t D: 0.699202\n",
      "eps: 9.275977 \t G: 0.686139 \t D: 0.694071\n",
      "eps: 9.295977 \t G: 0.715559 \t D: 0.691591\n",
      "eps: 9.315977 \t G: 0.721473 \t D: 0.694705\n",
      "eps: 9.335977 \t G: 0.699836 \t D: 0.700774\n",
      "eps: 9.355977 \t G: 0.689537 \t D: 0.690166\n",
      "eps: 9.375977 \t G: 0.693082 \t D: 0.695173\n",
      "eps: 9.395977 \t G: 0.694534 \t D: 0.695173\n",
      "eps: 9.415977 \t G: 0.700059 \t D: 0.698420\n",
      "eps: 9.435977 \t G: 0.698749 \t D: 0.692723\n",
      "eps: 9.455977 \t G: 0.691733 \t D: 0.695272\n",
      "eps: 9.475977 \t G: 0.711630 \t D: 0.693643\n",
      "eps: 9.495977 \t G: 0.706853 \t D: 0.691853\n",
      "eps: 9.515977 \t G: 0.696636 \t D: 0.691733\n",
      "eps: 9.535977 \t G: 0.696215 \t D: 0.696250\n",
      "eps: 9.555977 \t G: 0.702907 \t D: 0.691832\n",
      "eps: 9.575977 \t G: 0.714041 \t D: 0.695757\n",
      "eps: 9.595977 \t G: 0.697746 \t D: 0.694564\n",
      "eps: 9.615977 \t G: 0.702878 \t D: 0.693213\n",
      "eps: 9.635977 \t G: 0.731086 \t D: 0.699579\n",
      "eps: 9.655977 \t G: 0.707542 \t D: 0.695599\n",
      "eps: 9.675977 \t G: 0.690351 \t D: 0.696782\n",
      "eps: 9.695977 \t G: 0.712726 \t D: 0.693319\n",
      "eps: 9.715977 \t G: 0.713519 \t D: 0.690887\n",
      "eps: 9.735977 \t G: 0.709094 \t D: 0.701579\n",
      "eps: 9.755977 \t G: 0.694409 \t D: 0.693226\n",
      "eps: 9.775977 \t G: 0.703121 \t D: 0.693624\n",
      "eps: 9.795977 \t G: 0.684308 \t D: 0.692475\n",
      "eps: 9.815977 \t G: 0.684525 \t D: 0.695275\n",
      "eps: 9.835977 \t G: 0.681902 \t D: 0.697289\n",
      "eps: 9.855977 \t G: 0.686178 \t D: 0.692194\n",
      "eps: 9.875977 \t G: 0.687372 \t D: 0.696504\n",
      "eps: 9.895977 \t G: 0.690510 \t D: 0.691553\n",
      "eps: 9.915977 \t G: 0.699482 \t D: 0.692439\n",
      "eps: 9.935977 \t G: 0.695582 \t D: 0.696715\n",
      "eps: 9.955977 \t G: 0.701558 \t D: 0.694982\n",
      "eps: 9.975977 \t G: 0.731646 \t D: 0.697401\n",
      "eps: 9.995977 \t G: 0.709171 \t D: 0.694371\n",
      "Synthesizer (SmartNoise): Fitting  patectgan spent 93.3619 sec.\n",
      "Synthesizer (SmartNoise): Sampling patectgan # 927 rows (same as raw) in 0.1432 sec.\n",
      "Sync data as ...\n",
      "       age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0  0.24186   0.103012  1.088126   0.554129         0.519998        0.581233   \n",
      "\n",
      "   occupation  relationship      race    gender  capital-gain  capital-loss  \\\n",
      "0    0.236864      0.475109  0.705326  0.676615      0.890221     -0.115185   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0         1.13638        0.654151  0.748044  \n",
      "         age workclass        fnlwgt  education  educational-num  \\\n",
      "0  41.385254   Private  294926.71711  Bachelors        11.385191   \n",
      "\n",
      "  marital-status      occupation   relationship   race gender  capital-gain  \\\n",
      "0  Never-married  Prof-specialty  Not-in-family  White   Male   9733.339667   \n",
      "\n",
      "   capital-loss  hours-per-week native-country income  \n",
      "0     41.004116       54.393705  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "issue332_gan(\n",
    "        load = load,\n",
    "        synthesizing_method = 'smartnoise-patectgan',\n",
    "        outlier_inhibit = True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
