{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setting / ç’°å¢ƒè¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Current working directory: demo/petsard-yaml/evaluator-yaml\n",
      "âœ… PETsARD demo_utils loaded. Use quick_setup() to initialize.\n"
     ]
    }
   ],
   "source": [
    "import os  # noqa: I001\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Handle utils.py for Colab\n",
    "if \"COLAB_GPU\" in os.environ:\n",
    "    import urllib.request\n",
    "\n",
    "    demo_utils_url = (\n",
    "        \"https://raw.githubusercontent.com/nics-tw/petsard/main/demo/demo_utils.py\"\n",
    "    )\n",
    "    # Download and save to local file for proper import\n",
    "    content = urllib.request.urlopen(demo_utils_url).read().decode(\"utf-8\")\n",
    "    with open(\"demo_utils.py\", \"w\") as f:\n",
    "        f.write(content)\n",
    "else:\n",
    "    # demo_utils.py search for local\n",
    "    for p in [Path.cwd()] + list(Path.cwd().parents)[:10]:\n",
    "        utils_path = p / \"demo_utils.py\"\n",
    "        if utils_path.exists() and \"demo\" in str(utils_path):\n",
    "            sys.path.insert(0, str(p))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick setup / å¿«é€Ÿè¨­å®š: Evaluation YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Changed working directory to demo: petsard/demo\n",
      "   ğŸ“ Notebook location: demo/petsard-yaml/evaluator-yaml/\n",
      "   ğŸ” YAML search priority: \n",
      "      1. demo/petsard-yaml/evaluator-yaml/\n",
      "      2. demo/\n",
      "   ğŸ’¾ Output files will be saved in: demo/\n",
      "ğŸš€ PETsARD v1.8.0\n",
      "ğŸ“… 2025-10-18 19:48:36 UTC+8\n",
      "ğŸ”§ Added to Python path: petsard/demo/petsard-yaml/evaluator-yaml\n",
      "ğŸ“ Processing configuration files from subfolder: petsard-yaml/evaluator-yaml\n",
      "âœ… Found configuration (1/2): petsard/demo/petsard-yaml/evaluator-yaml/evaluator-data-release.yaml\n",
      "âœ… Found configuration (2/2): petsard/demo/petsard-yaml/evaluator-yaml/evaluator-specific-task-application.yaml\n"
     ]
    }
   ],
   "source": [
    "from demo_utils import display_results, display_yaml_info, quick_setup  # noqa: I001\n",
    "from petsard import Executor  # noqa: I001\n",
    "\n",
    "\n",
    "is_colab, branch, yaml_path = quick_setup(\n",
    "    config_file=[\n",
    "        \"evaluator-data-release.yaml\",\n",
    "        \"evaluator-specific-task-application.yaml\",\n",
    "    ],\n",
    "    benchmark_data=None,\n",
    "    petsard_branch=\"main\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution and Result / åŸ·è¡Œèˆ‡çµæœ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended Evaluation Workflow: Data Release / å»ºè­°è©•ä¼°æµç¨‹ï¼šè³‡æ–™é‡‹å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“‹ YAML Configuration Files / YAML è¨­å®šæª”æ¡ˆ\n",
      "============================================================\n",
      "\n",
      "ğŸ“„ File: evaluator-data-release.yaml\n",
      "ğŸ“ Path: petsard/demo/petsard-yaml/evaluator-yaml/evaluator-data-release.yaml\n",
      "\n",
      "âš™ï¸ Configuration content / è¨­å®šå…§å®¹:\n",
      "----------------------------------------\n",
      "---\n",
      "Splitter:\n",
      "  external_split:\n",
      "    method: custom_data\n",
      "    filepath:\n",
      "      ori: benchmark://adult-income_ori\n",
      "      control: benchmark://adult-income_control\n",
      "    schema:\n",
      "      ori: benchmark://adult-income_schema\n",
      "      control: benchmark://adult-income_schema\n",
      "Synthesizer:\n",
      "  external_data:\n",
      "    method: custom_data\n",
      "    filepath: benchmark://adult-income_syn\n",
      "    schema: benchmark://adult-income_schema\n",
      "Evaluator:\n",
      "  # Step 1: Data validity diagnosis (should be close to 1.0)\n",
      "  validity_check:\n",
      "    method: sdmetrics-diagnosticreport\n",
      "  # Step 2: Privacy protection assessment (risk should be < 0.09)\n",
      "  singling_out_risk:\n",
      "    method: anonymeter-singlingout\n",
      "    n_attacks: 400\n",
      "    max_attempts: 4000\n",
      "  linkability_risk:\n",
      "    method: anonymeter-linkability\n",
      "    aux_cols:\n",
      "      -\n",
      "        - workclass\n",
      "        - education\n",
      "        - occupation\n",
      "        - race\n",
      "        - gender\n",
      "      -\n",
      "        - age\n",
      "        - marital-status\n",
      "        - relationship\n",
      "        - native-country\n",
      "        - income\n",
      "  inference_risk:\n",
      "    method: anonymeter-inference\n",
      "    secret: income\n",
      "  # Focus: Pursue high fidelity (higher score is better)\n",
      "  fidelity_assessment:\n",
      "    method: sdmetrics-qualityreport\n",
      "  # Utility evaluation is optional (not necessary)\n",
      "...\n",
      "============================================================\n",
      "Generating report ...\n",
      "\n",
      "(1/2) Evaluating Data Validity: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 335.15it/s]|\n",
      "Data Validity Score: 100.0%\n",
      "\n",
      "(2/2) Evaluating Data Structure: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 412.54it/s]|\n",
      "Data Structure Score: 100.0%\n",
      "\n",
      "Overall Score (Average): 100.0%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 329 failed queries out of 400. Check DEBUG messages for more details.\n",
      "Reached maximum number of attempts 4000 when generating singling out queries. Returning 0 instead of the requested 400.To avoid this, increase the number of attempts or set it to ``None`` to disable The limitation entirely.\n",
      "Attack `multivariate` could generate only 0 singling out queries out of the requested 400. This can probably lead to an underestimate of the singling out risk.\n",
      "/Users/justyn.chen/Library/CloudStorage/Dropbox/5_Career å·¥ä½œ/20231016_NICS è³‡å®‰é™¢/3_å·¥è—ï¼šPETsARD/petsard/.venv/lib/python3.11/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.004756147167148254, baseline = 0.004756147167148254. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "\n",
      "(1/2) Evaluating Column Shapes: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 52.78it/s]|\n",
      "Column Shapes Score: 95.27%\n",
      "\n",
      "(2/2) Evaluating Column Pair Trends: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 162.60it/s]|\n",
      "Column Pair Trends Score: 61.56%\n",
      "\n",
      "Overall Score (Average): 78.42%\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Execution Results / åŸ·è¡Œçµæœ\n",
      "================================================================================\n",
      "\n",
      "[1] Splitter[external_split_[1-1]]_Synthesizer[external_data]_Evaluator[validity_check]\n",
      "------------------------------------------------------------\n",
      "ğŸ“¦ Dictionary with 3 keys / åŒ…å« 3 å€‹éµçš„å­—å…¸\n",
      "\n",
      "  â€¢ global: DataFrame (1 rows Ã— 3 columns)\n",
      "    ğŸ“‹ Showing first 1 rows / é¡¯ç¤ºå‰ 1 è¡Œ:\n",
      "            Score  Data Validity  Data Structure\n",
      "    result    1.0            1.0             1.0\n",
      "    ğŸ“ Columns / æ¬„ä½: Score, Data Validity, Data Structure\n",
      "\n",
      "  â€¢ columnwise: DataFrame (15 rows Ã— 3 columns)\n",
      "    ğŸ“‹ Showing first 3 rows / é¡¯ç¤ºå‰ 3 è¡Œ:\n",
      "                    Property             Metric  Score\n",
      "    age        Data Validity  BoundaryAdherence    1.0\n",
      "    workclass  Data Validity  CategoryAdherence    1.0\n",
      "    fnlwgt     Data Validity  BoundaryAdherence    1.0\n",
      "    ... (12 more rows) / ... (é‚„æœ‰ 12 è¡Œ)\n",
      "    ğŸ“ Columns / æ¬„ä½: Property, Metric, Score\n",
      "  â€¢ pairwise: NoneType\n",
      "\n",
      "[2] Splitter[external_split_[1-1]]_Synthesizer[external_data]_Evaluator[singling_out_risk]\n",
      "------------------------------------------------------------\n",
      "ğŸ“¦ Dictionary with 2 keys / åŒ…å« 2 å€‹éµçš„å­—å…¸\n",
      "\n",
      "  â€¢ global: DataFrame (1 rows Ã— 9 columns)\n",
      "    ğŸ“‹ Showing first 1 rows / é¡¯ç¤ºå‰ 1 è¡Œ:\n",
      "            risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  baseline_rate  baseline_rate_err  control_rate  control_rate_err\n",
      "    result   0.0          0.0         0.01          0.0              0.0            0.0                0.0           0.0               0.0\n",
      "    ğŸ“ Columns / æ¬„ä½: risk, risk_CI_btm, risk_CI_top, attack_rate, attack_rate_err, baseline_rate, baseline_rate_err, control_rate, control_rate_err\n",
      "  â€¢ details: dict\n",
      "\n",
      "[3] Splitter[external_split_[1-1]]_Synthesizer[external_data]_Evaluator[linkability_risk]\n",
      "------------------------------------------------------------\n",
      "ğŸ“¦ Dictionary with 2 keys / åŒ…å« 2 å€‹éµçš„å­—å…¸\n",
      "\n",
      "  â€¢ global: DataFrame (1 rows Ã— 9 columns)\n",
      "    ğŸ“‹ Showing first 1 rows / é¡¯ç¤ºå‰ 1 è¡Œ:\n",
      "            risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  baseline_rate  baseline_rate_err  control_rate  control_rate_err\n",
      "    result   0.0          0.0          0.0          0.0              0.0            0.0                0.0           0.0               0.0\n",
      "    ğŸ“ Columns / æ¬„ä½: risk, risk_CI_btm, risk_CI_top, attack_rate, attack_rate_err, baseline_rate, baseline_rate_err, control_rate, control_rate_err\n",
      "  â€¢ details: dict\n",
      "\n",
      "[4] Splitter[external_split_[1-1]]_Synthesizer[external_data]_Evaluator[inference_risk]\n",
      "------------------------------------------------------------\n",
      "ğŸ“¦ Dictionary with 2 keys / åŒ…å« 2 å€‹éµçš„å­—å…¸\n",
      "\n",
      "  â€¢ global: DataFrame (1 rows Ã— 9 columns)\n",
      "    ğŸ“‹ Showing first 1 rows / é¡¯ç¤ºå‰ 1 è¡Œ:\n",
      "            risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  baseline_rate  baseline_rate_err  control_rate  control_rate_err\n",
      "    result  0.02          0.0         0.06          0.7             0.01           0.64               0.01           0.7              0.01\n",
      "    ğŸ“ Columns / æ¬„ä½: risk, risk_CI_btm, risk_CI_top, attack_rate, attack_rate_err, baseline_rate, baseline_rate_err, control_rate, control_rate_err\n",
      "  â€¢ details: NoneType\n",
      "\n",
      "[5] Splitter[external_split_[1-1]]_Synthesizer[external_data]_Evaluator[fidelity_assessment]\n",
      "------------------------------------------------------------\n",
      "ğŸ“¦ Dictionary with 3 keys / åŒ…å« 3 å€‹éµçš„å­—å…¸\n",
      "\n",
      "  â€¢ global: DataFrame (1 rows Ã— 3 columns)\n",
      "    ğŸ“‹ Showing first 1 rows / é¡¯ç¤ºå‰ 1 è¡Œ:\n",
      "            Score  Column Shapes  Column Pair Trends\n",
      "    result   0.78           0.95                0.62\n",
      "    ğŸ“ Columns / æ¬„ä½: Score, Column Shapes, Column Pair Trends\n",
      "\n",
      "  â€¢ columnwise: DataFrame (15 rows Ã— 3 columns)\n",
      "    ğŸ“‹ Showing first 3 rows / é¡¯ç¤ºå‰ 3 è¡Œ:\n",
      "                    Property        Metric     Score\n",
      "    age        Column Shapes  KSComplement  0.962276\n",
      "    workclass  Column Shapes  TVComplement  0.986860\n",
      "    fnlwgt     Column Shapes  KSComplement  0.957951\n",
      "    ... (12 more rows) / ... (é‚„æœ‰ 12 è¡Œ)\n",
      "    ğŸ“ Columns / æ¬„ä½: Property, Metric, Score\n",
      "\n",
      "  â€¢ pairwise: DataFrame (105 rows Ã— 6 columns)\n",
      "    ğŸ“‹ Showing first 3 rows / é¡¯ç¤ºå‰ 3 è¡Œ:\n",
      "                             Property                 Metric     Score  Real Correlation  Synthetic Correlation Error\n",
      "    age workclass  Column Pair Trends  ContingencySimilarity  0.869526               NaN                    NaN  None\n",
      "        fnlwgt     Column Pair Trends  CorrelationSimilarity  0.991312         -0.074923              -0.057548  None\n",
      "        education  Column Pair Trends  ContingencySimilarity  0.841399               NaN                    NaN  None\n",
      "    ... (102 more rows) / ... (é‚„æœ‰ 102 è¡Œ)\n",
      "    ğŸ“ Columns / æ¬„ä½: Property, Metric, Score, Real Correlation, Synthetic Correlation, Error\n",
      "\n",
      "================================================================================\n",
      "âœ… Total results / ç¸½çµæœæ•¸: 5\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "display_yaml_info(yaml_path[0])\n",
    "exec_now = Executor(yaml_path[0])\n",
    "exec_now.run()\n",
    "display_results(exec_now.get_result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended Evaluation Workflow: Specific Task Application / å»ºè­°è©•ä¼°æµç¨‹ï¼šç‰¹å®šä»»å‹™æ‡‰ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“‹ YAML Configuration Files / YAML è¨­å®šæª”æ¡ˆ\n",
      "============================================================\n",
      "\n",
      "ğŸ“„ File: evaluator-specific-task-application.yaml\n",
      "ğŸ“ Path: petsard/demo/petsard-yaml/evaluator-yaml/evaluator-specific-task-application.yaml\n",
      "\n",
      "âš™ï¸ Configuration content / è¨­å®šå…§å®¹:\n",
      "----------------------------------------\n",
      "---\n",
      "Splitter:\n",
      "  external_split:\n",
      "    method: custom_data\n",
      "    filepath:\n",
      "      ori: benchmark://adult-income_ori\n",
      "      control: benchmark://adult-income_control\n",
      "    schema:\n",
      "      ori: benchmark://adult-income_schema\n",
      "      control: benchmark://adult-income_schema\n",
      "Synthesizer:\n",
      "  external_data:\n",
      "    method: custom_data\n",
      "    filepath: benchmark://adult-income_syn\n",
      "    schema: benchmark://adult-income_schema\n",
      "Evaluator:\n",
      "  # Step 1: Data validity diagnosis (should be close to 1.0)\n",
      "  validity_check:\n",
      "    method: sdmetrics-diagnosticreport\n",
      "  # Step 2: Privacy protection assessment (risk should be < 0.09)\n",
      "  singling_out_risk:\n",
      "    method: anonymeter-singlingout\n",
      "    n_attacks: 400\n",
      "    max_attempts: 4000\n",
      "  linkability_risk:\n",
      "    method: anonymeter-linkability\n",
      "    aux_cols:\n",
      "      -\n",
      "        - workclass\n",
      "        - education\n",
      "        - occupation\n",
      "        - race\n",
      "        - gender\n",
      "      -\n",
      "        - age\n",
      "        - marital-status\n",
      "        - relationship\n",
      "        - native-country\n",
      "        - income\n",
      "  inference_risk:\n",
      "    method: anonymeter-inference\n",
      "    secret: income\n",
      "  # Fidelity just needs to meet threshold (â‰¥ 0.75)\n",
      "  fidelity_assessment:\n",
      "    method: sdmetrics-qualityreport\n",
      "  # Focus: Pursue high utility (evaluate by task type)\n",
      "  ml_utility_assessment:\n",
      "    method: mlutility\n",
      "    task_type: classification\n",
      "    target: income\n",
      "...\n",
      "============================================================\n",
      "Generating report ...\n",
      "\n",
      "(1/2) Evaluating Data Validity: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 408.54it/s]|\n",
      "Data Validity Score: 100.0%\n",
      "\n",
      "(2/2) Evaluating Data Structure: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 615.81it/s]|\n",
      "Data Structure Score: 100.0%\n",
      "\n",
      "Overall Score (Average): 100.0%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 323 failed queries out of 400. Check DEBUG messages for more details.\n",
      "Reached maximum number of attempts 4000 when generating singling out queries. Returning 2 instead of the requested 400.To avoid this, increase the number of attempts or set it to ``None`` to disable The limitation entirely.\n",
      "Attack `multivariate` could generate only 2 singling out queries out of the requested 400. This can probably lead to an underestimate of the singling out risk.\n",
      "/Users/justyn.chen/Library/CloudStorage/Dropbox/5_Career å·¥ä½œ/20231016_NICS è³‡å®‰é™¢/3_å·¥è—ï¼šPETsARD/petsard/.venv/lib/python3.11/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.004756147167148254, baseline = 0.007232366431312513. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n",
      "/Users/justyn.chen/Library/CloudStorage/Dropbox/5_Career å·¥ä½œ/20231016_NICS è³‡å®‰é™¢/3_å·¥è—ï¼šPETsARD/petsard/.venv/lib/python3.11/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.00019653745724212745, baseline = 0.00019653745724212745. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "\n",
      "(1/2) Evaluating Column Shapes: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 70.08it/s]|\n",
      "Column Shapes Score: 95.27%\n",
      "\n",
      "(2/2) Evaluating Column Pair Trends: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 172.99it/s]|\n",
      "Column Pair Trends Score: 61.56%\n",
      "\n",
      "Overall Score (Average): 78.42%\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Execution Results / åŸ·è¡Œçµæœ\n",
      "================================================================================\n",
      "\n",
      "[1] Splitter[external_split_[1-1]]_Synthesizer[external_data]_Evaluator[validity_check]\n",
      "------------------------------------------------------------\n",
      "ğŸ“¦ Dictionary with 3 keys / åŒ…å« 3 å€‹éµçš„å­—å…¸\n",
      "\n",
      "  â€¢ global: DataFrame (1 rows Ã— 3 columns)\n",
      "    ğŸ“‹ Showing first 1 rows / é¡¯ç¤ºå‰ 1 è¡Œ:\n",
      "            Score  Data Validity  Data Structure\n",
      "    result    1.0            1.0             1.0\n",
      "    ğŸ“ Columns / æ¬„ä½: Score, Data Validity, Data Structure\n",
      "\n",
      "  â€¢ columnwise: DataFrame (15 rows Ã— 3 columns)\n",
      "    ğŸ“‹ Showing first 3 rows / é¡¯ç¤ºå‰ 3 è¡Œ:\n",
      "                    Property             Metric  Score\n",
      "    age        Data Validity  BoundaryAdherence    1.0\n",
      "    workclass  Data Validity  CategoryAdherence    1.0\n",
      "    fnlwgt     Data Validity  BoundaryAdherence    1.0\n",
      "    ... (12 more rows) / ... (é‚„æœ‰ 12 è¡Œ)\n",
      "    ğŸ“ Columns / æ¬„ä½: Property, Metric, Score\n",
      "  â€¢ pairwise: NoneType\n",
      "\n",
      "[2] Splitter[external_split_[1-1]]_Synthesizer[external_data]_Evaluator[singling_out_risk]\n",
      "------------------------------------------------------------\n",
      "ğŸ“¦ Dictionary with 2 keys / åŒ…å« 2 å€‹éµçš„å­—å…¸\n",
      "\n",
      "  â€¢ global: DataFrame (1 rows Ã— 9 columns)\n",
      "    ğŸ“‹ Showing first 1 rows / é¡¯ç¤ºå‰ 1 è¡Œ:\n",
      "            risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  baseline_rate  baseline_rate_err  control_rate  control_rate_err\n",
      "    result   0.0          0.0         0.01          0.0              0.0           0.01               0.01          0.01              0.01\n",
      "    ğŸ“ Columns / æ¬„ä½: risk, risk_CI_btm, risk_CI_top, attack_rate, attack_rate_err, baseline_rate, baseline_rate_err, control_rate, control_rate_err\n",
      "  â€¢ details: dict\n",
      "\n",
      "[3] Splitter[external_split_[1-1]]_Synthesizer[external_data]_Evaluator[linkability_risk]\n",
      "------------------------------------------------------------\n",
      "ğŸ“¦ Dictionary with 2 keys / åŒ…å« 2 å€‹éµçš„å­—å…¸\n",
      "\n",
      "  â€¢ global: DataFrame (1 rows Ã— 9 columns)\n",
      "    ğŸ“‹ Showing first 1 rows / é¡¯ç¤ºå‰ 1 è¡Œ:\n",
      "            risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  baseline_rate  baseline_rate_err  control_rate  control_rate_err\n",
      "    result   0.0          0.0          0.0          0.0              0.0            0.0                0.0           0.0               0.0\n",
      "    ğŸ“ Columns / æ¬„ä½: risk, risk_CI_btm, risk_CI_top, attack_rate, attack_rate_err, baseline_rate, baseline_rate_err, control_rate, control_rate_err\n",
      "  â€¢ details: dict\n",
      "\n",
      "[4] Splitter[external_split_[1-1]]_Synthesizer[external_data]_Evaluator[inference_risk]\n",
      "------------------------------------------------------------\n",
      "ğŸ“¦ Dictionary with 2 keys / åŒ…å« 2 å€‹éµçš„å­—å…¸\n",
      "\n",
      "  â€¢ global: DataFrame (1 rows Ã— 9 columns)\n",
      "    ğŸ“‹ Showing first 1 rows / é¡¯ç¤ºå‰ 1 è¡Œ:\n",
      "            risk  risk_CI_btm  risk_CI_top  attack_rate  attack_rate_err  baseline_rate  baseline_rate_err  control_rate  control_rate_err\n",
      "    result  0.03          0.0         0.07          0.7             0.01           0.64               0.01           0.7              0.01\n",
      "    ğŸ“ Columns / æ¬„ä½: risk, risk_CI_btm, risk_CI_top, attack_rate, attack_rate_err, baseline_rate, baseline_rate_err, control_rate, control_rate_err\n",
      "  â€¢ details: NoneType\n",
      "\n",
      "[5] Splitter[external_split_[1-1]]_Synthesizer[external_data]_Evaluator[fidelity_assessment]\n",
      "------------------------------------------------------------\n",
      "ğŸ“¦ Dictionary with 3 keys / åŒ…å« 3 å€‹éµçš„å­—å…¸\n",
      "\n",
      "  â€¢ global: DataFrame (1 rows Ã— 3 columns)\n",
      "    ğŸ“‹ Showing first 1 rows / é¡¯ç¤ºå‰ 1 è¡Œ:\n",
      "            Score  Column Shapes  Column Pair Trends\n",
      "    result   0.78           0.95                0.62\n",
      "    ğŸ“ Columns / æ¬„ä½: Score, Column Shapes, Column Pair Trends\n",
      "\n",
      "  â€¢ columnwise: DataFrame (15 rows Ã— 3 columns)\n",
      "    ğŸ“‹ Showing first 3 rows / é¡¯ç¤ºå‰ 3 è¡Œ:\n",
      "                    Property        Metric     Score\n",
      "    age        Column Shapes  KSComplement  0.962276\n",
      "    workclass  Column Shapes  TVComplement  0.986860\n",
      "    fnlwgt     Column Shapes  KSComplement  0.957951\n",
      "    ... (12 more rows) / ... (é‚„æœ‰ 12 è¡Œ)\n",
      "    ğŸ“ Columns / æ¬„ä½: Property, Metric, Score\n",
      "\n",
      "  â€¢ pairwise: DataFrame (105 rows Ã— 6 columns)\n",
      "    ğŸ“‹ Showing first 3 rows / é¡¯ç¤ºå‰ 3 è¡Œ:\n",
      "                             Property                 Metric     Score  Real Correlation  Synthetic Correlation Error\n",
      "    age workclass  Column Pair Trends  ContingencySimilarity  0.869526               NaN                    NaN  None\n",
      "        fnlwgt     Column Pair Trends  CorrelationSimilarity  0.991312         -0.074923              -0.057548  None\n",
      "        education  Column Pair Trends  ContingencySimilarity  0.841399               NaN                    NaN  None\n",
      "    ... (102 more rows) / ... (é‚„æœ‰ 102 è¡Œ)\n",
      "    ğŸ“ Columns / æ¬„ä½: Property, Metric, Score, Real Correlation, Synthetic Correlation, Error\n",
      "\n",
      "[6] Splitter[external_split_[1-1]]_Synthesizer[external_data]_Evaluator[ml_utility_assessment]\n",
      "------------------------------------------------------------\n",
      "ğŸ“¦ Dictionary with 2 keys / åŒ…å« 2 å€‹éµçš„å­—å…¸\n",
      "\n",
      "  â€¢ global: DataFrame (12 rows Ã— 4 columns)\n",
      "    ğŸ“‹ Showing first 3 rows / é¡¯ç¤ºå‰ 3 è¡Œ:\n",
      "         metric   ori   syn  diff\n",
      "    0  f1_score  0.71  0.27 -0.44\n",
      "    1   roc_auc  0.93  0.78 -0.14\n",
      "    2  accuracy  0.87  0.78 -0.09\n",
      "    ... (9 more rows) / ... (é‚„æœ‰ 9 è¡Œ)\n",
      "    ğŸ“ Columns / æ¬„ä½: metric, ori, syn, diff\n",
      "  â€¢ details: dict\n",
      "\n",
      "================================================================================\n",
      "âœ… Total results / ç¸½çµæœæ•¸: 6\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "display_yaml_info(yaml_path[1])\n",
    "exec_now = Executor(yaml_path[1])\n",
    "exec_now.run()\n",
    "display_results(exec_now.get_result())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "petsard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}