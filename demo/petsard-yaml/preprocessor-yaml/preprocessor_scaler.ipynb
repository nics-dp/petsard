{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setting / ç’°å¢ƒè¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # noqa: I001\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Handle utils.py for Colab\n",
    "if \"COLAB_GPU\" in os.environ:\n",
    "    import urllib.request\n",
    "\n",
    "    demo_utils_url = (\n",
    "        \"https://raw.githubusercontent.com/nics-tw/petsard/main/demo/demo_utils.py\"\n",
    "    )\n",
    "    # Download and save to file instead of exec\n",
    "    demo_utils_content = urllib.request.urlopen(demo_utils_url).read().decode(\"utf-8\")\n",
    "    with open(\"demo_utils.py\", \"w\") as f:\n",
    "        f.write(demo_utils_content)\n",
    "    print(\"âœ… demo_utils.py downloaded\")\n",
    "\n",
    "else:\n",
    "    # demo_utils.py search for local\n",
    "    for p in [Path.cwd()] + list(Path.cwd().parents)[:10]:\n",
    "        utils_path = p / \"demo_utils.py\"\n",
    "        if utils_path.exists() and \"demo\" in str(utils_path):\n",
    "            sys.path.insert(0, str(p))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick setup / å¿«é€Ÿè¨­å®š: Preprocessor YAML - Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Changed working directory to demo: petsard/demo\n",
      "   ğŸ“ Notebook location: demo/petsard-yaml/preprocessor-yaml/\n",
      "   ğŸ” YAML search priority: \n",
      "      1. demo/petsard-yaml/preprocessor-yaml/\n",
      "      2. demo/\n",
      "   ğŸ’¾ Output files will be saved in: demo/\n",
      "ğŸš€ PETsARD v1.9.0\n",
      "ğŸ“… 2025-11-19 11:22:41 UTC+8\n",
      "ğŸ”§ Added to Python path: petsard/demo/petsard-yaml/preprocessor-yaml\n",
      "ğŸ“ Processing configuration files from subfolder: petsard-yaml/preprocessor-yaml\n",
      "âœ… Found configuration (1/2): petsard/demo/petsard-yaml/preprocessor-yaml/preprocessor_scaler-field-specific.yaml\n",
      "âœ… Found configuration (2/2): petsard/demo/petsard-yaml/preprocessor-yaml/preprocessor_scaler-time-anchor-scaling.yaml\n"
     ]
    }
   ],
   "source": [
    "from demo_utils import display_results, display_yaml_info, quick_setup  # noqa: I001\n",
    "\n",
    "is_colab, branch, yaml_path, Executor = quick_setup(\n",
    "    config_file=[\n",
    "        \"preprocessor_scaler-field-specific.yaml\",\n",
    "        \"preprocessor_scaler-time-anchor-scaling.yaml\",\n",
    "    ],\n",
    "    benchmark_data=None,\n",
    "    petsard_branch=\"main\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution and Result / åŸ·è¡Œèˆ‡çµæœ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Scaling for Specific Fields / è‡ªè¨‚ç‰¹å®šæ¬„ä½çš„ç¸®æ”¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“‹ YAML Configuration Files / YAML è¨­å®šæª”æ¡ˆ\n",
      "============================================================\n",
      "\n",
      "ğŸ“„ File: preprocessor_scaler-field-specific.yaml\n",
      "ğŸ“ Path: petsard/demo/petsard-yaml/preprocessor-yaml/preprocessor_scaler-field-specific.yaml\n",
      "\n",
      "âš™ï¸ Configuration content / è¨­å®šå…§å®¹:\n",
      "----------------------------------------\n",
      "---\n",
      "Loader:\n",
      "  load_benchmark_with_schema:\n",
      "    filepath: benchmark://adult-income\n",
      "    schema: benchmark://adult-income_schema\n",
      "\n",
      "Preprocessor:\n",
      "  scaling-specific:\n",
      "    sequence:\n",
      "      - scaler\n",
      "    config:\n",
      "      scaler:\n",
      "        age: 'scaler_minmax'          # Min-Max scaling\n",
      "        fnlwgt: 'scaler_standard'     # Standardization\n",
      "        educational-num: 'scaler_log' # Log transformation\n",
      "        capital-loss: None            # No scaling for categorical field\n",
      "\n",
      "Reporter:\n",
      "  save_data:\n",
      "    method: save_data\n",
      "    source:\n",
      "      - Preprocessor\n",
      "  save_schema:\n",
      "    method: save_schema\n",
      "    source:\n",
      "      - Loader\n",
      "      - Preprocessor\n",
      "...\n",
      "============================================================\n",
      "================================================================================\n",
      "ğŸ“Š Execution Results / åŸ·è¡Œçµæœ\n",
      "================================================================================\n",
      "\n",
      "[1] Loader[load_benchmark_with_schema]_Preprocessor[scaling-specific]_Reporter[save_data]\n",
      "------------------------------------------------------------\n",
      "ğŸ“‹ Reporter output / Reporter è¼¸å‡º\n",
      "  â€¢ Loader[load_benchmark_with_schema]_Preprocessor[scaling-specific]: DataFrame\n",
      "\n",
      "[2] Loader[load_benchmark_with_schema]_Preprocessor[scaling-specific]_Reporter[save_schema]\n",
      "------------------------------------------------------------\n",
      "ğŸ“‹ Reporter output / Reporter è¼¸å‡º\n",
      "  â€¢ Loader[load_benchmark_with_schema]: dict\n",
      "  â€¢ Loader[load_benchmark_with_schema]_Preprocessor[scaling-specific]: dict\n",
      "\n",
      "================================================================================\n",
      "âœ… Total results / ç¸½çµæœæ•¸: 2\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "display_yaml_info(yaml_path[0])\n",
    "exec_now = Executor(yaml_path[0])\n",
    "exec_now.run()\n",
    "display_results(exec_now.get_result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Anchor Scaling / æ™‚é–“éŒ¨é»ç¸®æ”¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“‹ YAML Configuration Files / YAML è¨­å®šæª”æ¡ˆ\n",
      "============================================================\n",
      "\n",
      "ğŸ“„ File: preprocessor_scaler-time-anchor-scaling.yaml\n",
      "ğŸ“ Path: petsard/demo/petsard-yaml/preprocessor-yaml/preprocessor_scaler-time-anchor-scaling.yaml\n",
      "\n",
      "âš™ï¸ Configuration content / è¨­å®šå…§å®¹:\n",
      "----------------------------------------\n",
      "---\n",
      "Loader:\n",
      "  load_benchmark_with_schema:\n",
      "    filepath: benchmark://best-practices_multi-table\n",
      "\n",
      "Preprocessor:\n",
      "  time_scaling:\n",
      "    sequence:\n",
      "      - scaler\n",
      "    config:\n",
      "      scaler:\n",
      "        established_date:\n",
      "          method: 'scaler_timeanchor'\n",
      "          reference:                   # Reference time field\n",
      "            - 'first_apply_apply_date'\n",
      "            - 'first_apply_approval_date'\n",
      "            - 'latest_apply_apply_date'\n",
      "            - 'latest_apply_approval_date'\n",
      "          unit: 'D'                    # Unit: days\n",
      "\n",
      "Reporter:\n",
      "  save_data:\n",
      "    method: save_data\n",
      "    source:\n",
      "      - Preprocessor\n",
      "  save_schema:\n",
      "    method: save_schema\n",
      "    source:\n",
      "      - Loader\n",
      "      - Preprocessor\n",
      "...\n",
      "============================================================\n",
      "================================================================================\n",
      "ğŸ“Š Execution Results / åŸ·è¡Œçµæœ\n",
      "================================================================================\n",
      "\n",
      "[1] Loader[load_benchmark_with_schema]_Preprocessor[time_scaling]_Reporter[save_data]\n",
      "------------------------------------------------------------\n",
      "ğŸ“‹ Reporter output / Reporter è¼¸å‡º\n",
      "  â€¢ Loader[load_benchmark_with_schema]_Preprocessor[time_scaling]: DataFrame\n",
      "\n",
      "[2] Loader[load_benchmark_with_schema]_Preprocessor[time_scaling]_Reporter[save_schema]\n",
      "------------------------------------------------------------\n",
      "ğŸ“‹ Reporter output / Reporter è¼¸å‡º\n",
      "  â€¢ Loader[load_benchmark_with_schema]: dict\n",
      "  â€¢ Loader[load_benchmark_with_schema]_Preprocessor[time_scaling]: dict\n",
      "\n",
      "================================================================================\n",
      "âœ… Total results / ç¸½çµæœæ•¸: 2\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "display_yaml_info(yaml_path[1])\n",
    "exec_now = Executor(yaml_path[1])\n",
    "exec_now.run()\n",
    "display_results(exec_now.get_result())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "petsard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
