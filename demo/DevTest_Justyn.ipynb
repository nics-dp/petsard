{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Test: import PETsARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PETsARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Test: Module-by-Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PETsARD import Loader\n",
    "\n",
    "\n",
    "load = Loader(\n",
    "    filepath='benchmark://adult',\n",
    "    na_values={k: '?' for k in [\n",
    "        'workclass',\n",
    "        'occupation',\n",
    "        'native-country'\n",
    "    ]}\n",
    ")\n",
    "load.load()\n",
    "print(load.data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint.pprint(loader.metadata.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPETsARD\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Splitter\n\u001b[0;32m      4\u001b[0m splitter \u001b[38;5;241m=\u001b[39m Splitter(\n\u001b[0;32m      5\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m      6\u001b[0m     train_split_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m splitter\u001b[38;5;241m.\u001b[39msplit(data\u001b[38;5;241m=\u001b[39m\u001b[43mloader\u001b[49m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(splitter\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(splitter\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "from PETsARD import Splitter\n",
    "\n",
    "\n",
    "split = Splitter(\n",
    "    num_samples=30,\n",
    "    train_split_ratio=0.1\n",
    ")\n",
    "split.split(data=load.data)\n",
    "print(split.data[1]['train'].shape[0])\n",
    "print(split.data[1]['validation'].shape[0])\n",
    "print(split.data[1]['train'].head(1))\n",
    "print(split.data[1]['validation'].head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor: transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0  0.642897   0.844496 -0.176607   0.139437        -0.401918        0.846848   \n",
      "\n",
      "   occupation  relationship      race    gender  capital-gain  capital-loss  \\\n",
      "0    0.623739      0.542708  0.823557  0.724266     -0.142108     -0.215452   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0       -0.042022        0.892416  0.592797  \n"
     ]
    }
   ],
   "source": [
    "from PETsARD import Processor\n",
    "\n",
    "\n",
    "proc = Processor(\n",
    "    metadata=loader.metadata,\n",
    ")\n",
    "proc.fit(\n",
    "    data=splitter.data[1]['train'],\n",
    ")\n",
    "preproc_data = proc.transform(\n",
    "    data=splitter.data[1]['train']\n",
    ")\n",
    "print(preproc_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal: Cont. as 0~1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing method: sdv-single_table-gaussiancopula\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0529 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 1.8427 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 2690 rows (same as raw) in 0.3397 sec.\n",
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0  0.675136   0.899215  0.159513   0.485683         2.083186         0.19298   \n",
      "\n",
      "   occupation  relationship      race    gender  capital-gain  capital-loss  \\\n",
      "0    0.451156      0.309264  0.396997  0.403955     -0.142108     -0.215452   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0       -0.009439        0.543633  0.318437  \n"
     ]
    }
   ],
   "source": [
    "from PETsARD import Synthesizer\n",
    "\n",
    "\n",
    "sdv_methods = [\n",
    "    # 'sdv-single_table-copulagan',\n",
    "    # 'sdv-single_table-ctgan',\n",
    "    'sdv-single_table-gaussiancopula',\n",
    "    # 'sdv-single_table-tvae'\n",
    "]\n",
    "\n",
    "smartnoise_methods = [\n",
    "    # 'smartnoise-mwem',\n",
    "]\n",
    "# 可能由於版本限制，無法執行 aim\n",
    " # 'smartnoise-aim',\n",
    "# GAN系未支援\n",
    " # 'smartnoise-dpctgan',\n",
    " # 'smartnoise-patectgan',\n",
    " # 'smartnoise-dpgan',\n",
    " # 'smartnoise-pategan',\n",
    "\n",
    "for synthesizing_method in sdv_methods + smartnoise_methods:\n",
    "    print(f\"Synthesizing method: {synthesizing_method}\")\n",
    "    synthesizer = Synthesizer(\n",
    "        method=synthesizing_method,\n",
    "        epsilon=10.0,\n",
    "    )\n",
    "    synthesizer.create(data=preproc_data)\n",
    "    synthesizer.fit_sample()\n",
    "    print(synthesizer.data_syn.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical\n",
    "for mst, pacsynth in smartnoise\n",
    "\n",
    "`ValueError: The transformer appears to have some continuous columns. Please provide only categorical or ordinal.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc_cate = Processor(\n",
    "#     metadata=loader.metadata,\n",
    "# )\n",
    "\n",
    "# metadata_col = loader.metadata.metadata['col']\n",
    "# colnames_discrete = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "# proc_cate.update_config(\n",
    "#     {'encoder': {col: 'encoder_label' if col in colnames_discrete else None for col in metadata_col},\n",
    "#      'scaler': {col: None for col in metadata_col},\n",
    "#      }\n",
    "# )\n",
    "\n",
    "# proc_cate.fit(\n",
    "#     data=splitter.data[1]['train'],\n",
    "#     sequence=None\n",
    "# )\n",
    "# preproc_data_cate = proc_cate.transform(\n",
    "#     data=splitter.data[1]['train']\n",
    "# )\n",
    "# print(preproc_data_cate.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smartnoise_methods_cate = [\n",
    "#     'smartnoise-mst',\n",
    "#     'smartnoise-pacsynth',\n",
    "# ]\n",
    "\n",
    "# for col in preproc_data_cate.columns:\n",
    "#     preproc_data_cate[col] = preproc_data_cate[col].astype('category')\n",
    "\n",
    "# for synthesizing_method in smartnoise_methods_cate:\n",
    "#     print(f\"Synthesizing method: {synthesizing_method}\")\n",
    "#     synthesizer_cate = PETsARD.Synthesizer(\n",
    "#         data=preproc_data_cate,\n",
    "#         synthesizing_method=synthesizing_method,\n",
    "#         epsilon=1.0,\n",
    "#     )\n",
    "#     synthesizer_cate.fit_sample()\n",
    "#     print(synthesizer_cate.data_syn.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor: inverse_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age  workclass         fnlwgt     education  educational-num  \\\n",
      "0  47.440065  State-gov  208428.291072  Some-college        15.475563   \n",
      "\n",
      "       marital-status       occupation relationship   race gender  \\\n",
      "0  Married-civ-spouse  Exec-managerial      Husband  White   Male   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0  1.136868e-13           0.0       40.409281  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "postproc_data = proc.inverse_transform(\n",
    "    data=synthesizer.data_syn\n",
    ")\n",
    "print(postproc_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.034 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    }
   ],
   "source": [
    "from PETsARD import Evaluator\n",
    "\n",
    "\n",
    "eval = Evaluator(\n",
    "    method='anonymeter-singlingout_univariate',\n",
    "    anonymeter_n_attacks=2 # 2000\n",
    ")\n",
    "eval.create(\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': splitter.data[1]['validation']\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (Anonymeter - Linkability): Now is Linkability Evaluator\n",
      "Evaluator (Anonymeter - Linkability): aux_cols are [age, fnlwgt, race, gender, native-country]\n",
      "                                      and [workclass, education, capital-gain, capital-loss, hours-per-week].\n",
      "Evaluator (Anonymeter - Linkability): Evaluator time: 0.0 sec.\n",
      "Evaluator (Anonymeter): Evaluating  Linkability.\n",
      "Evaluator (Anonymeter): Evaluating Linkability spent 8.6534 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Risk': 0.0,\n",
       " 'Risk_CI_btm': 0.0,\n",
       " 'Risk_CI_top': 0.6928102649963914,\n",
       " 'Attack_Rate': 0.32880988624667346,\n",
       " 'Attack_Rate_err': 0.32880988624667346,\n",
       " 'Baseline_Rate': 0.32880988624667346,\n",
       " 'Baseline_Rate_err': 0.32880988624667346,\n",
       " 'Control_Rate': 0.32880988624667346,\n",
       " 'Control_Rate_err': 0.32880988624667346}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='anonymeter-linkability',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': splitter.data[1]['validation']\n",
    "    },\n",
    "    anonymeter_n_attacks=2, # 2000,\n",
    "    anonymeter_n_neighbors=10,\n",
    "    anonymeter_n_jobs=-1,\n",
    "    anonymeter_aux_cols=[\n",
    "        ['age', 'fnlwgt', 'race', 'gender', 'native-country'],\n",
    "        ['workclass', 'education', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    ]\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (Anonymeter - Inference): Now is Inference Evaluator\n",
      "Evaluator (Anonymeter - Inference): Evaluator time: 0.0 sec.\n",
      "Evaluator (Anonymeter): Evaluating  Inference.\n",
      "Evaluator (Anonymeter): Evaluating Inference spent 0.6498 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Risk': 0.0,\n",
       " 'Risk_CI_btm': 0.0,\n",
       " 'Risk_CI_top': 0.013449535585480343,\n",
       " 'Attack_Rate': 0.08915647695108263,\n",
       " 'Attack_Rate_err': 0.024683334547474907,\n",
       " 'Baseline_Rate': 0.09114122827015952,\n",
       " 'Baseline_Rate_err': 0.0249352437952306,\n",
       " 'Control_Rate': 0.11495824409908227,\n",
       " 'Control_Rate_err': 0.027695443904980018}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='anonymeter-inference',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': splitter.data[1]['validation']\n",
    "    },\n",
    "    anonymeter_n_attacks=2, #2000,\n",
    "    anonymeter_n_jobs=-1,\n",
    "    anonymeter_secret='age'\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (SDMetrics): Evaluating QualityReport.\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 67.76it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:05<00:00, 18.18it/s]\n",
      "\n",
      "Overall Score: 74.06%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 91.81%\n",
      "- Column Pair Trends: 56.31%\n",
      "Evaluator (SDMetrics): Evaluating QualityReport spent 6.0073 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.7405721651768964,\n",
       " 'properties': {'Column Shapes': {'Score': 0.918070881955508},\n",
       "  'Column Pair Trends': {'Score': 0.5630734483982847}},\n",
       " 'details': {'Column Shapes':              Column        Metric     Score\n",
       "  0               age  KSComplement  0.948650\n",
       "  1         workclass  TVComplement  0.996087\n",
       "  2            fnlwgt  KSComplement  0.950445\n",
       "  3         education  TVComplement  0.539399\n",
       "  4   educational-num  KSComplement  0.881909\n",
       "  5    marital-status  TVComplement  0.971009\n",
       "  6        occupation  TVComplement  0.981831\n",
       "  7      relationship  TVComplement  0.962217\n",
       "  8              race  TVComplement  0.997025\n",
       "  9            gender  TVComplement  0.998437\n",
       "  10     capital-gain  KSComplement  0.918025\n",
       "  11     capital-loss  KSComplement  0.952909\n",
       "  12   hours-per-week  KSComplement  0.692668\n",
       "  13   native-country  TVComplement  0.991754\n",
       "  14           income  TVComplement  0.988698,\n",
       "  'Column Pair Trends':            Column 1         Column 2                 Metric     Score  \\\n",
       "  0               age        workclass  ContingencySimilarity  0.867992   \n",
       "  1               age           fnlwgt  CorrelationSimilarity  0.989224   \n",
       "  2               age        education  ContingencySimilarity  0.523663   \n",
       "  3               age  educational-num  CorrelationSimilarity  0.978033   \n",
       "  4               age   marital-status  ContingencySimilarity  0.798824   \n",
       "  ..              ...              ...                    ...       ...   \n",
       "  100    capital-loss   native-country  ContingencySimilarity  0.006040   \n",
       "  101    capital-loss           income  ContingencySimilarity  0.006066   \n",
       "  102  hours-per-week   native-country  ContingencySimilarity  0.519466   \n",
       "  103  hours-per-week           income  ContingencySimilarity  0.509003   \n",
       "  104  native-country           income  ContingencySimilarity  0.972553   \n",
       "  \n",
       "       Real Correlation  Synthetic Correlation Error  \n",
       "  0                 NaN                    NaN  None  \n",
       "  1           -0.074321              -0.052768  None  \n",
       "  2                 NaN                    NaN  None  \n",
       "  3            0.030102               0.074036  None  \n",
       "  4                 NaN                    NaN  None  \n",
       "  ..                ...                    ...   ...  \n",
       "  100               NaN                    NaN  None  \n",
       "  101               NaN                    NaN  None  \n",
       "  102               NaN                    NaN  None  \n",
       "  103               NaN                    NaN  None  \n",
       "  104               NaN                    NaN  None  \n",
       "  \n",
       "  [105 rows x 7 columns]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='sdmetrics-single_table-qualityreport',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (SDMetrics): Evaluating DiagnosticReport.\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|██████████| 15/15 [00:00<00:00, 199.66it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Evaluator (SDMetrics): Evaluating DiagnosticReport spent 0.0853 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 1.0,\n",
       " 'properties': {'Data Validity': {'Score': 1.0},\n",
       "  'Data Structure': {'Score': 1.0}},\n",
       " 'details': {'Data Validity':              Column             Metric  Score\n",
       "  0               age  BoundaryAdherence    1.0\n",
       "  1         workclass  CategoryAdherence    1.0\n",
       "  2            fnlwgt  BoundaryAdherence    1.0\n",
       "  3         education  CategoryAdherence    1.0\n",
       "  4   educational-num  BoundaryAdherence    1.0\n",
       "  5    marital-status  CategoryAdherence    1.0\n",
       "  6        occupation  CategoryAdherence    1.0\n",
       "  7      relationship  CategoryAdherence    1.0\n",
       "  8              race  CategoryAdherence    1.0\n",
       "  9            gender  CategoryAdherence    1.0\n",
       "  10     capital-gain  BoundaryAdherence    1.0\n",
       "  11     capital-loss  BoundaryAdherence    1.0\n",
       "  12   hours-per-week  BoundaryAdherence    1.0\n",
       "  13   native-country  CategoryAdherence    1.0\n",
       "  14           income  CategoryAdherence    1.0,\n",
       "  'Data Structure':            Metric  Score\n",
       "  0  TableStructure    1.0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='sdmetrics-single_table-diagnosticreport',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Test: Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader - Benchmarker: file benchmark\\adult.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "Executor - Loader: adult loading time: 7.0139 sec.\n",
      "Executor - Splitter: 0.8 splitting time: 0.0689 sec.\n",
      "No self-defined config passed.  Generate a config automatically.\n",
      "Executor - Processor (preprocessing): drop-IQR-stanard-label processing time: 0.4141 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0469 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 7.8931 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21557 rows (same as raw) in 1.2511 sec.\n",
      "Executor - Synthesizer: GaussianCopula synthesizing time: 9.1911 sec.\n",
      "Executor - Processor (postprocessing): drop-IQR-stanard-label processing time: 0.0288 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.045 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n",
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 4.9866 sec.\n",
      "No self-defined config passed.  Generate a config automatically.\n",
      "Executor - Processor (preprocessing): drop-IQR-stanard-label processing time: 0.3603 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0228 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 7.7783 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21541 rows (same as raw) in 1.4599 sec.\n",
      "Executor - Synthesizer: GaussianCopula synthesizing time: 9.2625 sec.\n",
      "Executor - Processor (postprocessing): drop-IQR-stanard-label processing time: 0.0338 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0419 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n",
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 4.6758 sec.\n",
      "====== ====== ====== ====== ====== ======\n",
      "Executor (run - single process): Total execution time: 38.4373 sec.\n",
      "====== ====== ====== ====== ====== ======\n",
      "{'Attack_Rate': 0.3967253428113813,\n",
      " 'Attack_Rate_err': 0.3967253428113813,\n",
      " 'Baseline_Rate': 0.3967253428113813,\n",
      " 'Baseline_Rate_err': 0.3967253428113813,\n",
      " 'Control_Rate': 0.3967253428113813,\n",
      " 'Control_Rate_err': 0.3967253428113813,\n",
      " 'Risk': 0.0,\n",
      " 'Risk_CI_btm': 0.0,\n",
      " 'Risk_CI_top': 0.9300148011448004}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "\n",
    "para_Executor = {\n",
    "    'Loader': {\n",
    "        'adult': {\n",
    "            'filepath': 'benchmark://adult',\n",
    "            'na_values': {k: '?' for k in [\n",
    "                'workclass',\n",
    "                'occupation',\n",
    "                'native-country'\n",
    "            ]}\n",
    "        }\n",
    "    },\n",
    "    'Splitter': {\n",
    "        '0.8': {\n",
    "            'num_samples': 2,\n",
    "            'train_split_ratio': 0.8,\n",
    "        }\n",
    "    },\n",
    "    'Processor': {\n",
    "        'drop-IQR-stanard-label': {\n",
    "            'missing': {\n",
    "                'method': 'missing_drop',\n",
    "                'all': True\n",
    "            },\n",
    "            #'method': , # ValueError: y contains previously unseen labels:\n",
    "            'encoder': [\n",
    "                {'method': 'encoder_label',\n",
    "                 'include': ['education','marital-status','relationship','gender']\n",
    "                },\n",
    "                {'method': 'encoder_uniform',\n",
    "                 'include': ['workclass', 'occupation', 'race', 'native-country', 'income']\n",
    "                }\n",
    "            ],\n",
    "            'outlier': {\n",
    "                'method': 'outlier_iqr',\n",
    "                'include': 'hours-per-week'\n",
    "            },\n",
    "            'scaler': {\n",
    "                'method': 'scaler_standard',\n",
    "                'exclude': ['hours-per-week',\n",
    "                    'workclass', 'education', 'marital-status',\n",
    "                    'occupation', 'relationship', 'race', 'gender',\n",
    "                    'native-country', 'income'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'Synthesizer': {\n",
    "        'GaussianCopula': {\n",
    "            'synthesizing_method': 'sdv-singletable-gaussiancopula'\n",
    "        }\n",
    "    },\n",
    "    'Evaluator': {\n",
    "        'anonymeter-SinglingOut': {\n",
    "            'evaluating_method': 'anonymeter-singlingout-univariate',\n",
    "            'anonymeter_n_attacks': 1,  # 2000'\n",
    "            'anonymeter_num_samples': 2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "executor_single = PETsARD.Executor(**para_Executor)\n",
    "executor_single.run()\n",
    "pprint(\n",
    "    executor_single.evaluator[(\n",
    "        'adult',\n",
    "        '0.8',\n",
    "        1,\n",
    "        'drop-IQR-stanard-label',\n",
    "        'GaussianCopula',\n",
    "        'anonymeter-SinglingOut',\n",
    "        1\n",
    "    )].Evaluator.evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .run_parallel()\n",
    "Not applicable now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|          | 0/1 [00:20<?, ?it/s]s/it]\n",
      "Splitting: 100%|██████████| 1/1 [00:20<00:00, 20.74s/it]\n",
      "Loading: 100%|██████████| 1/1 [00:20<00:00, 20.74s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'Processor.__init__.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\process.py\", line 211, in _sendback_result\n    result_queue.put(_ResultItem(work_id, result=result,\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py\", line 371, in put\n    obj = _ForkingPickler.dumps(obj)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nAttributeError: Can't pickle local object 'Processor.__init__.<locals>.<lambda>'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 73\u001b[0m\n\u001b[0;32m     11\u001b[0m para_Executor \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoader\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     }\n\u001b[0;32m     69\u001b[0m }\n\u001b[0;32m     72\u001b[0m executor_parallel \u001b[38;5;241m=\u001b[39m PETsARD\u001b[38;5;241m.\u001b[39mExecutor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpara_Executor)\n\u001b[1;32m---> 73\u001b[0m \u001b[43mexecutor_parallel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m pprint(\n\u001b[0;32m     75\u001b[0m     executor_parallel\u001b[38;5;241m.\u001b[39mevaluator[(\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m     )]\u001b[38;5;241m.\u001b[39mEvaluator\u001b[38;5;241m.\u001b[39mevaluation\n\u001b[0;32m     84\u001b[0m )\n",
      "File \u001b[1;32mD:\\Dropbox\\89_其他應用\\GitHub\\PETsARD\\PETsARD\\Executor.py:541\u001b[0m, in \u001b[0;36mExecutor.run_parallel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    539\u001b[0m trials_till_proc \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proc_future \u001b[38;5;129;01min\u001b[39;00m as_completed(proc_futures):\n\u001b[1;32m--> 541\u001b[0m     proc_result \u001b[38;5;241m=\u001b[39m \u001b[43mproc_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m     proc_name \u001b[38;5;241m=\u001b[39m proc_futures[proc_future][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor[proc_name] \u001b[38;5;241m=\u001b[39m proc_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'Processor.__init__.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD')\n",
    "os.chdir('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD\\\\demo')\n",
    "\n",
    "import PETsARD\n",
    "\n",
    "\n",
    "para_Executor = {\n",
    "    'Loader': {\n",
    "        'adult': {\n",
    "            'filepath': 'benchmark://adult',\n",
    "            'na_values': {k: '?' for k in [\n",
    "                'workclass',\n",
    "                'occupation',\n",
    "                'native-country'\n",
    "            ]}\n",
    "        }\n",
    "    },\n",
    "    'Splitter': {\n",
    "        '0.8': {\n",
    "            'num_samples': 2,\n",
    "            'train_split_ratio': 0.8,\n",
    "        }\n",
    "    },\n",
    "    'Processor': {\n",
    "        'drop-IQR-stanard-label': {\n",
    "            'missingist': {\n",
    "                'method': 'missingist_drop',\n",
    "                'all': True\n",
    "            },\n",
    "            #'method': , # ValueError: y contains previously unseen labels:\n",
    "            'encoder': [\n",
    "                {'method': 'encoder_label',\n",
    "                 'include': ['education','marital-status','relationship','gender']\n",
    "                },\n",
    "                {'method': 'encoder_uniform',\n",
    "                 'include': ['workclass', 'occupation', 'race', 'native-country', 'income']\n",
    "                }\n",
    "            ],\n",
    "            'outlierist': {\n",
    "                'method': 'outlierist_iqr',\n",
    "                'include': 'hours-per-week'\n",
    "            },\n",
    "            'scaler': {\n",
    "                'method': 'scaler_standard',\n",
    "                'exclude': ['hours-per-week',\n",
    "                    'workclass', 'education', 'marital-status',\n",
    "                    'occupation', 'relationship', 'race', 'gender',\n",
    "                    'native-country', 'income'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'Synthesizer': {\n",
    "        'GaussianCopula': {\n",
    "            'synthesizing_method': 'sdv-singletable-gaussiancopula'\n",
    "        }\n",
    "    },\n",
    "    'Evaluator': {\n",
    "        'anonymeter-SinglingOut': {\n",
    "            'evaluating_method': 'anonymeter-singlingout-univariate',\n",
    "            'anonymeter_n_attacks': 1,  # 2000'\n",
    "            'anonymeter_num_samples': 2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Processor contains lambda function, but python couldn't pickle it.\n",
    "# so Processor .run_parallel() didn't valid after Processor migration.\n",
    "executor_parallel = PETsARD.Executor(**para_Executor)\n",
    "executor_parallel.run_parallel()\n",
    "pprint(\n",
    "    executor_parallel.evaluator[(\n",
    "        'adult',\n",
    "        '0.8',\n",
    "        1,\n",
    "        'drop-IQR-stanard-label',\n",
    "        'GaussianCopula',\n",
    "        'anonymeter-SinglingOut',\n",
    "        1\n",
    "    )].Evaluator.evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un arrangment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Result(__evaluator):\n",
    "    import numpy as np\n",
    "    __dict_result = {}\n",
    "    __para_to_handle = [('Risk', ['risk()', 'value']), ('Risk_CI_btm', ['risk()', 'ci[0]']), ('Risk_CI_top', ['risk()', 'ci[1]']), ('Attack_Rate', ['results()', 'attack_rate', 'value']), ('Attack_Rate_err', ['results()', 'attack_rate', 'error']), ('Baseline_Rate', ['results()', 'baseline_rate', 'value']), ('Baseline_Rate_err', ['results()', 'baseline_rate', 'error']), ('Control_Rate', ['results()', 'control_rate', 'value']), ('Control_Rate_err', ['results()', 'control_rate', 'error'])\n",
    "                        ]\n",
    "    for __key, __attrs in __para_to_handle:\n",
    "        try:\n",
    "            __attr_value = __evaluator\n",
    "            for __attr in __attrs:\n",
    "                if '()' in __attr:\n",
    "                    __method_name = __attr.split('(')[0]\n",
    "                    if hasattr(__attr_value, __method_name):\n",
    "                        __method = getattr(__attr_value, __method_name)\n",
    "                        if callable(__method):\n",
    "                            __attr_value = __method()\n",
    "                        else:\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                elif '[' in __attr:\n",
    "                    __attr_name = __attr.split('[')[0]\n",
    "                    __index = int(__attr.split('[')[1].rstrip(']'))\n",
    "                    if hasattr(__attr_value, __attr_name)\\\n",
    "                            and isinstance(getattr(__attr_value, __attr_name), (list, dict, tuple)):\n",
    "                        try:\n",
    "                            __attr_value = getattr(\n",
    "                                __attr_value, __attr_name)[__index]\n",
    "                        except (IndexError, KeyError):\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                else:\n",
    "                    __attr_value = getattr(__attr_value, __attr)\n",
    "            __dict_result[__key] = __attr_value\n",
    "        except Exception as e:\n",
    "            __dict_result[__key] = np.nan\n",
    "    return __dict_result\n",
    "\n",
    "\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    from anonymeter.evaluators import SinglingOutEvaluator\n",
    "    print(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\")\n",
    "    evaluator = SinglingOutEvaluator(ori=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), syn=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), control=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\"), n_attacks=2000\n",
    "                                     )\n",
    "    try:\n",
    "        evaluator.evaluate(mode='univariate')\n",
    "        print(Result(evaluator))\n",
    "    except RuntimeError as ex:\n",
    "        print(f\"Singling out evaluation failed with {ex}.\"\n",
    "              \"Please re-run this cell.\"\n",
    "              \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "              \"make the evaluation slower.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "for type in ['][Ori]', '][Ctrl]', '-1-1]Postproc']:\n",
    "    for combo in itertools.combinations(['01', '02', '03', '04', '05', '06'], 2):\n",
    "        df_a = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[0]}{type}.csv\")\n",
    "        df_b = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[1]}{type}.csv\")\n",
    "        if df_a.equals(df_b):\n",
    "            print(type+': '+str(combo))\n",
    "            print(\"They're same!!??\")\n",
    "        # else:\n",
    "            # print(type+': '+str(combo))\n",
    "            # print(\"They're different.\")\n",
    "print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Loader: adult loading time: 6.8097 sec.\n",
      "Executor - Splitter: 0.8 splitting time: 0.339 sec.\n",
      "Preprocessor - Outlierist (IQR): Dropped  1060 rows on fnlwgt         . Kept [-63981.5, 419234.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   227 rows on educational-num. Kept [3.0, 19.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  1705 rows on capital-loss   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  9432 rows on hours-per-week . Kept [32.5, 52.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   214 rows on age            . Kept [-0.5, 75.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  3030 rows on capital-gain   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Totally Dropped 13932 in 36207 rows.\n",
      "Preprocessor - Encoder (Label): Column native-country  been labelized from 0 to 39.\n",
      "Preprocessor - Encoder (Label): Column gender          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column race            been labelized from 0 to  4.\n",
      "Preprocessor - Encoder (Label): Column relationship    been labelized from 0 to  5.\n",
      "Preprocessor - Encoder (Label): Column education       been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column income          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column workclass       been labelized from 0 to  6.\n",
      "Preprocessor - Encoder (Label): Column occupation      been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column marital-status  been labelized from 0 to  6.\n",
      "Executor - Preprocessor: drop-IQR-stanard-NA preprocessing time: 0.0764 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.021 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula spent 12.1284 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCoupula # 22275 rows (same as raw) in 1.313 sec.\n",
      "Executor - Synthesizer: GaussianCoupula synthesizing time: 13.466 sec.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding native-country.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding gender.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding race.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding relationship.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding education.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding income.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding workclass.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding occupation.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding marital-status.\n",
      "Executor - Postprocessor: postprocessing time: 0.0142 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0404 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 765 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 131.365 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0322 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 802 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 2 trials evaluating time: 131.1331 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0336 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 830 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 3 trials evaluating time: 131.5346 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0356 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 794 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 4 trials evaluating time: 131.4821 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0351 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 821 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 5 trials evaluating time: 132.587 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.036 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 800 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 6 trials evaluating time: 131.8783 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0352 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 799 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Result(__evaluator):\n",
    "    import numpy as np\n",
    "    __dict_result = {}\n",
    "    __para_to_handle = [('Risk', ['risk()', 'value']), ('Risk_CI_btm', ['risk()', 'ci[0]']), ('Risk_CI_top', ['risk()', 'ci[1]']), ('Attack_Rate', ['results()', 'attack_rate', 'value']), ('Attack_Rate_err', ['results()', 'attack_rate', 'error']), ('Baseline_Rate', ['results()', 'baseline_rate', 'value']), ('Baseline_Rate_err', ['results()', 'baseline_rate', 'error']), ('Control_Rate', ['results()', 'control_rate', 'value']), ('Control_Rate_err', ['results()', 'control_rate', 'error'])\n",
    "                        ]\n",
    "    for __key, __attrs in __para_to_handle:\n",
    "        try:\n",
    "            __attr_value = __evaluator\n",
    "            for __attr in __attrs:\n",
    "                if '()' in __attr:\n",
    "                    __method_name = __attr.split('(')[0]\n",
    "                    if hasattr(__attr_value, __method_name):\n",
    "                        __method = getattr(__attr_value, __method_name)\n",
    "                        if callable(__method):\n",
    "                            __attr_value = __method()\n",
    "                        else:\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                elif '[' in __attr:\n",
    "                    __attr_name = __attr.split('[')[0]\n",
    "                    __index = int(__attr.split('[')[1].rstrip(']'))\n",
    "                    if hasattr(__attr_value, __attr_name)\\\n",
    "                            and isinstance(getattr(__attr_value, __attr_name), (list, dict, tuple)):\n",
    "                        try:\n",
    "                            __attr_value = getattr(\n",
    "                                __attr_value, __attr_name)[__index]\n",
    "                        except (IndexError, KeyError):\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                else:\n",
    "                    __attr_value = getattr(__attr_value, __attr)\n",
    "            __dict_result[__key] = __attr_value\n",
    "        except Exception as e:\n",
    "            __dict_result[__key] = np.nan\n",
    "    return __dict_result\n",
    "\n",
    "\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    from anonymeter.evaluators import SinglingOutEvaluator\n",
    "    print(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\")\n",
    "    evaluator = SinglingOutEvaluator(ori=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), syn=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), control=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\"), n_attacks=2000\n",
    "                                     )\n",
    "    try:\n",
    "        evaluator.evaluate(mode='univariate')\n",
    "        print(Result(evaluator))\n",
    "    except RuntimeError as ex:\n",
    "        print(f\"Singling out evaluation failed with {ex}.\"\n",
    "              \"Please re-run this cell.\"\n",
    "              \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "              \"make the evaluation slower.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    eval = PETsARD.Evaluator(evaluating_method='anonymeter-singlingout-univariate', data={'ori': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), 'syn': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), 'control': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\")\n",
    "                                                                                          }, anonymeter_n_attacks=500\n",
    "                             )\n",
    "    eval.eval()\n",
    "    print(eval.Evaluator.evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 7 trials evaluating time: 131.5421 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0354 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for type in ['][Ori]', '][Ctrl]', '-1-1]Postproc']:\n",
    "    for combo in itertools.combinations(['01', '02', '03', '04', '05', '06'], 2):\n",
    "        df_a = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[0]}{type}.csv\")\n",
    "        df_b = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[1]}{type}.csv\")\n",
    "        if df_a.equals(df_b):\n",
    "            print(type+': '+str(combo))\n",
    "            print(\"They're same!!??\")\n",
    "        # else:\n",
    "            # print(type+': '+str(combo))\n",
    "            # print(\"They're different.\")\n",
    "print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'Loader': {\n",
    "        'NHANES': {\n",
    "            'filepath': '../[sunset]/data/[NHANES] B.csv',\n",
    "            'header_exist': False,\n",
    "            'header_names': ['gen', 'age', 'race', 'edu', 'mar', 'bmi', 'dep', 'pir', 'gh', 'mets', 'qm', 'dia']\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
