{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PETsARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import PETsARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "import PETsARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module-by-Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader - Benchmarker: file benchmark\\adult.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "   age workclass  fnlwgt education  educational-num marital-status  \\\n",
      "0   25   Private  226802      11th                7  Never-married   \n",
      "\n",
      "          occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Machine-op-inspct    Own-child  Black   Male             0             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              40  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "loader = PETsARD.Loader(\n",
    "    filepath='benchmark://adult',\n",
    "    na_values={k: '?' for k in [\n",
    "        'workclass',\n",
    "        'occupation',\n",
    "        'native-country'\n",
    "    ]}\n",
    ")\n",
    "print(loader.data.head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col': {'age': {'dtype': dtype('int8'),\n",
      "                 'infer_dtype': 'numerical',\n",
      "                 'na_percentage': 0.0},\n",
      "         'capital-gain': {'dtype': dtype('int32'),\n",
      "                          'infer_dtype': 'numerical',\n",
      "                          'na_percentage': 0.0},\n",
      "         'capital-loss': {'dtype': dtype('int16'),\n",
      "                          'infer_dtype': 'numerical',\n",
      "                          'na_percentage': 0.0},\n",
      "         'education': {'dtype': CategoricalDtype(categories=['10th', '11th', '12th', '1st-4th', '5th-6th', '7th-8th',\n",
      "                  '9th', 'Assoc-acdm', 'Assoc-voc', 'Bachelors', 'Doctorate',\n",
      "                  'HS-grad', 'Masters', 'Preschool', 'Prof-school',\n",
      "                  'Some-college'],\n",
      ", ordered=False),\n",
      "                       'infer_dtype': 'categorical',\n",
      "                       'na_percentage': 0.0},\n",
      "         'educational-num': {'dtype': dtype('int8'),\n",
      "                             'infer_dtype': 'numerical',\n",
      "                             'na_percentage': 0.0},\n",
      "         'fnlwgt': {'dtype': dtype('int32'),\n",
      "                    'infer_dtype': 'numerical',\n",
      "                    'na_percentage': 0.0},\n",
      "         'gender': {'dtype': CategoricalDtype(categories=['Female', 'Male'], ordered=False),\n",
      "                    'infer_dtype': 'categorical',\n",
      "                    'na_percentage': 0.0},\n",
      "         'hours-per-week': {'dtype': dtype('int8'),\n",
      "                            'infer_dtype': 'numerical',\n",
      "                            'na_percentage': 0.0},\n",
      "         'income': {'dtype': CategoricalDtype(categories=['<=50K', '>50K'], ordered=False),\n",
      "                    'infer_dtype': 'categorical',\n",
      "                    'na_percentage': 0.0},\n",
      "         'marital-status': {'dtype': CategoricalDtype(categories=['Divorced', 'Married-AF-spouse', 'Married-civ-spouse',\n",
      "                  'Married-spouse-absent', 'Never-married', 'Separated',\n",
      "                  'Widowed'],\n",
      ", ordered=False),\n",
      "                            'infer_dtype': 'categorical',\n",
      "                            'na_percentage': 0.0},\n",
      "         'native-country': {'dtype': CategoricalDtype(categories=['Cambodia', 'Canada', 'China', 'Columbia', 'Cuba',\n",
      "                  'Dominican-Republic', 'Ecuador', 'El-Salvador', 'England',\n",
      "                  'France', 'Germany', 'Greece', 'Guatemala', 'Haiti',\n",
      "                  'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n",
      "                  'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos',\n",
      "                  'Mexico', 'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru',\n",
      "                  'Philippines', 'Poland', 'Portugal', 'Puerto-Rico',\n",
      "                  'Scotland', 'South', 'Taiwan', 'Thailand', 'Trinadad&Tobago',\n",
      "                  'United-States', 'Vietnam', 'Yugoslavia'],\n",
      ", ordered=False),\n",
      "                            'infer_dtype': 'categorical',\n",
      "                            'na_percentage': 0.017546374022357807},\n",
      "         'occupation': {'dtype': CategoricalDtype(categories=['Adm-clerical', 'Armed-Forces', 'Craft-repair',\n",
      "                  'Exec-managerial', 'Farming-fishing', 'Handlers-cleaners',\n",
      "                  'Machine-op-inspct', 'Other-service', 'Priv-house-serv',\n",
      "                  'Prof-specialty', 'Protective-serv', 'Sales', 'Tech-support',\n",
      "                  'Transport-moving'],\n",
      ", ordered=False),\n",
      "                        'infer_dtype': 'categorical',\n",
      "                        'na_percentage': 0.05751197739650301},\n",
      "         'race': {'dtype': CategoricalDtype(categories=['Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other',\n",
      "                  'White'],\n",
      ", ordered=False),\n",
      "                  'infer_dtype': 'categorical',\n",
      "                  'na_percentage': 0.0},\n",
      "         'relationship': {'dtype': CategoricalDtype(categories=['Husband', 'Not-in-family', 'Other-relative', 'Own-child',\n",
      "                  'Unmarried', 'Wife'],\n",
      ", ordered=False),\n",
      "                          'infer_dtype': 'categorical',\n",
      "                          'na_percentage': 0.0},\n",
      "         'workclass': {'dtype': CategoricalDtype(categories=['Federal-gov', 'Local-gov', 'Never-worked', 'Private',\n",
      "                  'Self-emp-inc', 'Self-emp-not-inc', 'State-gov',\n",
      "                  'Without-pay'],\n",
      ", ordered=False),\n",
      "                       'infer_dtype': 'categorical',\n",
      "                       'na_percentage': 0.05730723557593874}},\n",
      " 'global': {'col_num': 15,\n",
      "            'na_percentage': 0.07411653904426518,\n",
      "            'row_num': 48842}}\n"
     ]
    }
   ],
   "source": [
    "pprint(loader.metadata.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4884\n",
      "43958\n",
      "   age workclass  fnlwgt education  educational-num marital-status  \\\n",
      "0   25   Private  226802      11th                7  Never-married   \n",
      "\n",
      "          occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Machine-op-inspct    Own-child  Black   Male             0             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              40  United-States  <=50K  \n",
      "   age workclass  fnlwgt education  educational-num      marital-status  \\\n",
      "0   38   Private   89814   HS-grad                9  Married-civ-spouse   \n",
      "\n",
      "        occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Farming-fishing      Husband  White   Male             0             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              50  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "splitter = PETsARD.Splitter(\n",
    "    data=loader.data,\n",
    "    num_samples=30,\n",
    "    train_split_ratio=0.1\n",
    ")\n",
    "print(splitter.data[1]['train'].shape[0])\n",
    "print(splitter.data[1]['validation'].shape[0])\n",
    "print(splitter.data[1]['train'].head(1))\n",
    "print(splitter.data[1]['validation'].head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor: transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No self-defined config passed.  Generate a config automatically.\n",
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0 -0.999057   0.307087  0.390396   0.824784        -1.181942        0.520919   \n",
      "\n",
      "   occupation  relationship      race    gender  capital-gain  capital-loss  \\\n",
      "0    0.779348      0.796506  0.911432  0.405937     -0.146857     -0.212508   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0       -0.032114        0.844928  0.610213  \n"
     ]
    }
   ],
   "source": [
    "processor = PETsARD.processor.Processor(\n",
    "    metadata=loader.metadata,\n",
    ")\n",
    "processor.fit(\n",
    "    data=splitter.data[1]['train'],\n",
    ")\n",
    "preproc_data = processor.transform(\n",
    "    data=splitter.data[1]['train']\n",
    ")\n",
    "print(preproc_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal: Cont. as 0~1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing method: smartnoise-mwem\n",
      "Synthesizer (SmartNoise): Fitting mwem.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mwem.py:570: UserWarning: Data should be preprocessed to have 0 based indices.\n",
      "  warnings.warn(\"Data should be preprocessed to have 0 based indices.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizer (SmartNoise): Fitting  mwem spent 5.6909 sec.\n",
      "Synthesizer (SmartNoise): Sampling mwem # 2796 rows (same as raw) in 0.4303 sec.\n",
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0    0          0      -1          0                0               0   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0           0             0     0       0             0             0   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0               0               0       0  \n"
     ]
    }
   ],
   "source": [
    "sdv_methods = [\n",
    "    # 'sdv-singletable-copulagan',\n",
    "    # 'sdv-singletable-ctgan',\n",
    "    # 'sdv-singletable-gaussiancopula',\n",
    "    # 'sdv-singletable-tvae'\n",
    "]\n",
    "\n",
    "smartnoise_methods = [\n",
    "    'smartnoise-mwem',\n",
    "]\n",
    "# 可能由於版本限制，無法執行 aim\n",
    " # 'smartnoise-aim', \n",
    "# GAN系未支援\n",
    " # 'smartnoise-dpctgan',\n",
    " # 'smartnoise-patectgan',\n",
    " # 'smartnoise-dpgan',\n",
    " # 'smartnoise-pategan',\n",
    "\n",
    "for synthesizing_method in sdv_methods + smartnoise_methods:\n",
    "    print(f\"Synthesizing method: {synthesizing_method}\")\n",
    "    synthesizer = PETsARD.Synthesizer(\n",
    "        data=preproc_data,\n",
    "        synthesizing_method=synthesizing_method,\n",
    "        epsilon=10.0,\n",
    "    )\n",
    "    synthesizer.fit_sample()\n",
    "    print(synthesizer.data_syn.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical\n",
    "for mst, pacsynth in smartnoise\n",
    "\n",
    "`ValueError: The transformer appears to have some continuous columns. Please provide only categorical or ordinal.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No self-defined config passed.  Generate a config automatically.\n",
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0   25          3  226802          1                7               4   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0           6             3     2       1             0             0   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0              40              36       0  \n"
     ]
    }
   ],
   "source": [
    "# processor_cate = PETsARD.processor.Processor(\n",
    "#     metadata=loader.metadata,\n",
    "# )\n",
    "\n",
    "# metadata_col = loader.metadata.metadata['col']\n",
    "# colnames_discrete = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "# processor_cate.update_config(\n",
    "#     {'encoder': {col: 'encoder_label' if col in colnames_discrete else None for col in metadata_col},\n",
    "#      'scaler': {col: None for col in metadata_col},\n",
    "#      }\n",
    "# )\n",
    "\n",
    "# processor_cate.fit(\n",
    "#     data=splitter.data[1]['train'],\n",
    "#     sequence=None\n",
    "# )\n",
    "# preproc_data_cate = processor_cate.transform(\n",
    "#     data=splitter.data[1]['train']\n",
    "# )\n",
    "# print(preproc_data_cate.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing method: smartnoise-mst\n",
      "Synthesizer (SmartNoise): Fitting mst.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The transformer appears to have some continuous columns. Please provide only categorical or ordinal.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 16\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSynthesizing method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msynthesizing_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m synthesizer_cate \u001b[38;5;241m=\u001b[39m PETsARD\u001b[38;5;241m.\u001b[39mSynthesizer(\n\u001b[0;32m     12\u001b[0m     data\u001b[38;5;241m=\u001b[39mpreproc_data_cate,\n\u001b[0;32m     13\u001b[0m     synthesizing_method\u001b[38;5;241m=\u001b[39msynthesizing_method,\n\u001b[0;32m     14\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m \u001b[43msynthesizer_cate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(synthesizer_cate\u001b[38;5;241m.\u001b[39mdata_syn\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\synthesizer\\synthesizer.py:63\u001b[0m, in \u001b[0;36mSynthesizer.fit_sample\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_sample\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    Fit and sample from the synthesizer.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    The combination of the methods `fit()` and `sample()`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_syn: pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSynthesizer\u001b[38;5;241m.\u001b[39mfit_sample(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\synthesizer\\smartnoise.py:138\u001b[0m, in \u001b[0;36mSmartNoise.fit_sample\u001b[1;34m(self, sample_num_rows, reset_sampling, output_file_path)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_sample\u001b[39m(\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    121\u001b[0m         sample_num_rows:  \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    122\u001b[0m         reset_sampling:   \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    123\u001b[0m         output_file_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    125\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m    Fit and sample from the synthesizer.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    The combination of the methods `fit()` and `sample()`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m        data_syn (pd.DataFrame): The synthesized data.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(sample_num_rows, reset_sampling, output_file_path)\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\synthesizer\\smartnoise.py:43\u001b[0m, in \u001b[0;36mSmartNoise.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     38\u001b[0m     t \u001b[38;5;241m=\u001b[39m TableTransformer([IdentityTransformer() \n\u001b[0;32m     39\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])])\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# TODO - Only support cube-style synthesizer. \u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# GAN-style synthesizer needed to be implemented.\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Synthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSynthesizer (SmartNoise): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m spent \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mtime_start\u001b[38;5;250m \u001b[39m,\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sec.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m     )\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\snsynth\\mst\\mst.py:86\u001b[0m, in \u001b[0;36mMSTSynthesizer.fit\u001b[1;34m(self, data, transformer, categorical_columns, ordinal_columns, continuous_columns, preprocessor_eps, nullable, prng, *ignore)\u001b[0m\n\u001b[0;32m     84\u001b[0m cards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer\u001b[38;5;241m.\u001b[39mcardinality\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m (c \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cards):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe transformer appears to have some continuous columns. Please provide only categorical or ordinal.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m dimensionality \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(cards)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "\u001b[1;31mValueError\u001b[0m: The transformer appears to have some continuous columns. Please provide only categorical or ordinal."
     ]
    }
   ],
   "source": [
    "# smartnoise_methods_cate = [\n",
    "#     'smartnoise-mst',\n",
    "#     'smartnoise-pacsynth',\n",
    "# ]\n",
    "\n",
    "# for col in preproc_data_cate.columns:\n",
    "#     preproc_data_cate[col] = preproc_data_cate[col].astype('category')\n",
    "\n",
    "# for synthesizing_method in smartnoise_methods_cate:\n",
    "#     print(f\"Synthesizing method: {synthesizing_method}\")\n",
    "#     synthesizer_cate = PETsARD.Synthesizer(\n",
    "#         data=preproc_data_cate,\n",
    "#         synthesizing_method=synthesizing_method,\n",
    "#         epsilon=1.0,\n",
    "#     )\n",
    "#     synthesizer_cate.fit_sample()\n",
    "#     print(synthesizer_cate.data_syn.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor: inverse_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bin edges must be unique: array([0.        , 0.91376797, 0.93230577, 0.94042908, 0.94480317,\n       0.94896896, 0.95292647, 0.95625911, 0.95959175, 0.96292439,\n       0.96625703, 0.96938138, 0.97229744, 0.97479692, 0.9772964 ,\n       0.97958759, 0.98187878, 0.98396167, 0.98583628, 0.98771089,\n       0.98916892, 0.99062695, 0.99187669, 0.99291814, 0.9937513 ,\n       0.99458446, 0.99520933, 0.9958342 , 0.99645907, 0.99708394,\n       0.99770881, 0.99812539, 0.99854197, 0.99875026, 0.99895855,\n       0.99916684, 0.99937513, 0.99958342, 0.99979171, 1.        ,\n       1.        , 1.        ]).\nYou can drop duplicate edges by setting the 'duplicates' kwarg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m postproc_data \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_syn\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(postproc_data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\processor\\base.py:550\u001b[0m, in \u001b[0;36mProcessor.inverse_transform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 550\u001b[0m         transformed[col] \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocessor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inverse transformation done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformed\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\processor\\encoder.py:95\u001b[0m, in \u001b[0;36mEncoder.inverse_transform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_fitted:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnfittedError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe object is not fitted. Use .fit() first.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\PETsARD\\processor\\encoder.py:189\u001b[0m, in \u001b[0;36mEncoderUniform._inverse_transform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe range of the data is out of range.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please check the data again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    187\u001b[0m bins_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlower_values, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcut\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_lowest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m              \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\tile.py:293\u001b[0m, in \u001b[0;36mcut\u001b[1;34m(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mdiff(bins\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbins must increase monotonically.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 293\u001b[0m fac, bins \u001b[38;5;241m=\u001b[39m \u001b[43m_bins_to_cuts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_lowest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_lowest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduplicates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduplicates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mordered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _postprocess_for_cut(fac, bins, retbins, dtype, original)\n",
      "File \u001b[1;32md:\\Dropbox\\89_other_application\\GitHub\\PETsARD\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\tile.py:420\u001b[0m, in \u001b[0;36m_bins_to_cuts\u001b[1;34m(x, bins, right, labels, precision, include_lowest, dtype, duplicates, ordered)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_bins) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m duplicates \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 420\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    421\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBin edges must be unique: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(bins)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    422\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can drop duplicate edges by setting the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduplicates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m kwarg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    423\u001b[0m         )\n\u001b[0;32m    424\u001b[0m     bins \u001b[38;5;241m=\u001b[39m unique_bins\n\u001b[0;32m    426\u001b[0m side: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m right \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Bin edges must be unique: array([0.        , 0.91376797, 0.93230577, 0.94042908, 0.94480317,\n       0.94896896, 0.95292647, 0.95625911, 0.95959175, 0.96292439,\n       0.96625703, 0.96938138, 0.97229744, 0.97479692, 0.9772964 ,\n       0.97958759, 0.98187878, 0.98396167, 0.98583628, 0.98771089,\n       0.98916892, 0.99062695, 0.99187669, 0.99291814, 0.9937513 ,\n       0.99458446, 0.99520933, 0.9958342 , 0.99645907, 0.99708394,\n       0.99770881, 0.99812539, 0.99854197, 0.99875026, 0.99895855,\n       0.99916684, 0.99937513, 0.99958342, 0.99979171, 1.        ,\n       1.        , 1.        ]).\nYou can drop duplicate edges by setting the 'duplicates' kwarg"
     ]
    }
   ],
   "source": [
    "postproc_data = processor.inverse_transform(\n",
    "    data=synthesizer.data_syn\n",
    ")\n",
    "print(postproc_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0734 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Risk': 0.0,\n",
       " 'Risk_CI_btm': 0.0,\n",
       " 'Risk_CI_top': 0.6928102649963914,\n",
       " 'Attack_Rate': 0.32880988624667346,\n",
       " 'Attack_Rate_err': 0.32880988624667346,\n",
       " 'Baseline_Rate': 0.32880988624667346,\n",
       " 'Baseline_Rate_err': 0.32880988624667346,\n",
       " 'Control_Rate': 0.32880988624667346,\n",
       " 'Control_Rate_err': 0.32880988624667346}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='anonymeter-singlingout-univariate',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': splitter.data[1]['validation']\n",
    "    },\n",
    "    anonymeter_n_attacks=2 # 2000\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (Anonymeter - Linkability): Now is Linkability Evaluator\n",
      "Evaluator (Anonymeter - Linkability): aux_cols are [age, fnlwgt, race, gender, native-country]\n",
      "                                      and [workclass, education, capital-gain, capital-loss, hours-per-week].\n",
      "Evaluator (Anonymeter - Linkability): Evaluator time: 0.0 sec.\n",
      "Evaluator (Anonymeter): Evaluating  Linkability.\n",
      "Evaluator (Anonymeter): Evaluating Linkability spent 8.6534 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Risk': 0.0,\n",
       " 'Risk_CI_btm': 0.0,\n",
       " 'Risk_CI_top': 0.6928102649963914,\n",
       " 'Attack_Rate': 0.32880988624667346,\n",
       " 'Attack_Rate_err': 0.32880988624667346,\n",
       " 'Baseline_Rate': 0.32880988624667346,\n",
       " 'Baseline_Rate_err': 0.32880988624667346,\n",
       " 'Control_Rate': 0.32880988624667346,\n",
       " 'Control_Rate_err': 0.32880988624667346}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='anonymeter-linkability',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': splitter.data[1]['validation']\n",
    "    },\n",
    "    anonymeter_n_attacks=2, # 2000,\n",
    "    anonymeter_n_neighbors=10,\n",
    "    anonymeter_n_jobs=-1,\n",
    "    anonymeter_aux_cols=[\n",
    "        ['age', 'fnlwgt', 'race', 'gender', 'native-country'],\n",
    "        ['workclass', 'education', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    ]\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (Anonymeter - Inference): Now is Inference Evaluator\n",
      "Evaluator (Anonymeter - Inference): Evaluator time: 0.0 sec.\n",
      "Evaluator (Anonymeter): Evaluating  Inference.\n",
      "Evaluator (Anonymeter): Evaluating Inference spent 0.6498 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Risk': 0.0,\n",
       " 'Risk_CI_btm': 0.0,\n",
       " 'Risk_CI_top': 0.013449535585480343,\n",
       " 'Attack_Rate': 0.08915647695108263,\n",
       " 'Attack_Rate_err': 0.024683334547474907,\n",
       " 'Baseline_Rate': 0.09114122827015952,\n",
       " 'Baseline_Rate_err': 0.0249352437952306,\n",
       " 'Control_Rate': 0.11495824409908227,\n",
       " 'Control_Rate_err': 0.027695443904980018}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='anonymeter-inference',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': splitter.data[1]['validation']\n",
    "    },\n",
    "    anonymeter_n_attacks=2, #2000,\n",
    "    anonymeter_n_jobs=-1,\n",
    "    anonymeter_secret='age'\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (SDMetrics): Evaluating QualityReport.\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 67.76it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:05<00:00, 18.18it/s]\n",
      "\n",
      "Overall Score: 74.06%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 91.81%\n",
      "- Column Pair Trends: 56.31%\n",
      "Evaluator (SDMetrics): Evaluating QualityReport spent 6.0073 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.7405721651768964,\n",
       " 'properties': {'Column Shapes': {'Score': 0.918070881955508},\n",
       "  'Column Pair Trends': {'Score': 0.5630734483982847}},\n",
       " 'details': {'Column Shapes':              Column        Metric     Score\n",
       "  0               age  KSComplement  0.948650\n",
       "  1         workclass  TVComplement  0.996087\n",
       "  2            fnlwgt  KSComplement  0.950445\n",
       "  3         education  TVComplement  0.539399\n",
       "  4   educational-num  KSComplement  0.881909\n",
       "  5    marital-status  TVComplement  0.971009\n",
       "  6        occupation  TVComplement  0.981831\n",
       "  7      relationship  TVComplement  0.962217\n",
       "  8              race  TVComplement  0.997025\n",
       "  9            gender  TVComplement  0.998437\n",
       "  10     capital-gain  KSComplement  0.918025\n",
       "  11     capital-loss  KSComplement  0.952909\n",
       "  12   hours-per-week  KSComplement  0.692668\n",
       "  13   native-country  TVComplement  0.991754\n",
       "  14           income  TVComplement  0.988698,\n",
       "  'Column Pair Trends':            Column 1         Column 2                 Metric     Score  \\\n",
       "  0               age        workclass  ContingencySimilarity  0.867992   \n",
       "  1               age           fnlwgt  CorrelationSimilarity  0.989224   \n",
       "  2               age        education  ContingencySimilarity  0.523663   \n",
       "  3               age  educational-num  CorrelationSimilarity  0.978033   \n",
       "  4               age   marital-status  ContingencySimilarity  0.798824   \n",
       "  ..              ...              ...                    ...       ...   \n",
       "  100    capital-loss   native-country  ContingencySimilarity  0.006040   \n",
       "  101    capital-loss           income  ContingencySimilarity  0.006066   \n",
       "  102  hours-per-week   native-country  ContingencySimilarity  0.519466   \n",
       "  103  hours-per-week           income  ContingencySimilarity  0.509003   \n",
       "  104  native-country           income  ContingencySimilarity  0.972553   \n",
       "  \n",
       "       Real Correlation  Synthetic Correlation Error  \n",
       "  0                 NaN                    NaN  None  \n",
       "  1           -0.074321              -0.052768  None  \n",
       "  2                 NaN                    NaN  None  \n",
       "  3            0.030102               0.074036  None  \n",
       "  4                 NaN                    NaN  None  \n",
       "  ..                ...                    ...   ...  \n",
       "  100               NaN                    NaN  None  \n",
       "  101               NaN                    NaN  None  \n",
       "  102               NaN                    NaN  None  \n",
       "  103               NaN                    NaN  None  \n",
       "  104               NaN                    NaN  None  \n",
       "  \n",
       "  [105 rows x 7 columns]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='sdmetrics-single_table-qualityreport',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (SDMetrics): Evaluating DiagnosticReport.\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|██████████| 15/15 [00:00<00:00, 199.66it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Evaluator (SDMetrics): Evaluating DiagnosticReport spent 0.0853 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 1.0,\n",
       " 'properties': {'Data Validity': {'Score': 1.0},\n",
       "  'Data Structure': {'Score': 1.0}},\n",
       " 'details': {'Data Validity':              Column             Metric  Score\n",
       "  0               age  BoundaryAdherence    1.0\n",
       "  1         workclass  CategoryAdherence    1.0\n",
       "  2            fnlwgt  BoundaryAdherence    1.0\n",
       "  3         education  CategoryAdherence    1.0\n",
       "  4   educational-num  BoundaryAdherence    1.0\n",
       "  5    marital-status  CategoryAdherence    1.0\n",
       "  6        occupation  CategoryAdherence    1.0\n",
       "  7      relationship  CategoryAdherence    1.0\n",
       "  8              race  CategoryAdherence    1.0\n",
       "  9            gender  CategoryAdherence    1.0\n",
       "  10     capital-gain  BoundaryAdherence    1.0\n",
       "  11     capital-loss  BoundaryAdherence    1.0\n",
       "  12   hours-per-week  BoundaryAdherence    1.0\n",
       "  13   native-country  CategoryAdherence    1.0\n",
       "  14           income  CategoryAdherence    1.0,\n",
       "  'Data Structure':            Metric  Score\n",
       "  0  TableStructure    1.0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='sdmetrics-single_table-diagnosticreport',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader - Benchmarker: file benchmark\\adult.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "Executor - Loader: adult loading time: 7.0139 sec.\n",
      "Executor - Splitter: 0.8 splitting time: 0.0689 sec.\n",
      "No self-defined config passed.  Generate a config automatically.\n",
      "Executor - Processor (preprocessing): drop-IQR-stanard-label processing time: 0.4141 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0469 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 7.8931 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21557 rows (same as raw) in 1.2511 sec.\n",
      "Executor - Synthesizer: GaussianCopula synthesizing time: 9.1911 sec.\n",
      "Executor - Processor (postprocessing): drop-IQR-stanard-label processing time: 0.0288 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.045 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n",
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 4.9866 sec.\n",
      "No self-defined config passed.  Generate a config automatically.\n",
      "Executor - Processor (preprocessing): drop-IQR-stanard-label processing time: 0.3603 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0228 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 7.7783 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21541 rows (same as raw) in 1.4599 sec.\n",
      "Executor - Synthesizer: GaussianCopula synthesizing time: 9.2625 sec.\n",
      "Executor - Processor (postprocessing): drop-IQR-stanard-label processing time: 0.0338 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0419 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n",
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 4.6758 sec.\n",
      "====== ====== ====== ====== ====== ======\n",
      "Executor (run - single process): Total execution time: 38.4373 sec.\n",
      "====== ====== ====== ====== ====== ======\n",
      "{'Attack_Rate': 0.3967253428113813,\n",
      " 'Attack_Rate_err': 0.3967253428113813,\n",
      " 'Baseline_Rate': 0.3967253428113813,\n",
      " 'Baseline_Rate_err': 0.3967253428113813,\n",
      " 'Control_Rate': 0.3967253428113813,\n",
      " 'Control_Rate_err': 0.3967253428113813,\n",
      " 'Risk': 0.0,\n",
      " 'Risk_CI_btm': 0.0,\n",
      " 'Risk_CI_top': 0.9300148011448004}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "\n",
    "para_Executor = {\n",
    "    'Loader': {\n",
    "        'adult': {\n",
    "            'filepath': 'benchmark://adult',\n",
    "            'na_values': {k: '?' for k in [\n",
    "                'workclass',\n",
    "                'occupation',\n",
    "                'native-country'\n",
    "            ]}\n",
    "        }\n",
    "    },\n",
    "    'Splitter': {\n",
    "        '0.8': {\n",
    "            'num_samples': 2,\n",
    "            'train_split_ratio': 0.8,\n",
    "        }\n",
    "    },\n",
    "    'Processor': {\n",
    "        'drop-IQR-stanard-label': {\n",
    "            'missing': {\n",
    "                'method': 'missing_drop',\n",
    "                'all': True\n",
    "            },\n",
    "            #'method': , # ValueError: y contains previously unseen labels:\n",
    "            'encoder': [\n",
    "                {'method': 'encoder_label',\n",
    "                 'include': ['education','marital-status','relationship','gender']\n",
    "                },\n",
    "                {'method': 'encoder_uniform',\n",
    "                 'include': ['workclass', 'occupation', 'race', 'native-country', 'income']\n",
    "                }\n",
    "            ],\n",
    "            'outlier': {\n",
    "                'method': 'outlier_iqr',\n",
    "                'include': 'hours-per-week'\n",
    "            },\n",
    "            'scaler': {\n",
    "                'method': 'scaler_standard',\n",
    "                'exclude': ['hours-per-week',\n",
    "                    'workclass', 'education', 'marital-status',\n",
    "                    'occupation', 'relationship', 'race', 'gender',\n",
    "                    'native-country', 'income'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'Synthesizer': {\n",
    "        'GaussianCopula': {\n",
    "            'synthesizing_method': 'sdv-singletable-gaussiancopula'\n",
    "        }\n",
    "    },\n",
    "    'Evaluator': {\n",
    "        'anonymeter-SinglingOut': {\n",
    "            'evaluating_method': 'anonymeter-singlingout-univariate',\n",
    "            'anonymeter_n_attacks': 1,  # 2000'\n",
    "            'anonymeter_num_samples': 2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "executor_single = PETsARD.Executor(**para_Executor)\n",
    "executor_single.run()\n",
    "pprint(\n",
    "    executor_single.evaluator[(\n",
    "        'adult',\n",
    "        '0.8',\n",
    "        1,\n",
    "        'drop-IQR-stanard-label',\n",
    "        'GaussianCopula',\n",
    "        'anonymeter-SinglingOut',\n",
    "        1\n",
    "    )].Evaluator.evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .run_parallel()\n",
    "Not applicable now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|          | 0/1 [00:20<?, ?it/s]s/it]\n",
      "Splitting: 100%|██████████| 1/1 [00:20<00:00, 20.74s/it]\n",
      "Loading: 100%|██████████| 1/1 [00:20<00:00, 20.74s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'Processor.__init__.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\process.py\", line 211, in _sendback_result\n    result_queue.put(_ResultItem(work_id, result=result,\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py\", line 371, in put\n    obj = _ForkingPickler.dumps(obj)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nAttributeError: Can't pickle local object 'Processor.__init__.<locals>.<lambda>'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 73\u001b[0m\n\u001b[0;32m     11\u001b[0m para_Executor \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoader\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     }\n\u001b[0;32m     69\u001b[0m }\n\u001b[0;32m     72\u001b[0m executor_parallel \u001b[38;5;241m=\u001b[39m PETsARD\u001b[38;5;241m.\u001b[39mExecutor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpara_Executor)\n\u001b[1;32m---> 73\u001b[0m \u001b[43mexecutor_parallel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m pprint(\n\u001b[0;32m     75\u001b[0m     executor_parallel\u001b[38;5;241m.\u001b[39mevaluator[(\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m     )]\u001b[38;5;241m.\u001b[39mEvaluator\u001b[38;5;241m.\u001b[39mevaluation\n\u001b[0;32m     84\u001b[0m )\n",
      "File \u001b[1;32mD:\\Dropbox\\89_其他應用\\GitHub\\PETsARD\\PETsARD\\Executor.py:541\u001b[0m, in \u001b[0;36mExecutor.run_parallel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    539\u001b[0m trials_till_proc \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proc_future \u001b[38;5;129;01min\u001b[39;00m as_completed(proc_futures):\n\u001b[1;32m--> 541\u001b[0m     proc_result \u001b[38;5;241m=\u001b[39m \u001b[43mproc_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m     proc_name \u001b[38;5;241m=\u001b[39m proc_futures[proc_future][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor[proc_name] \u001b[38;5;241m=\u001b[39m proc_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'Processor.__init__.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD')\n",
    "os.chdir('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD\\\\demo')\n",
    "\n",
    "import PETsARD\n",
    "\n",
    "\n",
    "para_Executor = {\n",
    "    'Loader': {\n",
    "        'adult': {\n",
    "            'filepath': 'benchmark://adult',\n",
    "            'na_values': {k: '?' for k in [\n",
    "                'workclass',\n",
    "                'occupation',\n",
    "                'native-country'\n",
    "            ]}\n",
    "        }\n",
    "    },\n",
    "    'Splitter': {\n",
    "        '0.8': {\n",
    "            'num_samples': 2,\n",
    "            'train_split_ratio': 0.8,\n",
    "        }\n",
    "    },\n",
    "    'Processor': {\n",
    "        'drop-IQR-stanard-label': {\n",
    "            'missingist': {\n",
    "                'method': 'missingist_drop',\n",
    "                'all': True\n",
    "            },\n",
    "            #'method': , # ValueError: y contains previously unseen labels:\n",
    "            'encoder': [\n",
    "                {'method': 'encoder_label',\n",
    "                 'include': ['education','marital-status','relationship','gender']\n",
    "                },\n",
    "                {'method': 'encoder_uniform',\n",
    "                 'include': ['workclass', 'occupation', 'race', 'native-country', 'income']\n",
    "                }\n",
    "            ],\n",
    "            'outlierist': {\n",
    "                'method': 'outlierist_iqr',\n",
    "                'include': 'hours-per-week'\n",
    "            },\n",
    "            'scaler': {\n",
    "                'method': 'scaler_standard',\n",
    "                'exclude': ['hours-per-week',\n",
    "                    'workclass', 'education', 'marital-status',\n",
    "                    'occupation', 'relationship', 'race', 'gender',\n",
    "                    'native-country', 'income'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'Synthesizer': {\n",
    "        'GaussianCopula': {\n",
    "            'synthesizing_method': 'sdv-singletable-gaussiancopula'\n",
    "        }\n",
    "    },\n",
    "    'Evaluator': {\n",
    "        'anonymeter-SinglingOut': {\n",
    "            'evaluating_method': 'anonymeter-singlingout-univariate',\n",
    "            'anonymeter_n_attacks': 1,  # 2000'\n",
    "            'anonymeter_num_samples': 2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Processor contains lambda function, but python couldn't pickle it.\n",
    "# so Processor .run_parallel() didn't valid after Processor migration.\n",
    "executor_parallel = PETsARD.Executor(**para_Executor)\n",
    "executor_parallel.run_parallel()\n",
    "pprint(\n",
    "    executor_parallel.evaluator[(\n",
    "        'adult',\n",
    "        '0.8',\n",
    "        1,\n",
    "        'drop-IQR-stanard-label',\n",
    "        'GaussianCopula',\n",
    "        'anonymeter-SinglingOut',\n",
    "        1\n",
    "    )].Evaluator.evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un arrangment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Result(__evaluator):\n",
    "    import numpy as np\n",
    "    __dict_result = {}\n",
    "    __para_to_handle = [('Risk', ['risk()', 'value']), ('Risk_CI_btm', ['risk()', 'ci[0]']), ('Risk_CI_top', ['risk()', 'ci[1]']), ('Attack_Rate', ['results()', 'attack_rate', 'value']), ('Attack_Rate_err', ['results()', 'attack_rate', 'error']), ('Baseline_Rate', ['results()', 'baseline_rate', 'value']), ('Baseline_Rate_err', ['results()', 'baseline_rate', 'error']), ('Control_Rate', ['results()', 'control_rate', 'value']), ('Control_Rate_err', ['results()', 'control_rate', 'error'])\n",
    "                        ]\n",
    "    for __key, __attrs in __para_to_handle:\n",
    "        try:\n",
    "            __attr_value = __evaluator\n",
    "            for __attr in __attrs:\n",
    "                if '()' in __attr:\n",
    "                    __method_name = __attr.split('(')[0]\n",
    "                    if hasattr(__attr_value, __method_name):\n",
    "                        __method = getattr(__attr_value, __method_name)\n",
    "                        if callable(__method):\n",
    "                            __attr_value = __method()\n",
    "                        else:\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                elif '[' in __attr:\n",
    "                    __attr_name = __attr.split('[')[0]\n",
    "                    __index = int(__attr.split('[')[1].rstrip(']'))\n",
    "                    if hasattr(__attr_value, __attr_name)\\\n",
    "                            and isinstance(getattr(__attr_value, __attr_name), (list, dict, tuple)):\n",
    "                        try:\n",
    "                            __attr_value = getattr(\n",
    "                                __attr_value, __attr_name)[__index]\n",
    "                        except (IndexError, KeyError):\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                else:\n",
    "                    __attr_value = getattr(__attr_value, __attr)\n",
    "            __dict_result[__key] = __attr_value\n",
    "        except Exception as e:\n",
    "            __dict_result[__key] = np.nan\n",
    "    return __dict_result\n",
    "\n",
    "\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    from anonymeter.evaluators import SinglingOutEvaluator\n",
    "    print(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\")\n",
    "    evaluator = SinglingOutEvaluator(ori=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), syn=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), control=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\"), n_attacks=2000\n",
    "                                     )\n",
    "    try:\n",
    "        evaluator.evaluate(mode='univariate')\n",
    "        print(Result(evaluator))\n",
    "    except RuntimeError as ex:\n",
    "        print(f\"Singling out evaluation failed with {ex}.\"\n",
    "              \"Please re-run this cell.\"\n",
    "              \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "              \"make the evaluation slower.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "for type in ['][Ori]', '][Ctrl]', '-1-1]Postproc']:\n",
    "    for combo in itertools.combinations(['01', '02', '03', '04', '05', '06'], 2):\n",
    "        df_a = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[0]}{type}.csv\")\n",
    "        df_b = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[1]}{type}.csv\")\n",
    "        if df_a.equals(df_b):\n",
    "            print(type+': '+str(combo))\n",
    "            print(\"They're same!!??\")\n",
    "        # else:\n",
    "            # print(type+': '+str(combo))\n",
    "            # print(\"They're different.\")\n",
    "print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Loader: adult loading time: 6.8097 sec.\n",
      "Executor - Splitter: 0.8 splitting time: 0.339 sec.\n",
      "Preprocessor - Outlierist (IQR): Dropped  1060 rows on fnlwgt         . Kept [-63981.5, 419234.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   227 rows on educational-num. Kept [3.0, 19.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  1705 rows on capital-loss   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  9432 rows on hours-per-week . Kept [32.5, 52.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   214 rows on age            . Kept [-0.5, 75.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  3030 rows on capital-gain   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Totally Dropped 13932 in 36207 rows.\n",
      "Preprocessor - Encoder (Label): Column native-country  been labelized from 0 to 39.\n",
      "Preprocessor - Encoder (Label): Column gender          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column race            been labelized from 0 to  4.\n",
      "Preprocessor - Encoder (Label): Column relationship    been labelized from 0 to  5.\n",
      "Preprocessor - Encoder (Label): Column education       been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column income          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column workclass       been labelized from 0 to  6.\n",
      "Preprocessor - Encoder (Label): Column occupation      been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column marital-status  been labelized from 0 to  6.\n",
      "Executor - Preprocessor: drop-IQR-stanard-NA preprocessing time: 0.0764 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.021 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula spent 12.1284 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCoupula # 22275 rows (same as raw) in 1.313 sec.\n",
      "Executor - Synthesizer: GaussianCoupula synthesizing time: 13.466 sec.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding native-country.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding gender.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding race.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding relationship.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding education.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding income.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding workclass.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding occupation.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding marital-status.\n",
      "Executor - Postprocessor: postprocessing time: 0.0142 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0404 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 765 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 131.365 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0322 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 802 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 2 trials evaluating time: 131.1331 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0336 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 830 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 3 trials evaluating time: 131.5346 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0356 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 794 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 4 trials evaluating time: 131.4821 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0351 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 821 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 5 trials evaluating time: 132.587 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.036 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 800 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 6 trials evaluating time: 131.8783 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0352 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 799 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Result(__evaluator):\n",
    "    import numpy as np\n",
    "    __dict_result = {}\n",
    "    __para_to_handle = [('Risk', ['risk()', 'value']), ('Risk_CI_btm', ['risk()', 'ci[0]']), ('Risk_CI_top', ['risk()', 'ci[1]']), ('Attack_Rate', ['results()', 'attack_rate', 'value']), ('Attack_Rate_err', ['results()', 'attack_rate', 'error']), ('Baseline_Rate', ['results()', 'baseline_rate', 'value']), ('Baseline_Rate_err', ['results()', 'baseline_rate', 'error']), ('Control_Rate', ['results()', 'control_rate', 'value']), ('Control_Rate_err', ['results()', 'control_rate', 'error'])\n",
    "                        ]\n",
    "    for __key, __attrs in __para_to_handle:\n",
    "        try:\n",
    "            __attr_value = __evaluator\n",
    "            for __attr in __attrs:\n",
    "                if '()' in __attr:\n",
    "                    __method_name = __attr.split('(')[0]\n",
    "                    if hasattr(__attr_value, __method_name):\n",
    "                        __method = getattr(__attr_value, __method_name)\n",
    "                        if callable(__method):\n",
    "                            __attr_value = __method()\n",
    "                        else:\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                elif '[' in __attr:\n",
    "                    __attr_name = __attr.split('[')[0]\n",
    "                    __index = int(__attr.split('[')[1].rstrip(']'))\n",
    "                    if hasattr(__attr_value, __attr_name)\\\n",
    "                            and isinstance(getattr(__attr_value, __attr_name), (list, dict, tuple)):\n",
    "                        try:\n",
    "                            __attr_value = getattr(\n",
    "                                __attr_value, __attr_name)[__index]\n",
    "                        except (IndexError, KeyError):\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                else:\n",
    "                    __attr_value = getattr(__attr_value, __attr)\n",
    "            __dict_result[__key] = __attr_value\n",
    "        except Exception as e:\n",
    "            __dict_result[__key] = np.nan\n",
    "    return __dict_result\n",
    "\n",
    "\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    from anonymeter.evaluators import SinglingOutEvaluator\n",
    "    print(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\")\n",
    "    evaluator = SinglingOutEvaluator(ori=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), syn=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), control=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\"), n_attacks=2000\n",
    "                                     )\n",
    "    try:\n",
    "        evaluator.evaluate(mode='univariate')\n",
    "        print(Result(evaluator))\n",
    "    except RuntimeError as ex:\n",
    "        print(f\"Singling out evaluation failed with {ex}.\"\n",
    "              \"Please re-run this cell.\"\n",
    "              \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "              \"make the evaluation slower.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    eval = PETsARD.Evaluator(evaluating_method='anonymeter-singlingout-univariate', data={'ori': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), 'syn': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), 'control': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\")\n",
    "                                                                                          }, anonymeter_n_attacks=500\n",
    "                             )\n",
    "    eval.eval()\n",
    "    print(eval.Evaluator.evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 7 trials evaluating time: 131.5421 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0354 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for type in ['][Ori]', '][Ctrl]', '-1-1]Postproc']:\n",
    "    for combo in itertools.combinations(['01', '02', '03', '04', '05', '06'], 2):\n",
    "        df_a = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[0]}{type}.csv\")\n",
    "        df_b = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[1]}{type}.csv\")\n",
    "        if df_a.equals(df_b):\n",
    "            print(type+': '+str(combo))\n",
    "            print(\"They're same!!??\")\n",
    "        # else:\n",
    "            # print(type+': '+str(combo))\n",
    "            # print(\"They're different.\")\n",
    "print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'Loader': {\n",
    "        'NHANES': {\n",
    "            'filepath': '../[sunset]/data/[NHANES] B.csv',\n",
    "            'header_exist': False,\n",
    "            'header_names': ['gen', 'age', 'race', 'edu', 'mar', 'bmi', 'dep', 'pir', 'gh', 'mets', 'qm', 'dia']\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
