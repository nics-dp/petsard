{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PETsARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import PETsARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD')\n",
    "os.chdir('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD\\\\demo')\n",
    "# sys.path.append('/home/ec2-user/SageMaker/PETs-Experiment')\n",
    "# os.chdir('/home/ec2-user/SageMaker/PETs-Experiment/demo')\n",
    "\n",
    "import PETsARD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module-by-Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader - Benchmarker: file benchmark\\adult.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "   age workclass  fnlwgt education  educational-num marital-status  \\\n",
      "0   25   Private  226802      11th                7  Never-married   \n",
      "\n",
      "          occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Machine-op-inspct    Own-child  Black   Male             0             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              40  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "loader = PETsARD.Loader(\n",
    "    filepath='benchmark://adult',\n",
    "    na_values={k: '?' for k in [\n",
    "        'workclass',\n",
    "        'occupation',\n",
    "        'native-country'\n",
    "    ]}\n",
    ")\n",
    "print(loader.data.head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col': {'age': {'dtype': dtype('int8'),\n",
      "                 'infer_dtype': 'numerical',\n",
      "                 'na_percentage': 0.0},\n",
      "         'capital-gain': {'dtype': dtype('int32'),\n",
      "                          'infer_dtype': 'numerical',\n",
      "                          'na_percentage': 0.0},\n",
      "         'capital-loss': {'dtype': dtype('int16'),\n",
      "                          'infer_dtype': 'numerical',\n",
      "                          'na_percentage': 0.0},\n",
      "         'education': {'dtype': CategoricalDtype(categories=['10th', '11th', '12th', '1st-4th', '5th-6th', '7th-8th',\n",
      "                  '9th', 'Assoc-acdm', 'Assoc-voc', 'Bachelors', 'Doctorate',\n",
      "                  'HS-grad', 'Masters', 'Preschool', 'Prof-school',\n",
      "                  'Some-college'],\n",
      ", ordered=False),\n",
      "                       'infer_dtype': 'categorical',\n",
      "                       'na_percentage': 0.0},\n",
      "         'educational-num': {'dtype': dtype('int8'),\n",
      "                             'infer_dtype': 'numerical',\n",
      "                             'na_percentage': 0.0},\n",
      "         'fnlwgt': {'dtype': dtype('int32'),\n",
      "                    'infer_dtype': 'numerical',\n",
      "                    'na_percentage': 0.0},\n",
      "         'gender': {'dtype': CategoricalDtype(categories=['Female', 'Male'], ordered=False),\n",
      "                    'infer_dtype': 'categorical',\n",
      "                    'na_percentage': 0.0},\n",
      "         'hours-per-week': {'dtype': dtype('int8'),\n",
      "                            'infer_dtype': 'numerical',\n",
      "                            'na_percentage': 0.0},\n",
      "         'income': {'dtype': CategoricalDtype(categories=['<=50K', '>50K'], ordered=False),\n",
      "                    'infer_dtype': 'categorical',\n",
      "                    'na_percentage': 0.0},\n",
      "         'marital-status': {'dtype': CategoricalDtype(categories=['Divorced', 'Married-AF-spouse', 'Married-civ-spouse',\n",
      "                  'Married-spouse-absent', 'Never-married', 'Separated',\n",
      "                  'Widowed'],\n",
      ", ordered=False),\n",
      "                            'infer_dtype': 'categorical',\n",
      "                            'na_percentage': 0.0},\n",
      "         'native-country': {'dtype': CategoricalDtype(categories=['Cambodia', 'Canada', 'China', 'Columbia', 'Cuba',\n",
      "                  'Dominican-Republic', 'Ecuador', 'El-Salvador', 'England',\n",
      "                  'France', 'Germany', 'Greece', 'Guatemala', 'Haiti',\n",
      "                  'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n",
      "                  'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos',\n",
      "                  'Mexico', 'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru',\n",
      "                  'Philippines', 'Poland', 'Portugal', 'Puerto-Rico',\n",
      "                  'Scotland', 'South', 'Taiwan', 'Thailand', 'Trinadad&Tobago',\n",
      "                  'United-States', 'Vietnam', 'Yugoslavia'],\n",
      ", ordered=False),\n",
      "                            'infer_dtype': 'categorical',\n",
      "                            'na_percentage': 0.017546374022357807},\n",
      "         'occupation': {'dtype': CategoricalDtype(categories=['Adm-clerical', 'Armed-Forces', 'Craft-repair',\n",
      "                  'Exec-managerial', 'Farming-fishing', 'Handlers-cleaners',\n",
      "                  'Machine-op-inspct', 'Other-service', 'Priv-house-serv',\n",
      "                  'Prof-specialty', 'Protective-serv', 'Sales', 'Tech-support',\n",
      "                  'Transport-moving'],\n",
      ", ordered=False),\n",
      "                        'infer_dtype': 'categorical',\n",
      "                        'na_percentage': 0.05751197739650301},\n",
      "         'race': {'dtype': CategoricalDtype(categories=['Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other',\n",
      "                  'White'],\n",
      ", ordered=False),\n",
      "                  'infer_dtype': 'categorical',\n",
      "                  'na_percentage': 0.0},\n",
      "         'relationship': {'dtype': CategoricalDtype(categories=['Husband', 'Not-in-family', 'Other-relative', 'Own-child',\n",
      "                  'Unmarried', 'Wife'],\n",
      ", ordered=False),\n",
      "                          'infer_dtype': 'categorical',\n",
      "                          'na_percentage': 0.0},\n",
      "         'workclass': {'dtype': CategoricalDtype(categories=['Federal-gov', 'Local-gov', 'Never-worked', 'Private',\n",
      "                  'Self-emp-inc', 'Self-emp-not-inc', 'State-gov',\n",
      "                  'Without-pay'],\n",
      ", ordered=False),\n",
      "                       'infer_dtype': 'categorical',\n",
      "                       'na_percentage': 0.05730723557593874}},\n",
      " 'global': {'col_num': 15,\n",
      "            'na_percentage': 0.07411653904426518,\n",
      "            'row_num': 48842}}\n"
     ]
    }
   ],
   "source": [
    "pprint(loader.metadata.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39073\n",
      "9769\n",
      "   age workclass  fnlwgt education  educational-num marital-status  \\\n",
      "0   25   Private  226802      11th                7  Never-married   \n",
      "\n",
      "          occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Machine-op-inspct    Own-child  Black   Male             0             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              40  United-States  <=50K  \n",
      "   age workclass  fnlwgt education  educational-num      marital-status  \\\n",
      "0   27   Private  205145   HS-grad                9  Married-civ-spouse   \n",
      "\n",
      "          occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Machine-op-inspct      Husband  White   Male             0             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              40  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "splitter = PETsARD.Splitter(\n",
    "    data=loader.data,\n",
    "    num_samples=1,  # 30,\n",
    "    train_split_ratio=0.8\n",
    ")\n",
    "print(splitter.data[1]['train'].shape[0])\n",
    "print(splitter.data[1]['validation'].shape[0])\n",
    "print(splitter.data[1]['train'].head(1))\n",
    "print(splitter.data[1]['validation'].head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor: transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoder': {'education': 'encoder_label',\n",
      "             'gender': 'encoder_label',\n",
      "             'income': 'encoder_uniform',\n",
      "             'marital-status': 'encoder_label',\n",
      "             'native-country': 'encoder_uniform',\n",
      "             'occupation': 'encoder_uniform',\n",
      "             'race': 'encoder_uniform',\n",
      "             'relationship': 'encoder_label',\n",
      "             'workclass': 'encoder_uniform'},\n",
      " 'missingist': {'age': 'missingist_drop',\n",
      "                'capital-gain': 'missingist_drop',\n",
      "                'capital-loss': 'missingist_drop',\n",
      "                'education': 'missingist_drop',\n",
      "                'educational-num': 'missingist_drop',\n",
      "                'fnlwgt': 'missingist_drop',\n",
      "                'gender': 'missingist_drop',\n",
      "                'hours-per-week': 'missingist_drop',\n",
      "                'income': 'missingist_drop',\n",
      "                'marital-status': 'missingist_drop',\n",
      "                'native-country': 'missingist_drop',\n",
      "                'occupation': 'missingist_drop',\n",
      "                'race': 'missingist_drop',\n",
      "                'relationship': 'missingist_drop',\n",
      "                'workclass': 'missingist_drop'},\n",
      " 'outlierist': {'hours-per-week': 'outlierist_iqr'},\n",
      " 'scaler': {'age': None,\n",
      "            'capital-gain': None,\n",
      "            'capital-loss': None,\n",
      "            'education': None,\n",
      "            'educational-num': None,\n",
      "            'fnlwgt': None,\n",
      "            'gender': None,\n",
      "            'hours-per-week': None,\n",
      "            'income': None,\n",
      "            'marital-status': None,\n",
      "            'native-country': None,\n",
      "            'occupation': None,\n",
      "            'race': None,\n",
      "            'relationship': None,\n",
      "            'workclass': None}}\n"
     ]
    }
   ],
   "source": [
    "processor_config = PETsARD.Config.ProcessorConfig(\n",
    "    colnames = list(loader.metadata.metadata['col'].keys()),\n",
    "    config = {\n",
    "        'missingist': {\n",
    "            'method': 'missingist_drop',\n",
    "            'all': True\n",
    "        },\n",
    "        #'method': , # ValueError: y contains previously unseen labels:\n",
    "        'encoder': [\n",
    "            {'method': 'encoder_label',\n",
    "                'include': ['education','marital-status','relationship','gender']\n",
    "            },\n",
    "            {'method': 'encoder_uniform',\n",
    "                'include': ['workclass', 'occupation', 'race', 'native-country', 'income']\n",
    "            }\n",
    "        ],\n",
    "        'outlierist': {\n",
    "            'method': 'outlierist_iqr',\n",
    "            'include': 'hours-per-week'\n",
    "        },\n",
    "        'scaler': None\n",
    "        # 'scaler': {\n",
    "        #     'method': 'scaler_standard',\n",
    "        #     'exclude': ['hours-per-week',\n",
    "        #         'workclass', 'education', 'marital-status',\n",
    "        #         'occupation', 'relationship', 'race', 'gender',\n",
    "        #         'native-country', 'income'\n",
    "        #     ]\n",
    "        # }\n",
    "    }\n",
    ")\n",
    "pprint(processor_config.config_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No self-defined config passed.  Generate a config automatically.\n",
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0   25   0.305754  226802          1                7               4   \n",
      "\n",
      "   occupation  relationship     race  gender  capital-gain  capital-loss  \\\n",
      "0     0.77943             3  0.89837       1             0             0   \n",
      "\n",
      "   hours-per-week  native-country    income  \n",
      "0              40        0.240867  0.480535  \n"
     ]
    }
   ],
   "source": [
    "processor = PETsARD.Processor.Processor(metadata=loader.metadata,)\n",
    "processor.update_config(processor_config.config_transform)\n",
    "processor.fit(\n",
    "    data=splitter.data[1]['train'],\n",
    "    sequence=None\n",
    ")\n",
    "preproc_data = processor.transform(\n",
    "    data=splitter.data[1]['train']\n",
    ")\n",
    "print(preproc_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0415 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 9.4193 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21486 rows (same as raw) in 1.434 sec.\n",
      "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
      "0  1.274034   0.847556 -0.214793         15         -1.03573               0   \n",
      "\n",
      "   occupation  relationship      race  gender  capital-gain  capital-loss  \\\n",
      "0    0.193904             0  0.323358       1     -0.145386     -0.216634   \n",
      "\n",
      "   hours-per-week  native-country   income  \n",
      "0        0.176305        0.662747  0.67922  \n"
     ]
    }
   ],
   "source": [
    "synthesizer = PETsARD.Synthesizer(\n",
    "    data=preproc_data,\n",
    "    synthesizing_method='sdv-singletable-gaussiancopula'\n",
    ")\n",
    "synthesizer.fit_sample()\n",
    "print(synthesizer.data_syn.head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor: inverse_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age  workclass         fnlwgt     education  educational-num  \\\n",
      "0  56.054993  Local-gov  167216.417519  Some-college         7.409966   \n",
      "\n",
      "  marital-status    occupation relationship   race gender  capital-gain  \\\n",
      "0       Divorced  Craft-repair      Husband  White   Male           0.0   \n",
      "\n",
      "   capital-loss  hours-per-week native-country income  \n",
      "0           0.0       42.567547  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "postproc_data = processor.inverse_transform(\n",
    "    data=synthesizer.data_syn\n",
    ")\n",
    "print(postproc_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0496 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Risk': 0.0,\n",
       " 'Risk_CI_btm': 0.0,\n",
       " 'Risk_CI_top': 0.6928102649963914,\n",
       " 'Attack_Rate': 0.32880988624667346,\n",
       " 'Attack_Rate_err': 0.32880988624667346,\n",
       " 'Baseline_Rate': 0.32880988624667346,\n",
       " 'Baseline_Rate_err': 0.32880988624667346,\n",
       " 'Control_Rate': 0.32880988624667346,\n",
       " 'Control_Rate_err': 0.32880988624667346}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='anonymeter-singlingout-univariate',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': splitter.data[1]['validation']\n",
    "    },\n",
    "    anonymeter_n_attacks=2 # 2000\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (Anonymeter - Linkability): Now is Linkability Evaluator\n",
      "Evaluator (Anonymeter - Linkability): aux_cols are [age, fnlwgt, race, gender, native-country]\n",
      "                                      and [workclass, education, capital-gain, capital-loss, hours-per-week].\n",
      "Evaluator (Anonymeter - Linkability): Evaluator time: 0.001 sec.\n",
      "Evaluator (Anonymeter): Evaluating  Linkability.\n",
      "Evaluator (Anonymeter): Evaluating Linkability spent 60.1813 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Risk': 0.0,\n",
       " 'Risk_CI_btm': 0.0,\n",
       " 'Risk_CI_top': 0.6928102649963914,\n",
       " 'Attack_Rate': 0.32880988624667346,\n",
       " 'Attack_Rate_err': 0.32880988624667346,\n",
       " 'Baseline_Rate': 0.32880988624667346,\n",
       " 'Baseline_Rate_err': 0.32880988624667346,\n",
       " 'Control_Rate': 0.32880988624667346,\n",
       " 'Control_Rate_err': 0.32880988624667346}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='anonymeter-linkability',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': splitter.data[1]['validation']\n",
    "    },\n",
    "    anonymeter_n_attacks=2, # 2000,\n",
    "    anonymeter_n_neighbors=10,\n",
    "    anonymeter_n_jobs=-1,\n",
    "    anonymeter_aux_cols=[\n",
    "        ['age', 'fnlwgt', 'race', 'gender', 'native-country'],\n",
    "        ['workclass', 'education', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    ]\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (Anonymeter - Inference): Now is Inference Evaluator\n",
      "Evaluator (Anonymeter - Inference): Evaluator time: 0.001 sec.\n",
      "Evaluator (Anonymeter): Evaluating  Inference.\n",
      "Evaluator (Anonymeter): Evaluating Inference spent 0.7485 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Risk': 0.0,\n",
       " 'Risk_CI_btm': 0.0,\n",
       " 'Risk_CI_top': 0.029909810191960658,\n",
       " 'Attack_Rate': 0.08518697431292883,\n",
       " 'Attack_Rate_err': 0.024167884844459902,\n",
       " 'Baseline_Rate': 0.07923272035569816,\n",
       " 'Baseline_Rate_err': 0.02336369331827033,\n",
       " 'Control_Rate': 0.09312597958923642,\n",
       " 'Control_Rate_err': 0.025183431700097014}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='anonymeter-inference',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data,\n",
    "        'control': splitter.data[1]['validation']\n",
    "    },\n",
    "    anonymeter_n_attacks=2, #2000,\n",
    "    anonymeter_n_jobs=-1,\n",
    "    anonymeter_secret='age'\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (SDMetrics): Evaluating QualityReport.\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 32.56it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:07<00:00, 14.31it/s]\n",
      "\n",
      "Overall Score: 73.53%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 90.48%\n",
      "- Column Pair Trends: 56.58%\n",
      "Evaluator (SDMetrics): Evaluating QualityReport spent 7.8112 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.7352610230168115,\n",
       " 'properties': {'Column Shapes': {'Score': 0.904767942490236},\n",
       "  'Column Pair Trends': {'Score': 0.5657541035433872}},\n",
       " 'details': {'Column Shapes':              Column        Metric     Score\n",
       "  0               age  KSComplement  0.939545\n",
       "  1         workclass  TVComplement  0.997249\n",
       "  2            fnlwgt  KSComplement  0.949285\n",
       "  3         education  TVComplement  0.444169\n",
       "  4   educational-num  KSComplement  0.794142\n",
       "  5    marital-status  TVComplement  0.970994\n",
       "  6        occupation  TVComplement  0.988192\n",
       "  7      relationship  TVComplement  0.962895\n",
       "  8              race  TVComplement  0.997614\n",
       "  9            gender  TVComplement  0.999087\n",
       "  10     capital-gain  KSComplement  0.917411\n",
       "  11     capital-loss  KSComplement  0.953600\n",
       "  12   hours-per-week  KSComplement  0.681621\n",
       "  13   native-country  TVComplement  0.994843\n",
       "  14           income  TVComplement  0.980872,\n",
       "  'Column Pair Trends':            Column 1         Column 2                 Metric     Score  \\\n",
       "  0               age        workclass  ContingencySimilarity  0.861271   \n",
       "  1               age           fnlwgt  CorrelationSimilarity  0.994839   \n",
       "  2               age        education  ContingencySimilarity  0.419545   \n",
       "  3               age  educational-num  CorrelationSimilarity  0.977334   \n",
       "  4               age   marital-status  ContingencySimilarity  0.797452   \n",
       "  ..              ...              ...                    ...       ...   \n",
       "  100    capital-loss   native-country  ContingencySimilarity  0.006091   \n",
       "  101    capital-loss           income  ContingencySimilarity  0.006117   \n",
       "  102  hours-per-week   native-country  ContingencySimilarity  0.649509   \n",
       "  103  hours-per-week           income  ContingencySimilarity  0.633552   \n",
       "  104  native-country           income  ContingencySimilarity  0.964218   \n",
       "  \n",
       "       Real Correlation  Synthetic Correlation Error  \n",
       "  0                 NaN                    NaN  None  \n",
       "  1           -0.076287              -0.065966  None  \n",
       "  2                 NaN                    NaN  None  \n",
       "  3            0.031891               0.077224  None  \n",
       "  4                 NaN                    NaN  None  \n",
       "  ..                ...                    ...   ...  \n",
       "  100               NaN                    NaN  None  \n",
       "  101               NaN                    NaN  None  \n",
       "  102               NaN                    NaN  None  \n",
       "  103               NaN                    NaN  None  \n",
       "  104               NaN                    NaN  None  \n",
       "  \n",
       "  [105 rows x 7 columns]}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='sdmetrics-single_table-qualityreport',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator (SDMetrics): Evaluating DiagnosticReport.\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: :   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Evaluating Data Validity: : 100%|██████████| 15/15 [00:00<00:00, 149.84it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|██████████| 1/1 [00:00<00:00, 427.34it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Evaluator (SDMetrics): Evaluating DiagnosticReport spent 0.1076 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 1.0,\n",
       " 'properties': {'Data Validity': {'Score': 1.0},\n",
       "  'Data Structure': {'Score': 1.0}},\n",
       " 'details': {'Data Validity':              Column             Metric  Score\n",
       "  0               age  BoundaryAdherence    1.0\n",
       "  1         workclass  CategoryAdherence    1.0\n",
       "  2            fnlwgt  BoundaryAdherence    1.0\n",
       "  3         education  CategoryAdherence    1.0\n",
       "  4   educational-num  BoundaryAdherence    1.0\n",
       "  5    marital-status  CategoryAdherence    1.0\n",
       "  6        occupation  CategoryAdherence    1.0\n",
       "  7      relationship  CategoryAdherence    1.0\n",
       "  8              race  CategoryAdherence    1.0\n",
       "  9            gender  CategoryAdherence    1.0\n",
       "  10     capital-gain  BoundaryAdherence    1.0\n",
       "  11     capital-loss  BoundaryAdherence    1.0\n",
       "  12   hours-per-week  BoundaryAdherence    1.0\n",
       "  13   native-country  CategoryAdherence    1.0\n",
       "  14           income  CategoryAdherence    1.0,\n",
       "  'Data Structure':            Metric  Score\n",
       "  0  TableStructure    1.0}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = PETsARD.Evaluator(\n",
    "    evaluating_method='sdmetrics-single_table-diagnosticreport',\n",
    "    data={\n",
    "        'ori': splitter.data[1]['train'],\n",
    "        'syn': postproc_data\n",
    "    }\n",
    ")\n",
    "eval.eval()\n",
    "eval.Evaluator.evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader - Benchmarker: file benchmark\\adult.csv already exist and match SHA-256.\n",
      "                      PETsARD will ignore download and use local data directly.\n",
      "Executor - Loader: adult loading time: 8.8062 sec.\n",
      "Executor - Splitter: 0.8 splitting time: 0.0843 sec.\n",
      "No self-defined config passed.  Generate a config automatically.\n",
      "Executor - Processor (preprocessing): drop-IQR-stanard-label processing time: 0.5596 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0237 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 8.7439 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21577 rows (same as raw) in 1.3954 sec.\n",
      "Executor - Synthesizer: GaussianCopula synthesizing time: 10.163 sec.\n",
      "Executor - Processor (postprocessing): drop-IQR-stanard-label processing time: 0.0267 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0365 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n",
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 5.0743 sec.\n",
      "No self-defined config passed.  Generate a config automatically.\n",
      "Executor - Processor (preprocessing): drop-IQR-stanard-label processing time: 0.4261 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0249 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting GaussianCopula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCopula spent 8.4987 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCopula # 21619 rows (same as raw) in 1.3574 sec.\n",
      "Executor - Synthesizer: GaussianCopula synthesizing time: 9.891 sec.\n",
      "Executor - Processor (postprocessing): drop-IQR-stanard-label processing time: 0.0262 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0419 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n",
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 5.4322 sec.\n",
      "====== ====== ====== ====== ====== ======\n",
      "Executor (run - single process): Total execution time: 43.1427 sec.\n",
      "====== ====== ====== ====== ====== ======\n",
      "{'Attack_Rate': 0.3967253428113813,\n",
      " 'Attack_Rate_err': 0.3967253428113813,\n",
      " 'Baseline_Rate': 0.3967253428113813,\n",
      " 'Baseline_Rate_err': 0.3967253428113813,\n",
      " 'Control_Rate': 0.3967253428113813,\n",
      " 'Control_Rate_err': 0.3967253428113813,\n",
      " 'Risk': 0.0,\n",
      " 'Risk_CI_btm': 0.0,\n",
      " 'Risk_CI_top': 0.9300148011448004}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD')\n",
    "os.chdir('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD\\\\demo')\n",
    "\n",
    "import PETsARD\n",
    "\n",
    "\n",
    "para_Executor = {\n",
    "    'Loader': {\n",
    "        'adult': {\n",
    "            'filepath': 'benchmark://adult',\n",
    "            'na_values': {k: '?' for k in [\n",
    "                'workclass',\n",
    "                'occupation',\n",
    "                'native-country'\n",
    "            ]}\n",
    "        }\n",
    "    },\n",
    "    'Splitter': {\n",
    "        '0.8': {\n",
    "            'num_samples': 2,\n",
    "            'train_split_ratio': 0.8,\n",
    "        }\n",
    "    },\n",
    "    'Processor': {\n",
    "        'drop-IQR-stanard-label': {\n",
    "            'missingist': {\n",
    "                'method': 'missingist_drop',\n",
    "                'all': True\n",
    "            },\n",
    "            #'method': , # ValueError: y contains previously unseen labels:\n",
    "            'encoder': [\n",
    "                {'method': 'encoder_label',\n",
    "                 'include': ['education','marital-status','relationship','gender']\n",
    "                },\n",
    "                {'method': 'encoder_uniform',\n",
    "                 'include': ['workclass', 'occupation', 'race', 'native-country', 'income']\n",
    "                }\n",
    "            ],\n",
    "            'outlierist': {\n",
    "                'method': 'outlierist_iqr',\n",
    "                'include': 'hours-per-week'\n",
    "            },\n",
    "            'scaler': {\n",
    "                'method': 'scaler_standard',\n",
    "                'exclude': ['hours-per-week',\n",
    "                    'workclass', 'education', 'marital-status',\n",
    "                    'occupation', 'relationship', 'race', 'gender',\n",
    "                    'native-country', 'income'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'Synthesizer': {\n",
    "        'GaussianCopula': {\n",
    "            'synthesizing_method': 'sdv-singletable-gaussiancopula'\n",
    "        }\n",
    "    },\n",
    "    'Evaluator': {\n",
    "        'anonymeter-SinglingOut': {\n",
    "            'evaluating_method': 'anonymeter-singlingout-univariate',\n",
    "            'anonymeter_n_attacks': 1,  # 2000'\n",
    "            'anonymeter_num_samples': 2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "executor_single = PETsARD.Executor(**para_Executor)\n",
    "executor_single.run()\n",
    "pprint(\n",
    "    executor_single.evaluator[(\n",
    "        'adult',\n",
    "        '0.8',\n",
    "        1,\n",
    "        'drop-IQR-stanard-label',\n",
    "        'GaussianCopula',\n",
    "        'anonymeter-SinglingOut',\n",
    "        1\n",
    "    )].Evaluator.evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|          | 0/1 [00:20<?, ?it/s]s/it]\n",
      "Splitting: 100%|██████████| 1/1 [00:20<00:00, 20.74s/it]\n",
      "Loading: 100%|██████████| 1/1 [00:20<00:00, 20.74s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'Processor.__init__.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\process.py\", line 211, in _sendback_result\n    result_queue.put(_ResultItem(work_id, result=result,\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py\", line 371, in put\n    obj = _ForkingPickler.dumps(obj)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nAttributeError: Can't pickle local object 'Processor.__init__.<locals>.<lambda>'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 73\u001b[0m\n\u001b[0;32m     11\u001b[0m para_Executor \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoader\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     }\n\u001b[0;32m     69\u001b[0m }\n\u001b[0;32m     72\u001b[0m executor_parallel \u001b[38;5;241m=\u001b[39m PETsARD\u001b[38;5;241m.\u001b[39mExecutor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpara_Executor)\n\u001b[1;32m---> 73\u001b[0m \u001b[43mexecutor_parallel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m pprint(\n\u001b[0;32m     75\u001b[0m     executor_parallel\u001b[38;5;241m.\u001b[39mevaluator[(\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m     )]\u001b[38;5;241m.\u001b[39mEvaluator\u001b[38;5;241m.\u001b[39mevaluation\n\u001b[0;32m     84\u001b[0m )\n",
      "File \u001b[1;32mD:\\Dropbox\\89_其他應用\\GitHub\\PETsARD\\PETsARD\\Executor.py:541\u001b[0m, in \u001b[0;36mExecutor.run_parallel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    539\u001b[0m trials_till_proc \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proc_future \u001b[38;5;129;01min\u001b[39;00m as_completed(proc_futures):\n\u001b[1;32m--> 541\u001b[0m     proc_result \u001b[38;5;241m=\u001b[39m \u001b[43mproc_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m     proc_name \u001b[38;5;241m=\u001b[39m proc_futures[proc_future][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor[proc_name] \u001b[38;5;241m=\u001b[39m proc_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'Processor.__init__.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD')\n",
    "os.chdir('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETsARD\\\\demo')\n",
    "\n",
    "import PETsARD\n",
    "\n",
    "\n",
    "para_Executor = {\n",
    "    'Loader': {\n",
    "        'adult': {\n",
    "            'filepath': 'benchmark://adult',\n",
    "            'na_values': {k: '?' for k in [\n",
    "                'workclass',\n",
    "                'occupation',\n",
    "                'native-country'\n",
    "            ]}\n",
    "        }\n",
    "    },\n",
    "    'Splitter': {\n",
    "        '0.8': {\n",
    "            'num_samples': 2,\n",
    "            'train_split_ratio': 0.8,\n",
    "        }\n",
    "    },\n",
    "    'Processor': {\n",
    "        'drop-IQR-stanard-label': {\n",
    "            'missingist': {\n",
    "                'method': 'missingist_drop',\n",
    "                'all': True\n",
    "            },\n",
    "            #'method': , # ValueError: y contains previously unseen labels:\n",
    "            'encoder': [\n",
    "                {'method': 'encoder_label',\n",
    "                 'include': ['education','marital-status','relationship','gender']\n",
    "                },\n",
    "                {'method': 'encoder_uniform',\n",
    "                 'include': ['workclass', 'occupation', 'race', 'native-country', 'income']\n",
    "                }\n",
    "            ],\n",
    "            'outlierist': {\n",
    "                'method': 'outlierist_iqr',\n",
    "                'include': 'hours-per-week'\n",
    "            },\n",
    "            'scaler': {\n",
    "                'method': 'scaler_standard',\n",
    "                'exclude': ['hours-per-week',\n",
    "                    'workclass', 'education', 'marital-status',\n",
    "                    'occupation', 'relationship', 'race', 'gender',\n",
    "                    'native-country', 'income'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'Synthesizer': {\n",
    "        'GaussianCopula': {\n",
    "            'synthesizing_method': 'sdv-singletable-gaussiancopula'\n",
    "        }\n",
    "    },\n",
    "    'Evaluator': {\n",
    "        'anonymeter-SinglingOut': {\n",
    "            'evaluating_method': 'anonymeter-singlingout-univariate',\n",
    "            'anonymeter_n_attacks': 1,  # 2000'\n",
    "            'anonymeter_num_samples': 2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Processor contains lambda function, but python couldn't pickle it.\n",
    "# so Processor .run_parallel() didn't valid after Processor migration.\n",
    "executor_parallel = PETsARD.Executor(**para_Executor)\n",
    "executor_parallel.run_parallel()\n",
    "pprint(\n",
    "    executor_parallel.evaluator[(\n",
    "        'adult',\n",
    "        '0.8',\n",
    "        1,\n",
    "        'drop-IQR-stanard-label',\n",
    "        'GaussianCopula',\n",
    "        'anonymeter-SinglingOut',\n",
    "        1\n",
    "    )].Evaluator.evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un arrangment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Result(__evaluator):\n",
    "    import numpy as np\n",
    "    __dict_result = {}\n",
    "    __para_to_handle = [('Risk', ['risk()', 'value']), ('Risk_CI_btm', ['risk()', 'ci[0]']), ('Risk_CI_top', ['risk()', 'ci[1]']), ('Attack_Rate', ['results()', 'attack_rate', 'value']), ('Attack_Rate_err', ['results()', 'attack_rate', 'error']), ('Baseline_Rate', ['results()', 'baseline_rate', 'value']), ('Baseline_Rate_err', ['results()', 'baseline_rate', 'error']), ('Control_Rate', ['results()', 'control_rate', 'value']), ('Control_Rate_err', ['results()', 'control_rate', 'error'])\n",
    "                        ]\n",
    "    for __key, __attrs in __para_to_handle:\n",
    "        try:\n",
    "            __attr_value = __evaluator\n",
    "            for __attr in __attrs:\n",
    "                if '()' in __attr:\n",
    "                    __method_name = __attr.split('(')[0]\n",
    "                    if hasattr(__attr_value, __method_name):\n",
    "                        __method = getattr(__attr_value, __method_name)\n",
    "                        if callable(__method):\n",
    "                            __attr_value = __method()\n",
    "                        else:\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                elif '[' in __attr:\n",
    "                    __attr_name = __attr.split('[')[0]\n",
    "                    __index = int(__attr.split('[')[1].rstrip(']'))\n",
    "                    if hasattr(__attr_value, __attr_name)\\\n",
    "                            and isinstance(getattr(__attr_value, __attr_name), (list, dict, tuple)):\n",
    "                        try:\n",
    "                            __attr_value = getattr(\n",
    "                                __attr_value, __attr_name)[__index]\n",
    "                        except (IndexError, KeyError):\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                else:\n",
    "                    __attr_value = getattr(__attr_value, __attr)\n",
    "            __dict_result[__key] = __attr_value\n",
    "        except Exception as e:\n",
    "            __dict_result[__key] = np.nan\n",
    "    return __dict_result\n",
    "\n",
    "\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    from anonymeter.evaluators import SinglingOutEvaluator\n",
    "    print(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\")\n",
    "    evaluator = SinglingOutEvaluator(ori=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), syn=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), control=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\"), n_attacks=2000\n",
    "                                     )\n",
    "    try:\n",
    "        evaluator.evaluate(mode='univariate')\n",
    "        print(Result(evaluator))\n",
    "    except RuntimeError as ex:\n",
    "        print(f\"Singling out evaluation failed with {ex}.\"\n",
    "              \"Please re-run this cell.\"\n",
    "              \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "              \"make the evaluation slower.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "for type in ['][Ori]', '][Ctrl]', '-1-1]Postproc']:\n",
    "    for combo in itertools.combinations(['01', '02', '03', '04', '05', '06'], 2):\n",
    "        df_a = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[0]}{type}.csv\")\n",
    "        df_b = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[1]}{type}.csv\")\n",
    "        if df_a.equals(df_b):\n",
    "            print(type+': '+str(combo))\n",
    "            print(\"They're same!!??\")\n",
    "        # else:\n",
    "            # print(type+': '+str(combo))\n",
    "            # print(\"They're different.\")\n",
    "print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Loader: adult loading time: 6.8097 sec.\n",
      "Executor - Splitter: 0.8 splitting time: 0.339 sec.\n",
      "Preprocessor - Outlierist (IQR): Dropped  1060 rows on fnlwgt         . Kept [-63981.5, 419234.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   227 rows on educational-num. Kept [3.0, 19.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  1705 rows on capital-loss   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  9432 rows on hours-per-week . Kept [32.5, 52.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   214 rows on age            . Kept [-0.5, 75.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  3030 rows on capital-gain   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Totally Dropped 13932 in 36207 rows.\n",
      "Preprocessor - Encoder (Label): Column native-country  been labelized from 0 to 39.\n",
      "Preprocessor - Encoder (Label): Column gender          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column race            been labelized from 0 to  4.\n",
      "Preprocessor - Encoder (Label): Column relationship    been labelized from 0 to  5.\n",
      "Preprocessor - Encoder (Label): Column education       been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column income          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column workclass       been labelized from 0 to  6.\n",
      "Preprocessor - Encoder (Label): Column occupation      been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column marital-status  been labelized from 0 to  6.\n",
      "Executor - Preprocessor: drop-IQR-stanard-NA preprocessing time: 0.0764 sec.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.021 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula spent 12.1284 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCoupula # 22275 rows (same as raw) in 1.313 sec.\n",
      "Executor - Synthesizer: GaussianCoupula synthesizing time: 13.466 sec.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding native-country.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding gender.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding race.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding relationship.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding education.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding income.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding workclass.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding occupation.\n",
      "Postprocessor - Encoder (LabelEncoder): Decoding marital-status.\n",
      "Executor - Postprocessor: postprocessing time: 0.0142 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0404 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 765 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 1 trials evaluating time: 131.365 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0322 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 802 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 2 trials evaluating time: 131.1331 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0336 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 830 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 3 trials evaluating time: 131.5346 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0356 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 794 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 4 trials evaluating time: 131.4821 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0351 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 821 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 5 trials evaluating time: 132.587 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.036 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 800 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 6 trials evaluating time: 131.8783 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0352 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 799 failed queries out of 2000. Check DEBUG messages for more details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Result(__evaluator):\n",
    "    import numpy as np\n",
    "    __dict_result = {}\n",
    "    __para_to_handle = [('Risk', ['risk()', 'value']), ('Risk_CI_btm', ['risk()', 'ci[0]']), ('Risk_CI_top', ['risk()', 'ci[1]']), ('Attack_Rate', ['results()', 'attack_rate', 'value']), ('Attack_Rate_err', ['results()', 'attack_rate', 'error']), ('Baseline_Rate', ['results()', 'baseline_rate', 'value']), ('Baseline_Rate_err', ['results()', 'baseline_rate', 'error']), ('Control_Rate', ['results()', 'control_rate', 'value']), ('Control_Rate_err', ['results()', 'control_rate', 'error'])\n",
    "                        ]\n",
    "    for __key, __attrs in __para_to_handle:\n",
    "        try:\n",
    "            __attr_value = __evaluator\n",
    "            for __attr in __attrs:\n",
    "                if '()' in __attr:\n",
    "                    __method_name = __attr.split('(')[0]\n",
    "                    if hasattr(__attr_value, __method_name):\n",
    "                        __method = getattr(__attr_value, __method_name)\n",
    "                        if callable(__method):\n",
    "                            __attr_value = __method()\n",
    "                        else:\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                elif '[' in __attr:\n",
    "                    __attr_name = __attr.split('[')[0]\n",
    "                    __index = int(__attr.split('[')[1].rstrip(']'))\n",
    "                    if hasattr(__attr_value, __attr_name)\\\n",
    "                            and isinstance(getattr(__attr_value, __attr_name), (list, dict, tuple)):\n",
    "                        try:\n",
    "                            __attr_value = getattr(\n",
    "                                __attr_value, __attr_name)[__index]\n",
    "                        except (IndexError, KeyError):\n",
    "                            __dict_result[__key] = np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        __dict_result[__key] = np.nan\n",
    "                        break\n",
    "                else:\n",
    "                    __attr_value = getattr(__attr_value, __attr)\n",
    "            __dict_result[__key] = __attr_value\n",
    "        except Exception as e:\n",
    "            __dict_result[__key] = np.nan\n",
    "    return __dict_result\n",
    "\n",
    "\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    from anonymeter.evaluators import SinglingOutEvaluator\n",
    "    print(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\")\n",
    "    evaluator = SinglingOutEvaluator(ori=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), syn=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), control=pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\"), n_attacks=2000\n",
    "                                     )\n",
    "    try:\n",
    "        evaluator.evaluate(mode='univariate')\n",
    "        print(Result(evaluator))\n",
    "    except RuntimeError as ex:\n",
    "        print(f\"Singling out evaluation failed with {ex}.\"\n",
    "              \"Please re-run this cell.\"\n",
    "              \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "              \"make the evaluation slower.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for i in ['01', '02', '03']:  # ,'04','05','06'\n",
    "    eval = PETsARD.Evaluator(evaluating_method='anonymeter-singlingout-univariate', data={'ori': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ori].csv\"), 'syn': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}-1-1]Postproc.csv\"), 'control': pd.read_csv(f\"PETsARD[20231224-085805]_Trial[{i}][Ctrl].csv\")\n",
    "                                                                                          }, anonymeter_n_attacks=500\n",
    "                             )\n",
    "    eval.eval()\n",
    "    print(eval.Evaluator.evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor - Evaluator: anonymeter-SinglingOut at 7 trials evaluating time: 131.5421 sec.\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Now is SinglingOut - Univariate Evaluator\n",
      "Evaluator (Anonymeter - SinglingOut - Univariate): Evaluator time: 0.0354 sec.\n",
      "Evaluator (Anonymeter): Evaluating  SinglingOut - Univariate.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for type in ['][Ori]', '][Ctrl]', '-1-1]Postproc']:\n",
    "    for combo in itertools.combinations(['01', '02', '03', '04', '05', '06'], 2):\n",
    "        df_a = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[0]}{type}.csv\")\n",
    "        df_b = pd.read_csv(\n",
    "            f\"PETsARD[20231224-085805]_Trial[{combo[1]}{type}.csv\")\n",
    "        if df_a.equals(df_b):\n",
    "            print(type+': '+str(combo))\n",
    "            print(\"They're same!!??\")\n",
    "        # else:\n",
    "            # print(type+': '+str(combo))\n",
    "            # print(\"They're different.\")\n",
    "print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'Loader': {\n",
    "        'NHANES': {\n",
    "            'filepath': '../[sunset]/data/[NHANES] B.csv',\n",
    "            'header_exist': False,\n",
    "            'header_names': ['gen', 'age', 'race', 'edu', 'mar', 'bmi', 'dep', 'pir', 'gh', 'mets', 'qm', 'dia']\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
