{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `ydata-synthetic` Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.synthetic.ydata.ai/1.3/\n",
    "\n",
    "https://github.com/ydataai/ydata-synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ydata-synthetic` is a GAN-oriented SD library. It provides different GANs to synthesise tabular and sequential data. At this moment, it doesn't support GANs with DP. The following list is all the models the library includes (2024-01-11):\n",
    "\n",
    "* GAN\n",
    "* CGAN (Conditional GAN)\n",
    "* WGAN (Wasserstein GAN)\n",
    "* WGAN-GP (Wassertein GAN with Gradient Penalty)\n",
    "* DRAGAN (Deep Regret Analytic GAN)\n",
    "* Cramer GAN (Cramer Distance Solution to Biased Wasserstein Gradients)\n",
    "* CWGAN-GP (Conditional Wassertein GAN with Gradient Penalty)\n",
    "* CTGAN (Conditional Tabular GAN)\n",
    "* TimeGAN (specifically for time-series data)\n",
    "* DoppelGANger (specifically for time-series data)\n",
    "\n",
    "Besides, it also supports one probabilistic model, GMM, which is based on the mixture of several Gaussian distributions. Compared to GANs, GMMs are fast and easy to train. However they may suffer from the complexity of the real world data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please be aware of the error when importing `pandas`, `numpy`, `matplotlib` and `seaborn` after installing `ydata-synthetic`, due to the inconsistent dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When installing `ydata-synthetic`, `conda` also installs `pmlb` (a dataset library for accessing some public data including adult dataset). However, the file is incomplete. Please uninstall `pmlb` after installing `ydata-synthetic` using `conda remove pmlb --force` and install the newest version of `pmlb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmlb import fetch_data\n",
    "from ydata_synthetic.synthesizers.regular import RegularSynthesizer\n",
    "from ydata_synthetic.synthesizers import ModelParameters, TrainParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alex/PETsARD\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/alex/PETsARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_data('adult')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column types should be specified before fitting a synthesizer. For numerical columns, min-max scaling is used, while for categorical columns, one-hot encoding is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_cols = ['workclass','education', 'education-num', 'marital-status',\n",
    "                'occupation', 'relationship', 'race', 'sex', 'native-country', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('[Adt Income] adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 int64\n",
       "workclass          object\n",
       "fnlwgt              int64\n",
       "education          object\n",
       "educational-num     int64\n",
       "marital-status     object\n",
       "occupation         object\n",
       "relationship       object\n",
       "race               object\n",
       "gender             object\n",
       "capital-gain        int64\n",
       "capital-loss        int64\n",
       "hours-per-week      int64\n",
       "native-country     object\n",
       "income             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_cols = ['workclass','education', 'marital-status',\n",
    "                'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelParameters` can define the hyperparameters for constructing a model, and `TrainParameters` contains the parameter used in training process. All customisable parameters are shown below. Unfortunately, there is no documents about the explanation of these parameters. Further code review is needed for better understanding.\n",
    "\n",
    "```python\n",
    "_model_parameters = ['batch_size', 'lr', 'betas', 'layers_dim', 'noise_dim',\n",
    "                     'n_cols', 'seq_len', 'condition', 'n_critic', 'n_features', \n",
    "                     'tau_gs', 'generator_dims', 'critic_dims', 'l2_scale', \n",
    "                     'latent_dim', 'gp_lambda', 'pac', 'gamma', 'tanh']\n",
    "_model_parameters_df = [128, 1e-4, (None, None), 128, 264,\n",
    "                        None, None, None, 1, None, 0.2, [256, 256], \n",
    "                        [256, 256], 1e-6, 128, 10.0, 10, 1, False]\n",
    "\n",
    "_train_parameters = ['cache_prefix', 'label_dim', 'epochs', 'sample_interval', \n",
    "                     'labels', 'n_clusters', 'epsilon', 'log_frequency', \n",
    "                     'measurement_cols', 'sequence_length', 'number_sequences', \n",
    "                     'sample_length', 'rounds']\n",
    "defaults=('', None, 300, 50, None, 10, 0.005, True, None, 1, 1, 1, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | critic_loss: 0.015279442071914673 | generator_loss: 1.5918112993240356\n",
      "Epoch: 1 | critic_loss: 0.19867190718650818 | generator_loss: 0.7152256965637207\n",
      "Epoch: 2 | critic_loss: 0.2590620517730713 | generator_loss: 0.3547900915145874\n",
      "Epoch: 3 | critic_loss: 0.016865253448486328 | generator_loss: -0.051879703998565674\n",
      "Epoch: 4 | critic_loss: 0.09552137553691864 | generator_loss: -0.40007030963897705\n",
      "Epoch: 5 | critic_loss: 0.16511127352714539 | generator_loss: -0.660663366317749\n",
      "Epoch: 6 | critic_loss: 0.03420276194810867 | generator_loss: -0.8421027660369873\n",
      "Epoch: 7 | critic_loss: -0.11199554800987244 | generator_loss: -0.6539876461029053\n",
      "Epoch: 8 | critic_loss: 0.0336284264922142 | generator_loss: -0.8210815787315369\n",
      "Epoch: 9 | critic_loss: -0.03629501163959503 | generator_loss: -0.9905993342399597\n",
      "Epoch: 10 | critic_loss: -0.035927265882492065 | generator_loss: -0.6070727109909058\n",
      "Epoch: 11 | critic_loss: 0.11972399801015854 | generator_loss: -0.6612287759780884\n",
      "Epoch: 12 | critic_loss: -0.02305881679058075 | generator_loss: -0.5379796028137207\n",
      "Epoch: 13 | critic_loss: 0.04295390844345093 | generator_loss: -0.26052653789520264\n",
      "Epoch: 14 | critic_loss: 0.20911069214344025 | generator_loss: -0.473914235830307\n",
      "Epoch: 15 | critic_loss: -0.20147040486335754 | generator_loss: -0.4069518744945526\n",
      "Epoch: 16 | critic_loss: -0.12325094640254974 | generator_loss: -0.07150299847126007\n",
      "Epoch: 17 | critic_loss: 0.08878067135810852 | generator_loss: -0.10760358721017838\n",
      "Epoch: 18 | critic_loss: 0.006781131029129028 | generator_loss: -0.26365065574645996\n",
      "Epoch: 19 | critic_loss: -0.11718405038118362 | generator_loss: -0.2866760492324829\n",
      "Epoch: 20 | critic_loss: -0.02056724578142166 | generator_loss: -0.10041262954473495\n",
      "Epoch: 21 | critic_loss: 0.07848702371120453 | generator_loss: 0.035622451454401016\n",
      "Epoch: 22 | critic_loss: 0.07062041759490967 | generator_loss: -0.2392127513885498\n",
      "Epoch: 23 | critic_loss: -0.11005417257547379 | generator_loss: -0.0009751869365572929\n",
      "Epoch: 24 | critic_loss: -0.017572831362485886 | generator_loss: -0.3069373071193695\n",
      "Epoch: 25 | critic_loss: -0.13684310019016266 | generator_loss: -0.1737552285194397\n",
      "Epoch: 26 | critic_loss: -0.013857077807188034 | generator_loss: 0.1636323779821396\n",
      "Epoch: 27 | critic_loss: -0.10473906993865967 | generator_loss: -0.0662970095872879\n",
      "Epoch: 28 | critic_loss: -0.14343273639678955 | generator_loss: -0.24780429899692535\n",
      "Epoch: 29 | critic_loss: -0.06139026954770088 | generator_loss: -0.34898412227630615\n",
      "Epoch: 30 | critic_loss: -0.10111160576343536 | generator_loss: 0.026879355311393738\n",
      "Epoch: 31 | critic_loss: -0.021679304540157318 | generator_loss: -0.15297234058380127\n",
      "Epoch: 32 | critic_loss: 0.014740414917469025 | generator_loss: -0.32177749276161194\n",
      "Epoch: 33 | critic_loss: -0.29638203978538513 | generator_loss: -0.3374263644218445\n",
      "Epoch: 34 | critic_loss: -0.08152102679014206 | generator_loss: -0.44316011667251587\n",
      "Epoch: 35 | critic_loss: -0.12433889508247375 | generator_loss: -0.3975992798805237\n",
      "Epoch: 36 | critic_loss: 0.0594707727432251 | generator_loss: -0.4147588312625885\n",
      "Epoch: 37 | critic_loss: 0.0834604948759079 | generator_loss: -0.4354889392852783\n",
      "Epoch: 38 | critic_loss: -0.0040011927485466 | generator_loss: -0.6401945948600769\n",
      "Epoch: 39 | critic_loss: 0.027138464152812958 | generator_loss: -0.33294185996055603\n",
      "Epoch: 40 | critic_loss: 0.06177631765604019 | generator_loss: -0.09377965331077576\n",
      "Epoch: 41 | critic_loss: -0.09198807179927826 | generator_loss: -0.2438303828239441\n",
      "Epoch: 42 | critic_loss: -0.15638381242752075 | generator_loss: -0.2970083951950073\n",
      "Epoch: 43 | critic_loss: -0.08441898226737976 | generator_loss: -0.14636950194835663\n",
      "Epoch: 44 | critic_loss: 0.04869818687438965 | generator_loss: -0.07872305065393448\n",
      "Epoch: 45 | critic_loss: 0.22316326200962067 | generator_loss: -0.3341289460659027\n",
      "Epoch: 46 | critic_loss: -0.03379003703594208 | generator_loss: -0.3072504699230194\n",
      "Epoch: 47 | critic_loss: -0.09007291495800018 | generator_loss: -0.3576386570930481\n",
      "Epoch: 48 | critic_loss: -0.03746144846081734 | generator_loss: -0.2838408648967743\n",
      "Epoch: 49 | critic_loss: -0.3073844015598297 | generator_loss: -0.3649904131889343\n",
      "Epoch: 50 | critic_loss: -0.18390683829784393 | generator_loss: -0.17595964670181274\n",
      "Epoch: 51 | critic_loss: -0.3182474672794342 | generator_loss: -0.4516860842704773\n",
      "Epoch: 52 | critic_loss: -0.022850990295410156 | generator_loss: -0.40610769391059875\n",
      "Epoch: 53 | critic_loss: -0.04110118746757507 | generator_loss: -0.05057002976536751\n",
      "Epoch: 54 | critic_loss: -0.10031811892986298 | generator_loss: -0.3984166979789734\n",
      "Epoch: 55 | critic_loss: 0.06910759210586548 | generator_loss: -0.2562236487865448\n",
      "Epoch: 56 | critic_loss: -0.15804964303970337 | generator_loss: -0.5754713416099548\n",
      "Epoch: 57 | critic_loss: -0.39850908517837524 | generator_loss: -0.4082648754119873\n",
      "Epoch: 58 | critic_loss: -0.009345240890979767 | generator_loss: -0.5295708775520325\n",
      "Epoch: 59 | critic_loss: -0.0873187929391861 | generator_loss: -0.21302640438079834\n",
      "Epoch: 60 | critic_loss: -0.015231236815452576 | generator_loss: -0.48722323775291443\n",
      "Epoch: 61 | critic_loss: -0.007804170250892639 | generator_loss: -0.35068896412849426\n",
      "Epoch: 62 | critic_loss: 0.04103276878595352 | generator_loss: -0.4479063153266907\n",
      "Epoch: 63 | critic_loss: -0.03532545268535614 | generator_loss: -0.3357618749141693\n",
      "Epoch: 64 | critic_loss: -0.05551915615797043 | generator_loss: -0.5037551522254944\n",
      "Epoch: 65 | critic_loss: 0.17855605483055115 | generator_loss: -0.745880126953125\n",
      "Epoch: 66 | critic_loss: 0.03530067205429077 | generator_loss: -0.5632060170173645\n",
      "Epoch: 67 | critic_loss: 0.027362443506717682 | generator_loss: -0.3613516092300415\n",
      "Epoch: 68 | critic_loss: -0.21945449709892273 | generator_loss: -0.5397235751152039\n",
      "Epoch: 69 | critic_loss: 0.13951972126960754 | generator_loss: -0.2829861044883728\n",
      "Epoch: 70 | critic_loss: -0.0965341255068779 | generator_loss: -0.037951674312353134\n",
      "Epoch: 71 | critic_loss: -0.218397855758667 | generator_loss: -0.22530046105384827\n",
      "Epoch: 72 | critic_loss: 0.008503258228302002 | generator_loss: -0.23022432625293732\n",
      "Epoch: 73 | critic_loss: -0.08702515810728073 | generator_loss: -0.08509714901447296\n",
      "Epoch: 74 | critic_loss: -0.020657029002904892 | generator_loss: -0.12883426249027252\n",
      "Epoch: 75 | critic_loss: -0.35592353343963623 | generator_loss: -0.3929513394832611\n",
      "Epoch: 76 | critic_loss: 0.11512267589569092 | generator_loss: -0.2748488783836365\n",
      "Epoch: 77 | critic_loss: -0.0020603537559509277 | generator_loss: -0.47823649644851685\n",
      "Epoch: 78 | critic_loss: -0.08648696541786194 | generator_loss: -0.6214402318000793\n",
      "Epoch: 79 | critic_loss: -0.11518915742635727 | generator_loss: -0.2935323417186737\n",
      "Epoch: 80 | critic_loss: 0.12503425776958466 | generator_loss: -0.7547904253005981\n",
      "Epoch: 81 | critic_loss: -0.2185235172510147 | generator_loss: -0.320880651473999\n",
      "Epoch: 82 | critic_loss: 0.05974934995174408 | generator_loss: -0.4531404674053192\n",
      "Epoch: 83 | critic_loss: -0.14611706137657166 | generator_loss: -0.3197934329509735\n",
      "Epoch: 84 | critic_loss: 0.05038008093833923 | generator_loss: -0.15081167221069336\n",
      "Epoch: 85 | critic_loss: -0.07255642116069794 | generator_loss: -0.2669413089752197\n",
      "Epoch: 86 | critic_loss: -0.2926468551158905 | generator_loss: -0.328198105096817\n",
      "Epoch: 87 | critic_loss: -0.10181643813848495 | generator_loss: -0.4628506600856781\n",
      "Epoch: 88 | critic_loss: -0.09104534983634949 | generator_loss: -0.20859423279762268\n",
      "Epoch: 89 | critic_loss: -0.06017625331878662 | generator_loss: -0.0684141218662262\n",
      "Epoch: 90 | critic_loss: -0.06632807850837708 | generator_loss: -0.18758204579353333\n",
      "Epoch: 91 | critic_loss: -0.14400824904441833 | generator_loss: -0.20527450740337372\n",
      "Epoch: 92 | critic_loss: -0.11814481019973755 | generator_loss: -0.38092929124832153\n",
      "Epoch: 93 | critic_loss: -0.057183943688869476 | generator_loss: -0.29877641797065735\n",
      "Epoch: 94 | critic_loss: 0.05511394143104553 | generator_loss: -0.3722144067287445\n",
      "Epoch: 95 | critic_loss: -0.08438024669885635 | generator_loss: -0.5159732103347778\n",
      "Epoch: 96 | critic_loss: -0.09877331554889679 | generator_loss: -0.3047511577606201\n",
      "Epoch: 97 | critic_loss: -0.08630399405956268 | generator_loss: -0.46513357758522034\n",
      "Epoch: 98 | critic_loss: 0.008537530899047852 | generator_loss: -0.39098039269447327\n",
      "Epoch: 99 | critic_loss: -0.13910776376724243 | generator_loss: -0.20130306482315063\n",
      "Epoch: 100 | critic_loss: -0.2587244212627411 | generator_loss: -0.2686968445777893\n"
     ]
    }
   ],
   "source": [
    "# Define model and training parameters\n",
    "ctgan_args = ModelParameters(batch_size=500, lr=2e-4, betas=(0.5, 0.9))\n",
    "train_args = TrainParameters(epochs=101)\n",
    "\n",
    "# Train the generator model\n",
    "synth = RegularSynthesizer(modelname='ctgan', model_parameters=ctgan_args)\n",
    "synth.fit(data=df, train_arguments=train_args, num_cols=num_cols, cat_cols=cat_cols)\n",
    "\n",
    "# Generate 1000 new synthetic samples\n",
    "synth_data = synth.sample(1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>313359</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>314233</td>\n",
       "      <td>11th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>126878</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>Private</td>\n",
       "      <td>147537</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>105875</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>237084</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>11</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>233411</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>44687</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>Canada</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>96327</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2893</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>27825</td>\n",
       "      <td>Masters</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0     21   Private  313359  Some-college                9       Never-married   \n",
       "1     40   Private  314233          11th                6  Married-civ-spouse   \n",
       "2     33   Private  126878     Bachelors               13       Never-married   \n",
       "3     35   Private  147537       HS-grad                9  Married-civ-spouse   \n",
       "4     32   Private  105875  Some-college               10       Never-married   \n",
       "..   ...       ...     ...           ...              ...                 ...   \n",
       "995   44   Private  237084    Assoc-acdm               11            Divorced   \n",
       "996   17   Private  233411       HS-grad                9       Never-married   \n",
       "997   44   Private   44687  Some-college                4            Divorced   \n",
       "998   41   Private   96327       HS-grad                9           Separated   \n",
       "999   43   Private   27825       Masters               13            Divorced   \n",
       "\n",
       "           occupation   relationship   race  gender  capital-gain  \\\n",
       "0        Adm-clerical  Not-in-family  White    Male            -6   \n",
       "1        Craft-repair        Husband  White    Male           -11   \n",
       "2      Prof-specialty  Not-in-family  White    Male             6   \n",
       "3     Exec-managerial        Husband  White    Male             2   \n",
       "4       Other-service      Unmarried  Black  Female           -14   \n",
       "..                ...            ...    ...     ...           ...   \n",
       "995     Other-service  Not-in-family  White  Female           -12   \n",
       "996   Farming-fishing      Own-child  White  Female            -3   \n",
       "997  Transport-moving           Wife  White  Female             0   \n",
       "998             Sales  Not-in-family  White    Male          2893   \n",
       "999   Exec-managerial  Not-in-family  White  Female             1   \n",
       "\n",
       "     capital-loss  hours-per-week native-country income  \n",
       "0               0              39  United-States  <=50K  \n",
       "1               0              50  United-States  <=50K  \n",
       "2               0              50  United-States  <=50K  \n",
       "3               0              40  United-States   >50K  \n",
       "4               0              30  United-States  <=50K  \n",
       "..            ...             ...            ...    ...  \n",
       "995             0              34  United-States  <=50K  \n",
       "996             0               6  United-States  <=50K  \n",
       "997             0              36         Canada   >50K  \n",
       "998             0              50  United-States  <=50K  \n",
       "999             0              33  United-States  <=50K  \n",
       "\n",
       "[1000 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter search: 100%|██████████| 8/8 [04:52<00:00, 36.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train the GMM\n",
    "synth_gmm = RegularSynthesizer(modelname='fast')\n",
    "synth_gmm.fit(data=df, cat_cols=cat_cols, num_cols=num_cols)\n",
    "\n",
    "# Generate 1000 new synthetic samples\n",
    "synth_gmm_data = synth_gmm.sample(1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>Private</td>\n",
       "      <td>165855</td>\n",
       "      <td>Masters</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1157</td>\n",
       "      <td>-44</td>\n",
       "      <td>48</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>237037</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1322</td>\n",
       "      <td>378</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>118320</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>6</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>4773</td>\n",
       "      <td>682</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Private</td>\n",
       "      <td>101727</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>4788</td>\n",
       "      <td>-764</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>281083</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>3464</td>\n",
       "      <td>371</td>\n",
       "      <td>10</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>275246</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>17781</td>\n",
       "      <td>-458</td>\n",
       "      <td>48</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>20</td>\n",
       "      <td>Private</td>\n",
       "      <td>20268</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1311</td>\n",
       "      <td>175</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>345160</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>-5733</td>\n",
       "      <td>380</td>\n",
       "      <td>24</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>221465</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>-8204</td>\n",
       "      <td>134</td>\n",
       "      <td>66</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>269289</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>10147</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0     35   Private  165855       Masters               13       Never-married   \n",
       "1     58   Private  237037     Bachelors               10            Divorced   \n",
       "2     37   Private  118320       HS-grad                6            Divorced   \n",
       "3     20   Private  101727       HS-grad                7       Never-married   \n",
       "4     34   Private  281083  Some-college               10       Never-married   \n",
       "..   ...       ...     ...           ...              ...                 ...   \n",
       "995   30   Private  275246  Some-college               12  Married-civ-spouse   \n",
       "996   20   Private   20268       HS-grad                5  Married-civ-spouse   \n",
       "997   39   Private  345160       HS-grad               10  Married-civ-spouse   \n",
       "998   32   Private  221465     Assoc-voc               13  Married-civ-spouse   \n",
       "999   46   Private  269289  Some-college               10  Married-civ-spouse   \n",
       "\n",
       "           occupation   relationship   race  gender  capital-gain  \\\n",
       "0      Prof-specialty  Not-in-family  White    Male          1157   \n",
       "1               Sales  Not-in-family  White    Male          1322   \n",
       "2        Craft-repair      Own-child  White  Female          4773   \n",
       "3        Adm-clerical      Own-child  Black    Male          4788   \n",
       "4      Prof-specialty  Not-in-family  White  Female          3464   \n",
       "..                ...            ...    ...     ...           ...   \n",
       "995   Exec-managerial        Husband  White    Male         17781   \n",
       "996  Transport-moving        Husband  White    Male         -1311   \n",
       "997      Craft-repair        Husband  White    Male         -5733   \n",
       "998   Exec-managerial        Husband  White    Male         -8204   \n",
       "999      Craft-repair           Wife  White  Female         10147   \n",
       "\n",
       "     capital-loss  hours-per-week native-country income  \n",
       "0             -44              48  United-States  <=50K  \n",
       "1             378              45  United-States  <=50K  \n",
       "2             682              38  United-States  <=50K  \n",
       "3            -764              50  United-States  <=50K  \n",
       "4             371              10  United-States  <=50K  \n",
       "..            ...             ...            ...    ...  \n",
       "995          -458              48  United-States  <=50K  \n",
       "996           175              45  United-States  <=50K  \n",
       "997           380              24  United-States  <=50K  \n",
       "998           134              66  United-States   >50K  \n",
       "999             8              41  United-States   >50K  \n",
       "\n",
       "[1000 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_gmm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
