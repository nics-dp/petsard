name: ğŸ§ª Test Suite
# æ¸¬è©¦å¥—ä»¶ï¼šé‹è¡Œæ‰€æœ‰æ¸¬è©¦ç¢ºä¿ä»£ç¢¼å“è³ª

on:
  push:
    branches: [main, dev]
    paths:
      - "petsard/**"
      - "tests/**"
      - "pyproject.toml"
      - ".github/workflows/test-suite.yml"
  pull_request:
    branches: [main, dev]
    paths:
      - "petsard/**"
      - "tests/**"
      - "pyproject.toml"
      - ".github/workflows/test-suite.yml"

permissions:
  contents: read
  pull-requests: write

jobs:
  test:
    name: ğŸ§ª Run Tests
    runs-on: ubuntu-latest
    continue-on-error: true # ä¸å¼·åˆ¶è¦æ±‚æ¸¬è©¦é€šéæ‰èƒ½åˆä½µ

    strategy:
      matrix:
        python-version: ["3.10", "3.11"]

    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v5

      - name: ğŸ Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}

      - name: ğŸ“¦ Cache Dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.python-version }}-
            ${{ runner.os }}-pip-

      - name: ğŸ”§ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: ğŸ” Verify Test Environment
        run: |
          echo "### ğŸ” ç’°å¢ƒè¨ºæ–· Environment Diagnostics" >> test_report.md
          echo "" >> test_report.md
          
          echo "**Python ç‰ˆæœ¬ï¼š**" >> test_report.md
          python --version >> test_report.md 2>&1
          echo "" >> test_report.md
          
          echo "**å·²å®‰è£å¥—ä»¶ï¼š**" >> test_report.md
          echo "```" >> test_report.md
          pip list | grep -E "(pytest|ruff|petsard)" >> test_report.md 2>&1 || echo "ç›¸é—œå¥—ä»¶æœªæ‰¾åˆ°" >> test_report.md
          echo "```" >> test_report.md
          echo "" >> test_report.md
          
          echo "**æ¸¬è©¦æª”æ¡ˆçµæ§‹ï¼š**" >> test_report.md
          echo "```" >> test_report.md
          if [ -d "tests" ]; then
            ls -la tests/ >> test_report.md 2>&1
          else
            echo "tests/ ç›®éŒ„ä¸å­˜åœ¨" >> test_report.md
          fi
          echo "```" >> test_report.md
          echo "" >> test_report.md
          
          echo "**PETsARD æ¨¡çµ„æª¢æŸ¥ï¼š**" >> test_report.md
          echo "```" >> test_report.md
          python -c "import petsard; print(f'PETsARD version: {petsard.__version__ if hasattr(petsard, \"__version__\") else \"unknown\"}')" >> test_report.md 2>&1 || echo "ç„¡æ³•è¼‰å…¥ petsard æ¨¡çµ„" >> test_report.md
          echo "```" >> test_report.md
          echo "" >> test_report.md
          
          echo "---" >> test_report.md
          echo "" >> test_report.md

      - name: ğŸ” Run Ruff Code Quality Check
        id: ruff-check
        run: |
          # é‹è¡Œ Ruff æª¢æŸ¥ï¼ˆç°¡æ½”ç‰ˆæœ¬ï¼‰
          if ruff check . --output-format=concise > ruff_output.txt 2>&1; then
            echo "ruff_status=success" >> $GITHUB_OUTPUT
            echo "### âœ… ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥é€šé Code Quality Check Passed" >> test_report.md
            echo "" >> test_report.md
          else
            echo "ruff_status=failed" >> $GITHUB_OUTPUT
            
            # çµ±è¨ˆéŒ¯èª¤æ•¸é‡
            ERROR_COUNT=$(wc -l < ruff_output.txt)
            
            echo "### âš ï¸ ç¨‹å¼ç¢¼å“è³ªå•é¡Œ Code Quality Issues" >> test_report.md
            echo "**ç™¼ç¾ $ERROR_COUNT å€‹å•é¡Œéœ€è¦ä¿®æ­£**" >> test_report.md
            echo "" >> test_report.md
            
            # é¡¯ç¤ºå‰10å€‹éŒ¯èª¤
            echo "**ä¸»è¦å•é¡Œï¼ˆå‰10å€‹ï¼‰:**" >> test_report.md
            echo "```" >> test_report.md
            head -10 ruff_output.txt >> test_report.md
            echo "```" >> test_report.md
            
            if [ "$ERROR_COUNT" -gt 10 ]; then
              echo "*...é‚„æœ‰ $((ERROR_COUNT - 10)) å€‹å•é¡Œ*" >> test_report.md
            fi
            echo "" >> test_report.md
          fi

      - name: ğŸ§ª Run Unit Tests with Coverage
        id: unit-tests
        run: |
          echo "## ğŸ§ª æ¸¬è©¦çµæœ Test Results" >> test_report.md
          echo "" >> test_report.md

          # é‹è¡Œæ¸¬è©¦ä¸¦æ•ç²çµæœï¼Œä½¿ç”¨ç°¡æ½”æ ¼å¼
          if pytest tests/ --cov=petsard --cov-report=term-missing --cov-report=xml --tb=short --junit-xml=pytest-results.xml > test_output.txt 2>&1; then
            echo "test_status=success" >> $GITHUB_OUTPUT
            
            # æå–æ¸¬è©¦çµ±è¨ˆ
            PASSED_COUNT=$(grep -c "PASSED" test_output.txt 2>/dev/null || echo "0")
            TOTAL_COUNT=$(grep -E "^[0-9]+ passed" test_output.txt | grep -o "^[0-9]+" || echo "$PASSED_COUNT")
            
            echo "### âœ… æ‰€æœ‰æ¸¬è©¦é€šéï¼All Tests Passed!" >> test_report.md
            echo "" >> test_report.md
            echo "**ğŸ“Š ç¸½è¨ˆ**: $TOTAL_COUNT å€‹æ¸¬è©¦å…¨éƒ¨é€šé" >> test_report.md
          else
            echo "test_status=failed" >> $GITHUB_OUTPUT
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æ¸¬è©¦åŸ·è¡ŒéŒ¯èª¤
            if grep -q "ERROR" test_output.txt; then
              echo "### âŒ æ¸¬è©¦åŸ·è¡ŒéŒ¯èª¤ Test Execution Error" >> test_report.md
              echo "" >> test_report.md
              echo "**æ¸¬è©¦ç„¡æ³•æ­£å¸¸åŸ·è¡Œï¼Œå¯èƒ½çš„åŸå› ï¼š**" >> test_report.md
              echo "- æ‰¾ä¸åˆ°æ¸¬è©¦æª”æ¡ˆæˆ–æ¨¡çµ„" >> test_report.md
              echo "- æ¸¬è©¦é…ç½®éŒ¯èª¤" >> test_report.md
              echo "- ç›¸ä¾å¥—ä»¶æœªæ­£ç¢ºå®‰è£" >> test_report.md
              echo "" >> test_report.md
              echo "**éŒ¯èª¤è©³æƒ…ï¼š**" >> test_report.md
              echo "```" >> test_report.md
              # é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯ï¼ˆå‰50è¡Œï¼‰
              head -50 test_output.txt >> test_report.md
              echo "```" >> test_report.md
            else
              # æå–æ¸¬è©¦çµ±è¨ˆï¼ˆå¾ pytest æ‘˜è¦è¡Œï¼‰
              SUMMARY_LINE=$(grep -E "=+ (short test summary info|[0-9]+ failed|[0-9]+ passed|[0-9]+ error)" test_output.txt | tail -1)
              
              # å˜—è©¦å¾ä¸åŒæ ¼å¼æå–çµ±è¨ˆ
              if echo "$SUMMARY_LINE" | grep -q "short test summary"; then
                # å¦‚æœæœ‰ short test summaryï¼Œå¾ä¹‹å¾Œçš„è¡Œæå–
                PASSED_COUNT=$(grep -E "^[0-9]+ passed" test_output.txt | tail -1 | grep -o "^[0-9]*" || echo "0")
                FAILED_COUNT=$(grep -E "^[0-9]+ failed" test_output.txt | tail -1 | grep -o "^[0-9]*" || echo "0")
                ERROR_COUNT=$(grep -E "^[0-9]+ error" test_output.txt | tail -1 | grep -o "^[0-9]*" || echo "0")
                SKIPPED_COUNT=$(grep -E "^[0-9]+ skipped" test_output.txt | tail -1 | grep -o "^[0-9]*" || echo "0")
              else
                # æ¨™æº–æ ¼å¼æå–
                PASSED_COUNT=$(echo "$SUMMARY_LINE" | grep -o "[0-9]* passed" | grep -o "[0-9]*" || echo "0")
                FAILED_COUNT=$(echo "$SUMMARY_LINE" | grep -o "[0-9]* failed" | grep -o "[0-9]*" || echo "0")
                ERROR_COUNT=$(echo "$SUMMARY_LINE" | grep -o "[0-9]* error" | grep -o "[0-9]*" || echo "0")
                SKIPPED_COUNT=$(echo "$SUMMARY_LINE" | grep -o "[0-9]* skipped" | grep -o "[0-9]*" || echo "0")
              fi
              
              TOTAL_FAILED=$((FAILED_COUNT + ERROR_COUNT))
              TOTAL_COUNT=$((PASSED_COUNT + FAILED_COUNT + ERROR_COUNT + SKIPPED_COUNT))
              
              # å¦‚æœçµ±è¨ˆå…¨æ˜¯ 0ï¼Œå¯èƒ½æ˜¯è§£æå¤±æ•—
              if [ "$TOTAL_COUNT" -eq 0 ]; then
                echo "### âš ï¸ æ¸¬è©¦çµæœç„¡æ³•è§£æ Test Results Cannot Be Parsed" >> test_report.md
                echo "" >> test_report.md
                echo "**ç„¡æ³•å¾æ¸¬è©¦è¼¸å‡ºä¸­æå–çµ±è¨ˆè³‡è¨Š**" >> test_report.md
                echo "" >> test_report.md
                echo "**åŸå§‹è¼¸å‡ºï¼ˆå‰50è¡Œï¼‰ï¼š**" >> test_report.md
                echo "```" >> test_report.md
                head -50 test_output.txt >> test_report.md
                echo "```" >> test_report.md
              else
                echo "### âš ï¸ æ¸¬è©¦æœªå®Œå…¨é€šé Tests Not Fully Passed" >> test_report.md
                echo "" >> test_report.md
                echo "**ğŸ“Š æ¸¬è©¦çµæœ**: $PASSED_COUNT/$TOTAL_COUNT é€šé" >> test_report.md
                
                if [ "$TOTAL_FAILED" -gt 0 ]; then
                  echo "" >> test_report.md
                  echo "**âŒ å¤±æ•—çš„æ¸¬è©¦ ($TOTAL_FAILED å€‹):**" >> test_report.md
                  echo "" >> test_report.md
                  
                  # æå–å¤±æ•—æ¸¬è©¦åç¨±ï¼ˆå¾ FAILED è¡Œï¼‰
                  if grep "FAILED" test_output.txt | grep -o "tests/[^:]*::[^[:space:]]*" | sed 's/tests\///' | sed 's/::/ â†’ /' > failed_tests.txt 2>/dev/null && [ -s failed_tests.txt ]; then
                    cat failed_tests.txt | while IFS= read -r test_name; do
                      echo "â€¢ \`$test_name\`" >> test_report.md
                    done
                  fi
                  
                  # é¡¯ç¤ºéŒ¯èª¤è©³æƒ…ï¼ˆå¾ short test summaryï¼‰
                  if grep -q "FAILED\|ERROR" test_output.txt; then
                    echo "" >> test_report.md
                    echo "**éŒ¯èª¤è©³æƒ…ï¼š**" >> test_report.md
                    echo "```" >> test_report.md
                    grep -A 5 "short test summary" test_output.txt | head -20 >> test_report.md
                    echo "```" >> test_report.md
                  fi
                fi
                
                if [ "$SKIPPED_COUNT" -gt 0 ]; then
                  echo "" >> test_report.md
                  echo "**â­ï¸ è·³é**: $SKIPPED_COUNT å€‹æ¸¬è©¦" >> test_report.md
                fi
              fi
            fi
          fi
          
          echo "" >> test_report.md

      - name: ğŸ“Š Generate Coverage Report
        if: always()
        run: |
          # ç”Ÿæˆç°¡æ½”çš„è¦†è“‹ç‡å ±å‘Š
          if [ -f coverage.xml ]; then
            COVERAGE_PERCENT=$(grep -o 'line-rate="[0-9.]*"' coverage.xml | head -1 | grep -o '[0-9.]*' | awk '{printf "%.1f", $1*100}')
            if [ ! -z "$COVERAGE_PERCENT" ]; then
              echo "**è¦†è“‹ç‡**: $COVERAGE_PERCENT%" >> test_report.md
              echo "" >> test_report.md
            fi
          fi

      - name: ğŸ§ª Run Functional Tests
        id: functional-tests
        run: |
          # æª¢æŸ¥æ¸¬è©¦æª”æ¡ˆæ˜¯å¦å­˜åœ¨
          if [ ! -f "tests/test_petsard.py" ]; then
            echo "functional_status=skipped" >> $GITHUB_OUTPUT
            echo "### â­ï¸ åŠŸèƒ½æ¸¬è©¦è·³é Functional Tests Skipped" >> test_report.md
            echo "**åŸå› **: æ‰¾ä¸åˆ° tests/test_petsard.py æª”æ¡ˆ" >> test_report.md
            echo "" >> test_report.md
          else
            if pytest tests/test_petsard.py --tb=short > functional_output.txt 2>&1; then
              echo "functional_status=success" >> $GITHUB_OUTPUT
              
              # æå–æ¸¬è©¦æ•¸é‡
              FUNC_TOTAL=$(grep -E "^[0-9]+ passed" functional_output.txt | grep -o "^[0-9]+" || echo "0")
              
              echo "### âœ… åŠŸèƒ½æ¸¬è©¦é€šé Functional Tests Passed" >> test_report.md
              echo "**ğŸ“Š ç¸½è¨ˆ**: $FUNC_TOTAL å€‹åŠŸèƒ½æ¸¬è©¦å…¨éƒ¨é€šé" >> test_report.md
              echo "" >> test_report.md
            else
              echo "functional_status=failed" >> $GITHUB_OUTPUT
              
              # æª¢æŸ¥æ˜¯å¦æœ‰åŸ·è¡ŒéŒ¯èª¤
              if grep -q "ERROR" functional_output.txt; then
                echo "### âŒ åŠŸèƒ½æ¸¬è©¦åŸ·è¡ŒéŒ¯èª¤ Functional Test Execution Error" >> test_report.md
                echo "" >> test_report.md
                echo "**éŒ¯èª¤è©³æƒ…ï¼š**" >> test_report.md
                echo "```" >> test_report.md
                head -50 functional_output.txt >> test_report.md
                echo "```" >> test_report.md
              else
                # æå–æ¸¬è©¦çµ±è¨ˆ
                SUMMARY_LINE=$(grep -E "^[0-9]+ (failed|passed|error)" functional_output.txt | tail -1)
                FUNC_PASSED=$(echo "$SUMMARY_LINE" | grep -o "[0-9]* passed" | grep -o "[0-9]*" || echo "0")
                FUNC_FAILED=$(echo "$SUMMARY_LINE" | grep -o "[0-9]* failed" | grep -o "[0-9]*" || echo "0")
                FUNC_ERROR=$(echo "$SUMMARY_LINE" | grep -o "[0-9]* error" | grep -o "[0-9]*" || echo "0")
                FUNC_TOTAL=$((FUNC_PASSED + FUNC_FAILED + FUNC_ERROR))
                
                if [ "$FUNC_TOTAL" -eq 0 ]; then
                  echo "### âš ï¸ åŠŸèƒ½æ¸¬è©¦çµæœç„¡æ³•è§£æ Functional Test Results Cannot Be Parsed" >> test_report.md
                  echo "" >> test_report.md
                  echo "**åŸå§‹è¼¸å‡ºï¼ˆå‰50è¡Œï¼‰ï¼š**" >> test_report.md
                  echo "```" >> test_report.md
                  head -50 functional_output.txt >> test_report.md
                  echo "```" >> test_report.md
                else
                  echo "### âš ï¸ åŠŸèƒ½æ¸¬è©¦æœªå®Œå…¨é€šé Functional Tests Not Fully Passed" >> test_report.md
                  echo "**ğŸ“Š åŠŸèƒ½æ¸¬è©¦**: $FUNC_PASSED/$FUNC_TOTAL é€šé" >> test_report.md
                  
                  TOTAL_FUNC_FAILED=$((FUNC_FAILED + FUNC_ERROR))
                  if [ "$TOTAL_FUNC_FAILED" -gt 0 ]; then
                    echo "" >> test_report.md
                    echo "**âŒ å¤±æ•—çš„åŠŸèƒ½æ¸¬è©¦ ($TOTAL_FUNC_FAILED å€‹):**" >> test_report.md
                    
                    # æå–å¤±æ•—æ¸¬è©¦åç¨±
                    if grep "FAILED" functional_output.txt | grep -o "test_petsard.py::[^[:space:]]*" | sed 's/test_petsard.py:://' > failed_functional.txt 2>/dev/null && [ -s failed_functional.txt ]; then
                      cat failed_functional.txt | while IFS= read -r test_name; do
                        echo "â€¢ \`$test_name\`" >> test_report.md
                      done
                    fi
                    
                    # é¡¯ç¤ºéŒ¯èª¤è©³æƒ…
                    if grep -q "FAILED\|ERROR" functional_output.txt; then
                      echo "" >> test_report.md
                      echo "**éŒ¯èª¤è©³æƒ…ï¼š**" >> test_report.md
                      echo "```" >> test_report.md
                      grep -A 5 "short test summary" functional_output.txt | head -20 >> test_report.md
                      echo "```" >> test_report.md
                    fi
                  fi
                fi
              fi
            fi
          fi
          
          echo "" >> test_report.md

      - name: ğŸ“Š Generate Test Summary
        run: |
          echo "---" >> test_report.md
          echo "" >> test_report.md
          echo "### ğŸ“Š ç¸½çµ Summary" >> test_report.md
          echo "" >> test_report.md

          # æª¢æŸ¥æ‰€æœ‰æ­¥é©Ÿçš„ç‹€æ…‹
          RUFF_STATUS="${{ steps.ruff-check.outputs.ruff_status }}"
          UNIT_STATUS="${{ steps.unit-tests.outputs.test_status }}"
          FUNC_STATUS="${{ steps.functional-tests.outputs.functional_status }}"

          if [[ "$RUFF_STATUS" == "success" && "$UNIT_STATUS" == "success" && "$FUNC_STATUS" == "success" ]]; then
            echo "## ğŸ‰ æ‰€æœ‰æª¢æŸ¥é€šéï¼All Checks Passed!" >> test_report.md
            echo "test_overall=success" >> $GITHUB_ENV
          else
            echo "## âš ï¸ æª¢æŸ¥çµæœ Check Results" >> test_report.md
            echo "" >> test_report.md
            echo "| æª¢æŸ¥é …ç›® | ç‹€æ…‹ |" >> test_report.md
            echo "|---------|------|" >> test_report.md
            echo "| ç¨‹å¼ç¢¼å“è³ª Code Quality | $([ "$RUFF_STATUS" == "success" ] && echo "âœ… é€šé" || echo "âŒ å¤±æ•—") |" >> test_report.md
            echo "| å–®å…ƒæ¸¬è©¦ Unit Tests | $([ "$UNIT_STATUS" == "success" ] && echo "âœ… é€šé" || echo "âŒ å¤±æ•—") |" >> test_report.md
            echo "| åŠŸèƒ½æ¸¬è©¦ Functional Tests | $([ "$FUNC_STATUS" == "success" ] && echo "âœ… é€šé" || echo "âŒ å¤±æ•—") |" >> test_report.md
            echo "test_overall=failed" >> $GITHUB_ENV
          fi

          echo "" >> test_report.md
          
          # æ·»åŠ è©³ç´°è¼¸å‡ºé€£çµ
          echo "<details>" >> test_report.md
          echo "<summary>ğŸ“ æŸ¥çœ‹è©³ç´°æ¸¬è©¦è¼¸å‡º View Detailed Output</summary>" >> test_report.md
          echo "" >> test_report.md
          echo "### å–®å…ƒæ¸¬è©¦è¼¸å‡º Unit Test Output" >> test_report.md
          echo "```" >> test_report.md
          cat test_output.txt | head -500 >> test_report.md
          echo "```" >> test_report.md
          echo "" >> test_report.md
          echo "### åŠŸèƒ½æ¸¬è©¦è¼¸å‡º Functional Test Output" >> test_report.md
          echo "```" >> test_report.md
          cat functional_output.txt | head -500 >> test_report.md
          echo "```" >> test_report.md
          echo "</details>" >> test_report.md
          
          echo "" >> test_report.md
          echo "---" >> test_report.md
          echo "*Python ${{ matrix.python-version }} | $(date -u +"%Y-%m-%d %H:%M UTC")*" >> test_report.md

      - name: ğŸ’¬ Comment Test Results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('test_report.md', 'utf8');

            // æª¢æŸ¥æ˜¯å¦å·²æœ‰æ¸¬è©¦çµæœç•™è¨€
            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.data.find(comment =>
              comment.user.type === 'Bot' &&
              (comment.body.includes('ğŸ§ª æ¸¬è©¦çµæœ Test Results') || comment.body.includes('ğŸ§ª æ¸¬è©¦å¥—ä»¶å ±å‘Š Test Suite Report'))
            );

            const commentBody = `## ğŸ§ª æ¸¬è©¦å¥—ä»¶å ±å‘Š Test Suite Report\n\n${report}`;

            if (botComment) {
              // æ›´æ–°ç¾æœ‰ç•™è¨€
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: commentBody
              });
            } else {
              // å‰µå»ºæ–°ç•™è¨€
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: commentBody
              });
            }

      - name: ğŸ“¤ Upload Test Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-python-${{ matrix.python-version }}
          path: |
            test_output.txt
            functional_output.txt
            test_report.md
            coverage.xml
            failures.txt
            summary.txt
            coverage_detail.txt
            coverage_table.txt
            ruff_output.txt
            ruff_report.md
            failed_tests.txt
            failed_functional.txt
            pytest-results.xml
          retention-days: 7

      - name: â„¹ï¸ Test Status Summary
        if: always()
        run: |
          if [[ "$test_overall" == "success" ]]; then
            echo "::notice::ğŸ‰ æ‰€æœ‰æª¢æŸ¥é€šéï¼All checks passed for Python ${{ matrix.python-version }} (Code Quality + Tests)"
          else
            echo "::warning::âš ï¸ éƒ¨åˆ†æª¢æŸ¥å¤±æ•—ï¼Œä½†ä¸æœƒé˜»æ­¢åˆä½µã€‚Some checks failed for Python ${{ matrix.python-version }} (Code Quality + Tests), but merge is not blocked."
          fi
