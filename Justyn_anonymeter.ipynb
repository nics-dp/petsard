{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is [Adult]: [Adt Income] adult.csv comparision.\n",
      "Now is [Adult] original data been load: [Adt Income] adult.csv.\n",
      "Bootstrap df: 3 times is done.\n",
      "Now is [Adult] by library SDV.\n",
      "Now is [Adult] by method CoupulaGAN in library SDV.\n",
      "Trail as [Adult]_SDV_CoupulaGAN_0.\n",
      "Metafile loading time: 0.0312 sec.\n",
      "We are execute SingleTable - GaussianCoupula.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PETs_Tool\n",
    "\n",
    "\n",
    "folder_raw = '.\\\\data'\n",
    "folder_SD  = '.\\\\data_dpsd'\n",
    "\n",
    "\n",
    "\n",
    "dict_PETs_setting = {'adult' : {'filename'    : '[Adult]'\n",
    "                               ,'read_params' : {'downcast'       : 'N' # 'Y'\n",
    "                                                ,'label_encoding' : 'Y'}\n",
    "                            #    ,'describe_params' : {'data': {'?'}}\n",
    "                               }\n",
    "                    }\n",
    "dict_filename = {'adult': {'raw' : '[Adt Income] adult.csv'\n",
    "                          }\n",
    "                }\n",
    "dict_filename = {key: {**value, 'params': dict_PETs_setting.get(key, {})} \n",
    "                 for key, value in dict_filename.items()}\n",
    "# print(dict_filename)\n",
    "\n",
    "\n",
    "\n",
    "# update default in SDV\n",
    "list_adult_SD_SDV_train = ['CoupulaGAN'\n",
    "                          ,'CTGAN'\n",
    "                          ,'GaussianCoupula'\n",
    "                          ,'TVAE'\n",
    "                          ]\n",
    "dict_adult_SD_SDV_train = {k: {'sd_params': {'model': k}} for k in list_adult_SD_SDV_train}\n",
    "dict_filename = {key: PETs_Tool.PETs_util.update_append_nested(value\n",
    "                                                              ,{'SD_train': dict_adult_SD_SDV_train}\n",
    "                                                              ) \n",
    "                 for key, value in dict_filename.items()}\n",
    "dict_adult_SD_SDV_train_default = {'sd_params': {'save_model': 'N'}\n",
    "                                  ,'sample'   : 'Y'\n",
    "                                  ,'sample_params' : {'sample_rows_as_raw' : 'Y'\n",
    "                                                     ,'save_data' : 'N'}\n",
    "                                  }\n",
    "dict_adult_SD_train = {'SDV' : {key: PETs_Tool.PETs_util.update_append_nested(dict_adult_SD_SDV_train_default\n",
    "                                                                       ,dict_adult_SD_SDV_train.get(key ,{})\n",
    "                                                                       )\n",
    "                                for key in dict_adult_SD_SDV_train\n",
    "                               }\n",
    "                      }\n",
    "dict_filename = {k1: {k2: dict_adult_SD_train if k2 == 'SD_train' else v2\n",
    "                      for k2 ,v2 in dict_filename[k1].items()\n",
    "                     } \n",
    "                 for k1 in dict_filename\n",
    "                }\n",
    "# print(dict_filename)\n",
    "\n",
    "\n",
    "\n",
    "dict_bootstrap = {'bootstrap_params' : {'bootstrap_time' : 3 # 30\n",
    "                                       ,'sample_ratio'   : 0.8\n",
    "                                       ,'random_state'   : None\n",
    "                                       }\n",
    "                 ,'index_params' : {'index_save'      : 'N'\n",
    "                                   ,'index_save_data' : 'N'\n",
    "                                   ,'index_filename'  : 'Anomymeter'\n",
    "                                   }\n",
    "                 }\n",
    "# import json\n",
    "# print(json.dumps(dict_bootstrap ,indent=4))\n",
    "\n",
    "__Synther_param = {'sd_params': {'metadata' : 'SingleTable'\n",
    "                                ,'save_model' : 'N'}\n",
    "                  ,'sample' : 'Y'\n",
    "                  ,'sample_params' : {'sample_rows_as_raw' : 'Y'\n",
    "                                     ,'save_data' : 'N'}\n",
    "                  }\n",
    "aux_cols = [['age' ,'fnlwgt' ,'race' ,'gender' ,'native-country']\n",
    "           ,['workclass' ,'education' ,'capital-gain' ,'capital-loss' ,'hours-per-week']\n",
    "           ]\n",
    "\n",
    "__param_anonymeter = {'SinglingOut': {'univariate'   : 'Y'\n",
    "                                     ,'multivariate' : 'N'\n",
    "                                     }\n",
    "                     ,'Linkability' : 'Y'\n",
    "                     ,'Linkability_params' : {'aux_cols' : aux_cols}\n",
    "                     ,'Inference' : 'Y'\n",
    "                     ,'Inference_params' : {'secret' : ''} # all columns\n",
    "                     }\n",
    "\n",
    "\n",
    "\n",
    "__dict_anonymeter_result = {}\n",
    "for __dataset ,v in dict_filename.items():\n",
    "    __filename = v['params']['filename']\n",
    "    print(f\"Now is {__filename}: {v['raw']} comparision.\")\n",
    "\n",
    "    __Loader = PETs_Tool.PETs_Loader(os.path.join(folder_raw ,v['raw'])\n",
    "                                    ,v['params']\n",
    "                                    )\n",
    "    __df_ori = __Loader.data\n",
    "    print(f\"Now is {__filename} original data been load: {v['raw']}.\")\n",
    "\n",
    "    dict_boostrap_index = PETs_Tool.PETs_util.df_bootstrap(__df_ori ,dict_bootstrap)\n",
    "    digits_max_boostrap = len(str(max(dict_boostrap_index.keys()))) # max boostrap times for fill zero\n",
    "\n",
    "    for __library ,__dict_sd in v['SD_train'].items():\n",
    "        print(f\"Now is {__filename} by library {__library}.\")\n",
    "\n",
    "        for __method ,__params in __dict_sd.items():\n",
    "            print(f\"Now is {__filename} by method {__method} in library {__library}.\")\n",
    "\n",
    "            import copy\n",
    "            for time ,dict_idx in dict_boostrap_index.items():\n",
    "                __trail_name = f\"{__filename}_{__library}_{__method}_{str(time).zfill(digits_max_boostrap)}\"\n",
    "                print(f\"Trail as {__trail_name}.\")\n",
    "\n",
    "                ####### ####### #######\n",
    "                # init - ori ,ctrl ,syn #\n",
    "                ####### ####### #######\n",
    "                __Synther = copy.deepcopy(__Loader)\n",
    "                __data = __Synther.data.copy()\n",
    "                __Synther.data_ori     = __data.loc[dict_boostrap_index[time]['idx_train'     ]].reset_index(drop=True)\n",
    "                __Synther.data_control = __data.loc[dict_boostrap_index[time]['idx_validation']].reset_index(drop=True)\n",
    "                __Synther.data         = __Synther.data_ori.copy()\n",
    "                __Synther.data_syn     = PETs_Tool.PETs_SD_SDV(__Synther ,__Synther_param).synthetic_data\n",
    "                __Synther.data = __data.copy()\n",
    "\n",
    "\n",
    "                ####### ####### #######\n",
    "                # _anonymeter         #\n",
    "                ####### ####### #######\n",
    "                __anonymeter = PETs_eval_anonymeter(data_ori     = __Synther.data_ori\n",
    "                                                   ,data_syn     = __Synther.data_syn\n",
    "                                                   ,data_control = __Synther.data_control\n",
    "                                                   ,params = __param_anonymeter\n",
    "                                                   )\n",
    "                __evaluator = __anonymeter.evaluators\n",
    "                \n",
    "                __dict_anonymeter_result[__trail_name] = {}\n",
    "                if 'SinglingOut' in __evaluator:\n",
    "                    if 'univariate' in __evaluator['SinglingOut']:\n",
    "                        __dict_anonymeter_result[__trail_name]['SinglingOut_univariate_Risk'] = __evaluator['SinglingOut']['univariate'].risk().value\n",
    "                    if 'multivariate' in __evaluator['SinglingOut']:\n",
    "                        __dict_anonymeter_result[__trail_name]['SinglingOut_multivariate_Risk'] = __evaluator['SinglingOut']['multivariate'].risk().value\n",
    "\n",
    "                if 'Linkability' in __evaluator:\n",
    "                    __dict_anonymeter_result[__trail_name]['Linkability_Risk'] = __evaluator['Linkability'].risk().value\n",
    "                \n",
    "                if 'Inference' in __evaluator:\n",
    "                    __dict_anonymeter_result[__trail_name].update({'Inference_'+__secret: __secret_result.risk().value for __secret ,__secret_result in __evaluator['Inference'].items()})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # 20231116, Justyn: refer to\n",
    "                # https://github.com/statice/anonymeter/blob/main/notebooks/anonymeter_example.ipynb\n",
    "                # https://storage.googleapis.com/statice-public/anonymeter-datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SinglingOut': {},\n",
       " 'Linkability': <anonymeter.evaluators.linkability_evaluator.LinkabilityEvaluator at 0x181de747c70>,\n",
       " 'Inference': {'age': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181dda3ec50>,\n",
       "  'workclass': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181c5a54fa0>,\n",
       "  'fnlwgt': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181dba7f070>,\n",
       "  'education': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181dda3e680>,\n",
       "  'educational-num': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181dba7e020>,\n",
       "  'marital-status': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181c5ce4130>,\n",
       "  'occupation': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181de24eb30>,\n",
       "  'relationship': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181de24fdc0>,\n",
       "  'race': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181de24e8c0>,\n",
       "  'gender': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181de772cb0>,\n",
       "  'capital-gain': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181de770bb0>,\n",
       "  'capital-loss': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181dbc439a0>,\n",
       "  'hours-per-week': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181de770100>,\n",
       "  'native-country': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181de770490>,\n",
       "  'income': <anonymeter.evaluators.inference_evaluator.InferenceEvaluator at 0x181dbc436d0>}}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__anonymeter.evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Singling-Out Evaluator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 203 failed queries out of 500. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singling out evaluation failed with Optimal parameters not found: The maximum number of function evaluations is exceeded..Please re-run this cell.For more stable results increase `n_attacks`. Note that this will make the evaluation slower.\n",
      "Singling-Out Evaluator time: 34.2756 sec.\n",
      "Now is Linkability Evaluator\n",
      "aux_cols are [age, fnlwgt, race, gender, native-country]\n",
      "and [workclass, education, capital-gain, capital-loss, hours-per-week].\n",
      "Linkability Evaluator time: 6.1276 sec.\n",
      "Now is Inference Evaluator: secret is age.\n",
      "Inference Evaluator time: 2.0831 sec.\n",
      "Now is Inference Evaluator: secret is workclass.\n",
      "Inference Evaluator time: 2.0747 sec.\n",
      "Now is Inference Evaluator: secret is fnlwgt.\n",
      "Inference Evaluator time: 2.0553 sec.\n",
      "Now is Inference Evaluator: secret is education.\n",
      "Inference Evaluator time: 2.0643 sec.\n",
      "Now is Inference Evaluator: secret is educational-num.\n",
      "Inference Evaluator time: 2.3981 sec.\n",
      "Now is Inference Evaluator: secret is marital-status.\n",
      "Inference Evaluator time: 2.9898 sec.\n",
      "Now is Inference Evaluator: secret is occupation.\n",
      "Inference Evaluator time: 2.6515 sec.\n",
      "Now is Inference Evaluator: secret is relationship.\n",
      "Inference Evaluator time: 2.5057 sec.\n",
      "Now is Inference Evaluator: secret is race.\n",
      "Inference Evaluator time: 2.6395 sec.\n",
      "Now is Inference Evaluator: secret is gender.\n",
      "Inference Evaluator time: 3.0181 sec.\n",
      "Now is Inference Evaluator: secret is capital-gain.\n",
      "Inference Evaluator time: 2.5771 sec.\n",
      "Now is Inference Evaluator: secret is capital-loss.\n",
      "Inference Evaluator time: 2.5652 sec.\n",
      "Now is Inference Evaluator: secret is hours-per-week.\n",
      "Inference Evaluator time: 2.5815 sec.\n",
      "Now is Inference Evaluator: secret is native-country.\n",
      "Inference Evaluator time: 2.5417 sec.\n",
      "Now is Inference Evaluator: secret is income.\n",
      "Inference Evaluator time: 2.5538 sec.\n"
     ]
    }
   ],
   "source": [
    "__anonymeter = PETs_eval_anonymeter(data_ori     = __Synther.data_ori\n",
    "                                                   ,data_syn     = __Synther.data_syn\n",
    "                                                   ,data_control = __Synther.data_control\n",
    "                                                   ,params = __param_anonymeter\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PETs_eval_anonymeter():\n",
    "    import PETs_Tool\n",
    "    from anonymeter import evaluators\n",
    "\n",
    "    def __init__(self\n",
    "                ,data_ori ,data_syn ,data_control\n",
    "                ,params={} ,**kwargs):\n",
    "        ####### ####### #######\n",
    "        # init - params       #\n",
    "        ####### ####### #######\n",
    "        # {'evaluate_params' : {'anonymeter':\n",
    "        default_params = {'SinglingOut' : {'univariate'   : 'Y'\n",
    "                                          ,'multivariate' : 'N'\n",
    "                                          }\n",
    "                         ,'SinglingOut_params' : {'univariate'   : {'n_attacks' : 500}\n",
    "                                                 ,'multivariate' : {'n_attacks' : 500\n",
    "                                                                   ,'n_cols'    : 2\n",
    "                                                                   }\n",
    "                                                 }\n",
    "                         ,'Linkability' : 'Y'\n",
    "                         ,'Linkability_params' : {'n_attacks'   : 2000\n",
    "                                                 ,'aux_cols'    : []\n",
    "                                                 # [TODO] study how to set n_neighbors\n",
    "                                                 ,'n_neighbors' : 10\n",
    "                                                 # n_jobs follow joblib convention.\n",
    "                                                 # -1 = all cores,\n",
    "                                                 # -2 = all execept one\n",
    "                                                 ,'n_jobs'      : -2\n",
    "                                                 }\n",
    "                         ,'Inference' : 'Y'\n",
    "                         ,'Inference_params' : {'n_attacks'   : 1000\n",
    "                                               ,'secret'      : ''\n",
    "                                               # n_jobs follow joblib convention.\n",
    "                                               # -1 = all cores,\n",
    "                                               # -2 = all execept one\n",
    "                                               ,'n_jobs'      : -2\n",
    "                                               }\n",
    "                         }\n",
    "        self.params = update_append_nested(default_params ,params)\n",
    "        self.data_ori     = data_ori\n",
    "        self.data_syn     = data_syn\n",
    "        self.data_control = data_control\n",
    "        self.evaluators   = {}\n",
    "\n",
    "        import warnings\n",
    "        with warnings.catch_warnings():\n",
    "            # anonymeter\\evaluators\\singling_out_evaluator.py:97:\n",
    "            # FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version.\n",
    "            # Use isinstance(dtype, CategoricalDtype) instead elif is_categorical_dtype(values)\n",
    "            warnings.simplefilter(\"ignore\" ,category=FutureWarning)\n",
    "            # c:\\Program Files\\Python310\\lib\\site-packages\\anonymeter\\stats\\confidence.py:215:\n",
    "            # UserWarning: Attack is as good or worse as baseline model.\n",
    "            # Estimated rates: attack = 0.30674239114619767, baseline = 0.30773856438771213.\n",
    "            # Analysis results cannot be trusted. self._sanity_check()\n",
    "            warnings.simplefilter(\"ignore\" ,category=UserWarning)\n",
    "\n",
    "            ####### ####### #######\n",
    "            # init - SinglingOut  #\n",
    "            ####### ####### #######\n",
    "            if any(v == 'Y' for v in self.params['SinglingOut'].values()):\n",
    "                self.evaluators['SinglingOut'] = {}\n",
    "\n",
    "                if self.params['SinglingOut']['univariate'] == 'Y':\n",
    "                    self.__SinglingOutEvaluator(mode = 'univariate'\n",
    "                                               ,**self.params['SinglingOut_params']['univariate']\n",
    "                                               )\n",
    "                # if self.params['SinglingOut']['multivariate'] == 'Y':\n",
    "                #     self.__SinglingOutEvaluator(mode = 'multivariate'\n",
    "                #                                ,**self.params['SinglingOut_params']['multivariate']\n",
    "                #                                )\n",
    "            ####### ####### #######\n",
    "            # init - SinglingOut  #\n",
    "            ####### ####### #######\n",
    "            if self.params['Linkability'] == 'Y':\n",
    "                self.__LinkabilityEvaluator(**self.params['Linkability_params'])\n",
    "\n",
    "\n",
    "            if self.params['Inference'] == 'Y':\n",
    "                self.evaluators['Inference'] = {}\n",
    "                if self.params['Inference_params']['secret'] == '':\n",
    "                    for __secret in self.data_syn.columns:\n",
    "                        self.params['Inference_params']['secret'] = __secret\n",
    "                        self.__InferenceEvaluator(**self.params['Inference_params'])\n",
    "                else:\n",
    "                    self.__InferenceEvaluator(**self.params['Inference_params'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ####### ####### #######\n",
    "    # SinglingOut         #\n",
    "    ####### ####### #######\n",
    "    def __SinglingOutEvaluator(self ,mode ,**kwargs):\n",
    "        import time\n",
    "        __time_start = time.time()\n",
    "        print('Now is Singling-Out Evaluator')\n",
    "        __evaluator = evaluators.SinglingOutEvaluator(ori       = self.data_ori\n",
    "                                                     ,syn       = self.data_syn\n",
    "                                                     ,control   = self.data_control\n",
    "                                                     ,**kwargs\n",
    "                                                     )\n",
    "        try:\n",
    "            __evaluator.evaluate(mode=mode)\n",
    "            # print(__evaluator.risk())\n",
    "            # print(\"Successs rate of main attack    :\" ,__evaluator.results().attack_rate  )\n",
    "            # print(\"Successs rate of baseline attack:\" ,__evaluator.results().baseline_rate)\n",
    "            # print(\"Successs rate of control attack :\" ,__evaluator.results().control_rate )\n",
    "            self.evaluators['SinglingOut'][mode] = __evaluator\n",
    "        except RuntimeError as ex:\n",
    "            print(f\"Singling out evaluation failed with {ex}.\"\n",
    "                   \"Please re-run this cell.\"\n",
    "                   \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "                   \"make the evaluation slower.\")\n",
    "        # multivariance\n",
    "        # try:\n",
    "        #     __evaluator.evaluate(mode='multivariate')\n",
    "        #     __risk = __evaluator.risk()\n",
    "        #     print(__risk)\n",
    "        #     res = __evaluator.results()\n",
    "        #     print(__evaluator.queries()[:3])\n",
    "        # except RuntimeError as ex:\n",
    "        #     print(f\"Singling out evaluation failed with {ex}. Please re-run this cell.\"\n",
    "        #           \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "        #           \"make the evaluation slower.\")\n",
    "        print(f\"Singling-Out Evaluator time: {round(time.time()-__time_start ,4)} sec.\")\n",
    "\n",
    "\n",
    "\n",
    "    ####### ####### #######\n",
    "    # Linkability         #\n",
    "    ####### ####### #######\n",
    "    def __LinkabilityEvaluator(self ,n_jobs ,aux_cols ,**kwargs):\n",
    "        import time\n",
    "        __time_start = time.time()\n",
    "        print('Now is Linkability Evaluator')\n",
    "        __str_aux_cols = \"\\nand \".join(f\"[{', '.join(row)}]\" for row in aux_cols)\n",
    "        print(f\"aux_cols are {__str_aux_cols}.\")\n",
    "        __evaluator = evaluators.LinkabilityEvaluator(ori      = self.data_ori\n",
    "                                                     ,syn      = self.data_syn\n",
    "                                                     ,control  = self.data_control\n",
    "                                                     ,aux_cols = aux_cols\n",
    "                                                     ,**kwargs\n",
    "                                                     )\n",
    "        __evaluator.evaluate(n_jobs=n_jobs)\n",
    "        self.evaluators['Linkability'] = __evaluator\n",
    "        # print(__evaluator.risk())\n",
    "        # print(\"Successs rate of main attack    :\" ,__evaluator.results().attack_rate  )\n",
    "        # print(\"Successs rate of baseline attack:\" ,__evaluator.results().baseline_rate)\n",
    "        # print(\"Successs rate of control attack :\" ,__evaluator.results().control_rate )\n",
    "        print(f\"Linkability Evaluator time: {round(time.time()-__time_start ,4)} sec.\")\n",
    "\n",
    "\n",
    "\n",
    "    ####### ####### #######\n",
    "    # Inference           #\n",
    "    ####### ####### #######\n",
    "    def __InferenceEvaluator(self ,secret ,n_jobs ,**kwargs):\n",
    "        import time\n",
    "        __time_start = time.time()\n",
    "        print(f\"Now is Inference Evaluator: secret is {secret}.\")\n",
    "        __aux_cols = [col for col in self.data_syn.columns if col != secret]\n",
    "        __evaluator = evaluators.InferenceEvaluator(ori      = self.data_ori\n",
    "                                                   ,syn      = self.data_syn\n",
    "                                                   ,control  = self.data_control\n",
    "                                                   ,aux_cols = __aux_cols\n",
    "                                                   ,secret   = secret\n",
    "                                                   ,**kwargs\n",
    "                                                   )\n",
    "        __evaluator.evaluate(n_jobs=n_jobs)\n",
    "        # print(__evaluator.risk())\n",
    "        # print(\"Successs rate of main attack    :\" ,__evaluator.results().attack_rate  )\n",
    "        # print(\"Successs rate of baseline attack:\" ,__evaluator.results().baseline_rate)\n",
    "        # print(\"Successs rate of control attack :\" ,__evaluator.results().control_rate )\n",
    "        self.evaluators['Inference'][secret] = __evaluator\n",
    "        print(f\"Inference Evaluator time: {round(time.time()-__time_start ,4)} sec.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Singling-Out Evaluator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 200 failed queries out of 500. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singling-Out Evaluator time: 40.643 sec.\n",
      "Now is Linkability Evaluator\n",
      "aux_cols are [age, fnlwgt, race, gender, native-country]\n",
      "and [workclass, education, capital-gain, capital-loss, hours-per-week].\n",
      "Linkability Evaluator time: 9.0073 sec.\n",
      "Now is Inference Evaluator: secret is age.\n",
      "Inference Evaluator time: 3.2676 sec.\n",
      "Now is Inference Evaluator: secret is workclass.\n",
      "Inference Evaluator time: 2.2787 sec.\n",
      "Now is Inference Evaluator: secret is fnlwgt.\n",
      "Inference Evaluator time: 2.2634 sec.\n",
      "Now is Inference Evaluator: secret is education.\n",
      "Inference Evaluator time: 2.2382 sec.\n",
      "Now is Inference Evaluator: secret is educational-num.\n",
      "Inference Evaluator time: 2.4507 sec.\n",
      "Now is Inference Evaluator: secret is marital-status.\n",
      "Inference Evaluator time: 2.5689 sec.\n",
      "Now is Inference Evaluator: secret is occupation.\n",
      "Inference Evaluator time: 2.2586 sec.\n",
      "Now is Inference Evaluator: secret is relationship.\n",
      "Inference Evaluator time: 2.2576 sec.\n",
      "Now is Inference Evaluator: secret is race.\n",
      "Inference Evaluator time: 2.1883 sec.\n",
      "Now is Inference Evaluator: secret is gender.\n",
      "Inference Evaluator time: 2.2418 sec.\n",
      "Now is Inference Evaluator: secret is capital-gain.\n",
      "Inference Evaluator time: 2.5116 sec.\n",
      "Now is Inference Evaluator: secret is capital-loss.\n",
      "Inference Evaluator time: 2.5175 sec.\n",
      "Now is Inference Evaluator: secret is hours-per-week.\n",
      "Inference Evaluator time: 2.6138 sec.\n",
      "Now is Inference Evaluator: secret is native-country.\n",
      "Inference Evaluator time: 2.6674 sec.\n",
      "Now is Inference Evaluator: secret is income.\n",
      "Inference Evaluator time: 2.4389 sec.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aux_cols = [['age' ,'fnlwgt' ,'race' ,'gender' ,'native-country']\n",
    "           ,['workclass' ,'education' ,'capital-gain' ,'capital-loss' ,'hours-per-week']\n",
    "           ]\n",
    "\n",
    "__param_anonymeter = {'SinglingOut': {'univariate'   : 'Y'\n",
    "                                     ,'multivariate' : 'N'\n",
    "                                     }\n",
    "                     ,'Linkability' : 'Y'\n",
    "                     ,'Linkability_params' : {'aux_cols' : aux_cols}\n",
    "                     ,'Inference' : 'Y'\n",
    "                     ,'Inference_params' : {'secret' : ''} # all columns\n",
    "                     }\n",
    "\n",
    "__anonymeter = PETs_eval_anonymeter(data_ori     = __Synther.data_ori\n",
    "                                   ,data_syn     = __Synther.data_syn\n",
    "                                   ,data_control = __Synther.data_control\n",
    "                                   ,params = __param_anonymeter\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 這是已經有檔案的做法 (Unfinished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_adult_SD_SDV = {'CoupulaGAN'      : ['[Adt Income]_[SDV]_[CoupulaGAN]_20231106_113038_Asia_Taipei_10000.csv']\n",
    "                    ,'CTGAN'           : ['[Adt Income]_[SDV]_[CTGAN]_20231106_093702_Asia_Taipei_10000.csv']\n",
    "                    ,'GaussianCoupula' : ['[Adt Income]_[SDV]_[GaussianCoupula]_20231106_093622_Asia_Taipei_10000.csv']\n",
    "                    ,'TVAE'            : ['[Adt Income]_[SDV]_[TVAE]_20231106_105252_Asia_Taipei_10000.csv']\n",
    "                    }\n",
    "dict_filename = {key: {**value ,'SDV': dict_adult_SD_SDV} \n",
    "                 for key, value in dict_filename.items()}\n",
    "\n",
    "\n",
    "\n",
    "for __dataset ,v in dict_filename.items():\n",
    "    __filename = v['params']['filename']\n",
    "    print(f\"Now is {__filename}: {v['raw']} comparision.\")\n",
    "\n",
    "    __df_ori = PETs_Tool.PETs_Loader(os.path.join(folder_raw ,v['raw'])\n",
    "                                    ,v['params']\n",
    "                                    ).data\n",
    "    print(f\"Now is {__filename} original data been load: {v['raw']}.\")\n",
    "\n",
    "    for __library ,__dict_sd in v['SD'].items():\n",
    "        print(f\"Now is {__filename} by library {__library}.\")\n",
    "\n",
    "        for __method ,__list_sd in __dict_sd.items():\n",
    "            print(f\"Now is {__filename} by method {__method} in library {__library}.\")\n",
    "            __list_sd = [__list_sd] if isinstance(__list_sd ,str) else __list_sd\n",
    "            for __filename_sd in __list_sd:\n",
    "                # 20231116, Justyn: 這裡是合成資料有落地\n",
    "                #                   如果必要，可以直接調用 PETs_SD_* 結果的.synthetic_data\n",
    "                __df_syn = PETs_Tool.PETs_Loader(os.path.join(folder_SD ,__filename_sd)\n",
    "                                                ,v['params']\n",
    "                                                ).data\n",
    "                print(f\"Now is {__filename} synthetic data been load: {__filename_sd}.\")\n",
    "\n",
    "                # 20231116, Justyn: refer to\n",
    "                # https://github.com/statice/anonymeter/blob/main/notebooks/anonymeter_example.ipynb\n",
    "                # https://storage.googleapis.com/statice-public/anonymeter-datasets\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
