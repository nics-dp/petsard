{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is [Adult]: [Adt Income] adult.csv comparision.\n",
      "Now is [Adult] original data been load: [Adt Income] adult.csv.\n",
      "Bootstrap df: 3 times is done.\n",
      "Now is [Adult] by library SDV.\n",
      "Now is [Adult] by method GaussianCoupula in library SDV.\n",
      "Metafile loading time: 0.026 sec.\n",
      "We are execute SingleTable - GaussianCoupula.\n",
      "Model training time: 22.1705 sec.\n",
      "Sample as same as raw data: # 48842 rows data by GaussianCoupula in 1.9991 秒\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PETs_Tool\n",
    "from anonymeter import evaluators\n",
    "\n",
    "\n",
    "folder_raw = '.\\\\data'\n",
    "folder_SD  = '.\\\\data_dpsd'\n",
    "\n",
    "\n",
    "\n",
    "dict_PETs_setting = {'adult' : {'filename'    : '[Adult]'\n",
    "                               ,'read_params' : {'downcast' : 'Y'}\n",
    "                               ,'describe_params' : {'data': {'?'}}\n",
    "                               }\n",
    "                    }\n",
    "dict_filename = {'adult': {'raw' : '[Adt Income] adult.csv'\n",
    "                          }\n",
    "                }\n",
    "dict_filename = {key: {**value, 'params': dict_PETs_setting.get(key, {})} \n",
    "                 for key, value in dict_filename.items()}\n",
    "# print(dict_filename)\n",
    "\n",
    "\n",
    "\n",
    "# update default in SDV\n",
    "list_adult_SD_SDV_train = ['GaussianCoupula'\n",
    "                        #    'CoupulaGAN'\n",
    "                        #   ,'CTGAN'\n",
    "                        #   ,'GaussianCoupula'\n",
    "                        #   ,'TVAE'\n",
    "                          ]\n",
    "dict_adult_SD_SDV_train = {k: {'sd_params': {'model': k}} for k in list_adult_SD_SDV_train}\n",
    "dict_filename = {key: PETs_Tool.PETs_util.update_append_nested(value\n",
    "                                                              ,{'SD_train': dict_adult_SD_SDV_train}\n",
    "                                                              ) \n",
    "                 for key, value in dict_filename.items()}\n",
    "dict_adult_SD_SDV_train_default = {'sd_params': {'save_model': 'N'}\n",
    "                                  ,'sample'   : 'Y'\n",
    "                                  ,'sample_params' : {'sample_rows_as_raw' : 'Y'\n",
    "                                                     ,'save_data' : 'N'}\n",
    "                                  }\n",
    "dict_adult_SD_train = {'SDV' : {key: PETs_Tool.PETs_util.update_append_nested(dict_adult_SD_SDV_train_default\n",
    "                                                                       ,dict_adult_SD_SDV_train.get(key ,{})\n",
    "                                                                       )\n",
    "                                for key in dict_adult_SD_SDV_train\n",
    "                               }\n",
    "                      }\n",
    "dict_filename = {k1: {k2: dict_adult_SD_train if k2 == 'SD_train' else v2\n",
    "                      for k2 ,v2 in dict_filename[k1].items()\n",
    "                     } \n",
    "                 for k1 in dict_filename\n",
    "                }\n",
    "# print(dict_filename)\n",
    "\n",
    "\n",
    "\n",
    "dict_bootstrap = {'bootstrap_params' : {'bootstrap_time' : 3\n",
    "                                       ,'sample_ratio'   : 0.8\n",
    "                                       ,'random_state'   : None\n",
    "                                       }\n",
    "                 ,'index_params' : {'index_save'      : 'N'\n",
    "                                   ,'index_save_data' : 'N'\n",
    "                                   ,'index_filename'  : 'Anomymeter'\n",
    "                                   }\n",
    "                 }\n",
    "# import json\n",
    "# print(json.dumps(dict_bootstrap ,indent=4))\n",
    "\n",
    "\n",
    "\n",
    "for __dataset ,v in dict_filename.items():\n",
    "    __filename = v['params']['filename']\n",
    "    print(f\"Now is {__filename}: {v['raw']} comparision.\")\n",
    "\n",
    "    __Loader = PETs_Tool.PETs_Loader(os.path.join(folder_raw ,v['raw'])\n",
    "                                    ,v['params']\n",
    "                                    )\n",
    "    __df_ori = __Loader.data\n",
    "    print(f\"Now is {__filename} original data been load: {v['raw']}.\")\n",
    "\n",
    "    dict_boostrap_index = PETs_Tool.PETs_util.df_bootstrap(__df_ori ,dict_bootstrap)\n",
    "\n",
    "    for __library ,__dict_sd in v['SD_train'].items():\n",
    "        print(f\"Now is {__filename} by library {__library}.\")\n",
    "\n",
    "        for __method ,__params in __dict_sd.items():\n",
    "            print(f\"Now is {__filename} by method {__method} in library {__library}.\")\n",
    "\n",
    "            __Loader_bkup = __Loader\n",
    "            for time ,dict_idx in dict_boostrap_index.items():\n",
    "                __df_control  = __Loader.data.loc[dict_boostrap_index[time]['idx_validation']].reset_index(drop=True)\n",
    "                __Loader.data = __Loader.data.loc[dict_boostrap_index[time]['idx_train'     ]].reset_index(drop=True)\n",
    "                __df_syn = PETs_Tool.PETs_SD_SDV(__Loader ,__params).synthetic_data\n",
    "\n",
    "                # recover\n",
    "                __Loader = __Loader_bkup\n",
    "                break\n",
    "\n",
    "                # 20231116, Justyn: refer to\n",
    "                # https://github.com/statice/anonymeter/blob/main/notebooks/anonymeter_example.ipynb\n",
    "                # https://storage.googleapis.com/statice-public/anonymeter-datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 342 failed queries out of 500. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrivacyRisk(value=0.0, ci=(0.0, 0.013564739669279447))\n"
     ]
    }
   ],
   "source": [
    "# anonymeter\\evaluators\\singling_out_evaluator.py:97:\n",
    "# FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version.\n",
    "# Use isinstance(dtype, CategoricalDtype) instead elif is_categorical_dtype(values)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\" ,category=FutureWarning)\n",
    "\n",
    "\n",
    "__evaluator = evaluators.SinglingOutEvaluator(ori     = __Loader.data\n",
    "                                             ,syn     = __df_syn\n",
    "                                             ,control = __df_control\n",
    "                                             ,n_attacks=500)\n",
    "\n",
    "try:\n",
    "    __evaluator.evaluate(mode='univariate')\n",
    "    __risk = __evaluator.risk()\n",
    "    print(__risk)\n",
    "    res = __evaluator.results()\n",
    "    print(\"Successs rate of main attack:\", res.attack_rate)\n",
    "    print(\"Successs rate of baseline attack:\", res.baseline_rate)\n",
    "    print(\"Successs rate of control attack:\", res.control_rate)\n",
    "except RuntimeError as ex:\n",
    "    print(f\"Singling out evaluation failed with {ex}. Please re-run this cell.\"\n",
    "          \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "          \"make the evaluation slower.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 496 failed queries out of 500. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 16\u001b[0m\n\u001b[0;32m      8\u001b[0m __evaluator \u001b[39m=\u001b[39m evaluators\u001b[39m.\u001b[39mSinglingOutEvaluator(ori     \u001b[39m=\u001b[39m __Loader\u001b[39m.\u001b[39mdata\n\u001b[0;32m      9\u001b[0m                                              ,syn     \u001b[39m=\u001b[39m __df_syn\n\u001b[0;32m     10\u001b[0m                                              ,control \u001b[39m=\u001b[39m __df_control\n\u001b[0;32m     11\u001b[0m                                              ,n_attacks\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m\n\u001b[0;32m     12\u001b[0m                                              ,n_cols\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m\n\u001b[0;32m     13\u001b[0m                                              )\n\u001b[0;32m     15\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     __evaluator\u001b[39m.\u001b[39;49mevaluate(mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmultivariate\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     17\u001b[0m     __risk \u001b[39m=\u001b[39m __evaluator\u001b[39m.\u001b[39mrisk()\n\u001b[0;32m     18\u001b[0m     \u001b[39mprint\u001b[39m(__risk)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\anonymeter\\evaluators\\singling_out_evaluator.py:474\u001b[0m, in \u001b[0;36mSinglingOutEvaluator.evaluate\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_baseline_queries \u001b[39m=\u001b[39m _evaluate_queries(df\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ori, queries\u001b[39m=\u001b[39mbaseline_queries)\n\u001b[0;32m    472\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_baseline \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_baseline_queries)\n\u001b[1;32m--> 474\u001b[0m queries \u001b[39m=\u001b[39m _generate_singling_out_queries(\n\u001b[0;32m    475\u001b[0m     df\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_syn, n_attacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_attacks, n_cols\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_cols, mode\u001b[39m=\u001b[39;49mmode\n\u001b[0;32m    476\u001b[0m )\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_queries \u001b[39m=\u001b[39m _evaluate_queries(df\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ori, queries\u001b[39m=\u001b[39mqueries)\n\u001b[0;32m    478\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_success \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_queries)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\anonymeter\\evaluators\\singling_out_evaluator.py:364\u001b[0m, in \u001b[0;36m_generate_singling_out_queries\u001b[1;34m(df, mode, n_attacks, n_cols)\u001b[0m\n\u001b[0;32m    361\u001b[0m     queries \u001b[39m=\u001b[39m univariate_singling_out_queries(df\u001b[39m=\u001b[39mdf, n_queries\u001b[39m=\u001b[39mn_attacks)\n\u001b[0;32m    363\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmultivariate\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 364\u001b[0m     queries \u001b[39m=\u001b[39m multivariate_singling_out_queries(df\u001b[39m=\u001b[39;49mdf, n_queries\u001b[39m=\u001b[39;49mn_attacks, n_cols\u001b[39m=\u001b[39;49mn_cols)\n\u001b[0;32m    366\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameter `mode` can be either `univariate` or `multivariate`. Got \u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\anonymeter\\evaluators\\singling_out_evaluator.py:341\u001b[0m, in \u001b[0;36mmultivariate_singling_out_queries\u001b[1;34m(df, n_queries, n_cols)\u001b[0m\n\u001b[0;32m    337\u001b[0m     columns \u001b[39m=\u001b[39m rng\u001b[39m.\u001b[39mchoice(df\u001b[39m.\u001b[39mcolumns, size\u001b[39m=\u001b[39mn_cols, replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m    339\u001b[0m     query \u001b[39m=\u001b[39m _query_from_record(record\u001b[39m=\u001b[39mrecord, dtypes\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mdtypes, columns\u001b[39m=\u001b[39mcolumns, medians\u001b[39m=\u001b[39mmedians)\n\u001b[1;32m--> 341\u001b[0m     so_queries\u001b[39m.\u001b[39;49mcheck_and_append(query\u001b[39m=\u001b[39;49mquery, df\u001b[39m=\u001b[39;49mdf)\n\u001b[0;32m    343\u001b[0m \u001b[39mreturn\u001b[39;00m so_queries\u001b[39m.\u001b[39mqueries\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\anonymeter\\evaluators\\singling_out_evaluator.py:249\u001b[0m, in \u001b[0;36mUniqueSinglingOutQueries.check_and_append\u001b[1;34m(self, query, df)\u001b[0m\n\u001b[0;32m    245\u001b[0m sorted_query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39msorted\u001b[39m(query))\n\u001b[0;32m    247\u001b[0m \u001b[39mif\u001b[39;00m sorted_query \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set:\n\u001b[1;32m--> 249\u001b[0m     counts \u001b[39m=\u001b[39m safe_query_counts(query\u001b[39m=\u001b[39;49mquery, df\u001b[39m=\u001b[39;49mdf)\n\u001b[0;32m    251\u001b[0m     \u001b[39mif\u001b[39;00m counts \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m counts \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set\u001b[39m.\u001b[39madd(sorted_query)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\anonymeter\\evaluators\\singling_out_evaluator.py:124\u001b[0m, in \u001b[0;36msafe_query_counts\u001b[1;34m(query, df)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return number of elements satisfying a given query.\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(df\u001b[39m.\u001b[39;49mquery(query, engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpython\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    125\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m    126\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQuery \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m failed with \u001b[39m\u001b[39m{\u001b[39;00mex\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4599\u001b[0m, in \u001b[0;36mDataFrame.query\u001b[1;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[0;32m   4597\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   4598\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 4599\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval(expr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   4601\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   4602\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc[res]\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4718\u001b[0m, in \u001b[0;36mDataFrame.eval\u001b[1;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[0;32m   4716\u001b[0m inplace \u001b[39m=\u001b[39m validate_bool_kwarg(inplace, \u001b[39m\"\u001b[39m\u001b[39minplace\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4717\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 4718\u001b[0m index_resolvers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_index_resolvers()\n\u001b[0;32m   4719\u001b[0m column_resolvers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cleaned_column_resolvers()\n\u001b[0;32m   4720\u001b[0m resolvers \u001b[39m=\u001b[39m column_resolvers, index_resolvers\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:616\u001b[0m, in \u001b[0;36mNDFrame._get_index_resolvers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    614\u001b[0m d: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Series \u001b[39m|\u001b[39m MultiIndex] \u001b[39m=\u001b[39m {}\n\u001b[0;32m    615\u001b[0m \u001b[39mfor\u001b[39;00m axis_name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_AXIS_ORDERS:\n\u001b[1;32m--> 616\u001b[0m     d\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_axis_resolvers(axis_name))\n\u001b[0;32m    618\u001b[0m \u001b[39mreturn\u001b[39;00m {clean_column_name(k): v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m d\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(k, \u001b[39mint\u001b[39m)}\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:597\u001b[0m, in \u001b[0;36mNDFrame._get_axis_resolvers\u001b[1;34m(self, axis)\u001b[0m\n\u001b[0;32m    594\u001b[0m     level \u001b[39m=\u001b[39m i\n\u001b[0;32m    596\u001b[0m level_values \u001b[39m=\u001b[39m axis_index\u001b[39m.\u001b[39mget_level_values(level)\n\u001b[1;32m--> 597\u001b[0m s \u001b[39m=\u001b[39m level_values\u001b[39m.\u001b[39;49mto_series()\n\u001b[0;32m    598\u001b[0m s\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m axis_index\n\u001b[0;32m    599\u001b[0m d[key] \u001b[39m=\u001b[39m s\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:1590\u001b[0m, in \u001b[0;36mIndex.to_series\u001b[1;34m(self, index, name)\u001b[0m\n\u001b[0;32m   1587\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1588\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\n\u001b[1;32m-> 1590\u001b[0m \u001b[39mreturn\u001b[39;00m Series(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values\u001b[39m.\u001b[39;49mcopy(), index\u001b[39m=\u001b[39mindex, name\u001b[39m=\u001b[39mname)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# anonymeter\\evaluators\\singling_out_evaluator.py:97:\n",
    "# FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version.\n",
    "# Use isinstance(dtype, CategoricalDtype) instead elif is_categorical_dtype(values)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\" ,category=FutureWarning)\n",
    "\n",
    "\n",
    "__evaluator = evaluators.SinglingOutEvaluator(ori     = __Loader.data\n",
    "                                             ,syn     = __df_syn\n",
    "                                             ,control = __df_control\n",
    "                                             ,n_attacks=500\n",
    "                                             ,n_cols=4\n",
    "                                             )\n",
    "\n",
    "try:\n",
    "    __evaluator.evaluate(mode='multivariate')\n",
    "    __risk = __evaluator.risk()\n",
    "    print(__risk)\n",
    "    res = __evaluator.results()\n",
    "    print(__evaluator.queries()[:3])\n",
    "except RuntimeError as ex:\n",
    "    print(f\"Singling out evaluation failed with {ex}. Please re-run this cell.\"\n",
    "          \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "          \"make the evaluation slower.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_cols = [\n",
    "    ['type_employer', 'education', 'hr_per_week', 'capital_loss', 'capital_gain'],\n",
    "    [ 'race', 'sex', 'fnlwgt', 'age', 'country']\n",
    "]\n",
    "\n",
    "__evaluator = evaluators.LinkabilityEvaluator(ori     = __Loader.data\n",
    "                                             ,syn     = __df_syn\n",
    "                                             ,control = __df_control\n",
    "                                             ,n_attacks=2000\n",
    "                                             ,aux_cols=aux_cols,\n",
    "                                             ,n_neighbors=10)\n",
    "\n",
    "__evaluator.evaluate(n_jobs=-2)  # n_jobs follow joblib convention. -1 = all cores, -2 = all execept one\n",
    "print(__evaluator.risk())\n",
    "res = __evaluator.results()\n",
    "print(\"Successs rate of main attack:\", res.attack_rate)\n",
    "print(\"Successs rate of baseline attack:\", res.baseline_rate)\n",
    "print(\"Successs rate of control attack:\", res.control_rate)\n",
    "print(__evaluator.risk(n_neighbors=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ori.columns\n",
    "results = []\n",
    "\n",
    "for secret in columns:\n",
    "    \n",
    "    aux_cols = [col for col in columns if col != secret]\n",
    "    \n",
    "    __evaluator = evaluators.InferenceEvaluator(ori     = __Loader.data\n",
    "                                               ,syn     = __df_syn\n",
    "                                               ,control = __df_control\n",
    "                                               ,aux_cols=aux_cols\n",
    "                                               ,secret=secret\n",
    "                                               ,n_attacks=1000)\n",
    "    __evaluator.evaluate(n_jobs=-2)\n",
    "    results.append((secret, __evaluator.results()))\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "risks = [res[1].risk().value for res in results]\n",
    "columns = [res[0] for res in results]\n",
    "\n",
    "ax.bar(x=columns, height=risks, alpha=0.5, ecolor='black', capsize=10)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "ax.set_ylabel(\"Measured inference risk\")\n",
    "_ = ax.set_xlabel(\"Secret column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 這是已經有檔案的做法 (Unfinished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_adult_SD_SDV = {'CoupulaGAN'      : ['[Adt Income]_[SDV]_[CoupulaGAN]_20231106_113038_Asia_Taipei_10000.csv']\n",
    "                    ,'CTGAN'           : ['[Adt Income]_[SDV]_[CTGAN]_20231106_093702_Asia_Taipei_10000.csv']\n",
    "                    ,'GaussianCoupula' : ['[Adt Income]_[SDV]_[GaussianCoupula]_20231106_093622_Asia_Taipei_10000.csv']\n",
    "                    ,'TVAE'            : ['[Adt Income]_[SDV]_[TVAE]_20231106_105252_Asia_Taipei_10000.csv']\n",
    "                    }\n",
    "dict_filename = {key: {**value ,'SDV': dict_adult_SD_SDV} \n",
    "                 for key, value in dict_filename.items()}\n",
    "\n",
    "\n",
    "\n",
    "for __dataset ,v in dict_filename.items():\n",
    "    __filename = v['params']['filename']\n",
    "    print(f\"Now is {__filename}: {v['raw']} comparision.\")\n",
    "\n",
    "    __df_ori = PETs_Tool.PETs_Loader(os.path.join(folder_raw ,v['raw'])\n",
    "                                    ,v['params']\n",
    "                                    ).data\n",
    "    print(f\"Now is {__filename} original data been load: {v['raw']}.\")\n",
    "\n",
    "    for __library ,__dict_sd in v['SD'].items():\n",
    "        print(f\"Now is {__filename} by library {__library}.\")\n",
    "\n",
    "        for __method ,__list_sd in __dict_sd.items():\n",
    "            print(f\"Now is {__filename} by method {__method} in library {__library}.\")\n",
    "            __list_sd = [__list_sd] if isinstance(__list_sd ,str) else __list_sd\n",
    "            for __filename_sd in __list_sd:\n",
    "                # 20231116, Justyn: 這裡是合成資料有落地\n",
    "                #                   如果必要，可以直接調用 PETs_SD_* 結果的.synthetic_data\n",
    "                __df_syn = PETs_Tool.PETs_Loader(os.path.join(folder_SD ,__filename_sd)\n",
    "                                                ,v['params']\n",
    "                                                ).data\n",
    "                print(f\"Now is {__filename} synthetic data been load: {__filename_sd}.\")\n",
    "\n",
    "                # 20231116, Justyn: refer to\n",
    "                # https://github.com/statice/anonymeter/blob/main/notebooks/anonymeter_example.ipynb\n",
    "                # https://storage.googleapis.com/statice-public/anonymeter-datasets\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
