{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is [Retail] Online Retail.xlsx\n",
      "讀 3*metafile 時間 0.8076 秒\n",
      "現在套件是CTGAN\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.22 GiB for an array with shape (541909, 4070) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\justyn.chen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"C:\\Users\\justyn.chen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\justyn.chen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\justyn.chen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\justyn.chen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ctgan\\data_transformer.py\", line 133, in _transform_discrete\n    return ohe.transform(data).to_numpy()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\justyn.chen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rdt\\transformers\\base.py\", line 55, in wrapper\n    return function(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\justyn.chen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rdt\\transformers\\base.py\", line 424, in transform\n    transformed_data = self._transform(columns_data)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\justyn.chen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rdt\\transformers\\categorical.py\", line 656, in _transform\n    return self._transform_helper(data)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\justyn.chen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rdt\\transformers\\categorical.py\", line 624, in _transform_helper\n    array = (coded == dummies).astype(int)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 8.22 GiB for an array with shape (541909, 4070) and data type int32\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\justyn.chen\\Desktop\\PETs\\Justyn.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/justyn.chen/Desktop/PETs/Justyn.ipynb#W0sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39melif\u001b[39;00m method_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCTGAN\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/justyn.chen/Desktop/PETs/Justyn.ipynb#W0sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m     synthesizer \u001b[39m=\u001b[39m CTGANSynthesizer(metadata_oricast)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/justyn.chen/Desktop/PETs/Justyn.ipynb#W0sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m     synthesizer\u001b[39m.\u001b[39;49mfit(__data_oricast)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/justyn.chen/Desktop/PETs/Justyn.ipynb#W0sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m \u001b[39melif\u001b[39;00m method_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTVAE\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/justyn.chen/Desktop/PETs/Justyn.ipynb#W0sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m     synthesizer \u001b[39m=\u001b[39m TVAESynthesizer(metadata_label_encoding)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sdv\\single_table\\base.py:378\u001b[0m, in \u001b[0;36mBaseSynthesizer.fit\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_random_state_set \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    377\u001b[0m processed_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess(data)\n\u001b[1;32m--> 378\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_processed_data(processed_data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sdv\\single_table\\base.py:361\u001b[0m, in \u001b[0;36mBaseSynthesizer.fit_processed_data\u001b[1;34m(self, processed_data)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit this model to the transformed data.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \n\u001b[0;32m    356\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[39m    processed_data (pandas.DataFrame):\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[39m        The transformed data used to fit the model to.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m processed_data\u001b[39m.\u001b[39mempty:\n\u001b[1;32m--> 361\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(processed_data)\n\u001b[0;32m    363\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fitted \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fitted_date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sdv\\single_table\\ctgan.py:120\u001b[0m, in \u001b[0;36mCTGANSynthesizer._fit\u001b[1;34m(self, processed_data)\u001b[0m\n\u001b[0;32m    118\u001b[0m discrete_columns \u001b[39m=\u001b[39m detect_discrete_columns(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_metadata(), processed_data)\n\u001b[0;32m    119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m CTGAN(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_kwargs)\n\u001b[1;32m--> 120\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mfit(processed_data, discrete_columns\u001b[39m=\u001b[39;49mdiscrete_columns)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ctgan\\synthesizers\\base.py:50\u001b[0m, in \u001b[0;36mrandom_state.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_states \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m         \u001b[39mreturn\u001b[39;00m function(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     52\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m         \u001b[39mwith\u001b[39;00m set_random_states(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_random_state):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ctgan\\synthesizers\\ctgan.py:307\u001b[0m, in \u001b[0;36mCTGAN.fit\u001b[1;34m(self, train_data, discrete_columns, epochs)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer \u001b[39m=\u001b[39m DataTransformer()\n\u001b[0;32m    305\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer\u001b[39m.\u001b[39mfit(train_data, discrete_columns)\n\u001b[1;32m--> 307\u001b[0m train_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformer\u001b[39m.\u001b[39;49mtransform(train_data)\n\u001b[0;32m    309\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_sampler \u001b[39m=\u001b[39m DataSampler(\n\u001b[0;32m    310\u001b[0m     train_data,\n\u001b[0;32m    311\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer\u001b[39m.\u001b[39moutput_info_list,\n\u001b[0;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_frequency)\n\u001b[0;32m    314\u001b[0m data_dim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer\u001b[39m.\u001b[39moutput_dimensions\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ctgan\\data_transformer.py:183\u001b[0m, in \u001b[0;36mDataTransformer.transform\u001b[1;34m(self, raw_data)\u001b[0m\n\u001b[0;32m    178\u001b[0m     column_data_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_synchronous_transform(\n\u001b[0;32m    179\u001b[0m         raw_data,\n\u001b[0;32m    180\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_column_transform_info_list\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     column_data_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parallel_transform(\n\u001b[0;32m    184\u001b[0m         raw_data,\n\u001b[0;32m    185\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_column_transform_info_list\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    188\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mconcatenate(column_data_list, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ctgan\\data_transformer.py:167\u001b[0m, in \u001b[0;36mDataTransformer._parallel_transform\u001b[1;34m(self, raw_data, column_transform_info_list)\u001b[0m\n\u001b[0;32m    164\u001b[0m         process \u001b[39m=\u001b[39m delayed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_discrete)(column_transform_info, data)\n\u001b[0;32m    165\u001b[0m     processes\u001b[39m.\u001b[39mappend(process)\n\u001b[1;32m--> 167\u001b[0m \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)(processes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[39m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[39m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[39m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[39m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_error_fast()\n\u001b[0;32m   1700\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[39m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[39m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[39m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[39m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[39mif\u001b[39;00m error_job \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     error_job\u001b[39m.\u001b[39;49mget_result(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[39m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[39m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[39m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_return_or_raise()\n\u001b[0;32m    738\u001b[0m \u001b[39m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.22 GiB for an array with shape (541909, 4070) and data type int32"
     ]
    }
   ],
   "source": [
    "# reload during dev\n",
    "from importlib import reload\n",
    "import PET_raw_data\n",
    "PET_raw_data = reload(PET_raw_data)\n",
    "\n",
    "\n",
    "\n",
    "dict_load = {\n",
    "            #  '[Adt Income] adult.csv'      : {'describe_params' : {'missing_level' : {'data': {'?'}}}}\n",
    "            # ,'[Census] adult.data'         : {'read_params'     : {'label_encoding' : 'Y'\n",
    "            #                                                       ,'header_exist' : 'N'\n",
    "            #                                                       ,'header'       : ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','income']\n",
    "            #                                                       }\n",
    "            #                                  ,'describe_params' : {'missing_level' : {'data': {'?'}}}\n",
    "            #                                  }\n",
    "            # ,'[NHANES] B.csv'              : {'read_params'     : {'label_encoding' : 'Y'\n",
    "            #                                                       ,'header_exist' : 'N'\n",
    "            #                                                       ,'header'       : ['gen','age','race','edu','mar','bmi','dep','pir','gh','mets','qm','dia']\n",
    "            #                                                       }\n",
    "            #                                  }\n",
    "            # ,\n",
    "             '[Retail] Online Retail.xlsx' : {'read_method'     : 'pandas_xlsx'\n",
    "                                             ,'read_params'     : {'label_encoding' : 'Y'\n",
    "                                                                  ,'sheet_name' : 'Online Retail'\n",
    "                                                                  ,'str_col'    : ['InvoiceNo','StockCode','InvoiceDate','CustomerID']\n",
    "                                                                  }\n",
    "                                             }\n",
    "            ,'[UK-US PF] va_household_ver_1_9_instance_2.csv' : {'read_params' : {'label_encoding' : 'Y'\n",
    "                                                                                 ,'str_col' : ['hid','rlid','admin1','admin2']}}\n",
    "            ,'[UK-US PF] va_person_ver_1_9_instance_2.csv'    : {'read_params' : {'label_encoding' : 'Y'\n",
    "                                                                                 ,'str_col' : ['hid','pid','person_number','sex']}}\n",
    "            }\n",
    "dict_out  = {'[Adt Income] adult.csv'      : \"[Adt Income]\"\n",
    "            ,'[Census] adult.data'         : \"[Census]\"\n",
    "            ,'[NHANES] B.csv'              : \"[NHANES]\"\n",
    "            ,'[Retail] Online Retail.xlsx' : \"[Retail]\"\n",
    "            ,'[UK-US PF] va_household_ver_1_9_instance_2.csv' : \"[UK-US PF] Household\"\n",
    "            ,'[UK-US PF] va_person_ver_1_9_instance_2.csv'    : \"[UK-US PF] Person\"\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "# 231103, Justyn: 如果是跑 VSCode 失敗的話，檢查能否 import torch，不行的話可能需要裝 Microsoft Visual C++ Redistributable：Microsoft 官網下載即可\n",
    "from sdv.single_table import GaussianCopulaSynthesizer ,CTGANSynthesizer ,TVAESynthesizer ,CopulaGANSynthesizer\n",
    "n_sample = 10\n",
    "library_name = 'SDV'\n",
    "\n",
    "\n",
    "__temp = {}\n",
    "for filename ,file_params in dict_load.items():\n",
    "\n",
    "    if filename != '[Retail] Online Retail.xlsx':\n",
    "        continue\n",
    "\n",
    "    file_params_init = {'read_params'     : {'label_encoding' : 'Y'}\n",
    "                       ,'describe'        : 'N'\n",
    "                       ,'describe_params' : {'correlation'   : 'N'\n",
    "                                            ,'collinearity'  : 'N'}\n",
    "                       ,'report'          : 'N'\n",
    "                       ,'report_params'   : {'print_report' : 'N'\n",
    "                                            ,'save_report'  : 'Y'}\n",
    "                       }\n",
    "    file_params_init.update(file_params)\n",
    "    print(f\"Now is {filename}\")\n",
    "    __temp[filename] = PET_raw_data.load_data(f\".\\data\\{filename}\" ,file_params_init)\n",
    "\n",
    "\n",
    "\n",
    "    time_start = time.time()\n",
    "    __data         = __temp[filename].data.copy()\n",
    "    __data_row_num = __data.shape[0]\n",
    "    metadata       = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(__data)\n",
    "    ##\n",
    "    __data_oricast   = __temp[filename].data_oricast.copy()\n",
    "    metadata_oricast = SingleTableMetadata()\n",
    "    metadata_oricast.detect_from_dataframe(__data)\n",
    "    ##\n",
    "    __data_label_encoding   = __temp[filename].data_label_encoding.copy()\n",
    "    metadata_label_encoding = SingleTableMetadata()\n",
    "    metadata_label_encoding.detect_from_dataframe(__data_label_encoding)\n",
    "    print(f\"讀 3*metafile 時間 {round(time.time()-time_start ,4)} 秒\")\n",
    "\n",
    "    for method_name in ['GaussianCoupula'\n",
    "                       ,'CTGAN'\n",
    "                       ,'TVAE'\n",
    "                       ,'CoupulaGAN']:\n",
    "\n",
    "        if filename != '[Retail] Online Retail.xlsx':\n",
    "            continue\n",
    "        elif method_name != 'CTGAN':\n",
    "            continue\n",
    "\n",
    "        exectime = datetime.now().astimezone(pytz.timezone('Asia/Taipei'))\n",
    "        exec_out = f\"{dict_out[filename]}_[{library_name}]_[{method_name}]_{exectime.strftime('%Y%m%d_%H%M%S')}_{exectime.tzinfo.zone.replace('/' ,'_')}\"\n",
    "\n",
    "        print(f\"現在套件是{method_name}\")\n",
    "        time_start = time.time()\n",
    "        if   method_name == 'GaussianCoupula':\n",
    "            synthesizer = GaussianCopulaSynthesizer(metadata)\n",
    "            synthesizer.fit(__data)\n",
    "        elif method_name == 'CTGAN':\n",
    "            synthesizer = CTGANSynthesizer(metadata_oricast)\n",
    "            synthesizer.fit(__data_oricast)\n",
    "        elif method_name == 'TVAE':\n",
    "            synthesizer = TVAESynthesizer(metadata_label_encoding)\n",
    "            synthesizer.fit(__data_label_encoding)\n",
    "        elif method_name == 'CoupulaGAN':\n",
    "            synthesizer = CopulaGANSynthesizer(metadata_label_encoding)\n",
    "            synthesizer.fit(__data_label_encoding)\n",
    "        else:\n",
    "            continue\n",
    "        print(f\"訓練時間 {round(time.time()-time_start ,4)} 秒\")\n",
    "        synthesizer.save(f\".\\model_dpsd\\{exec_out}.pkl\")\n",
    "\n",
    "\n",
    "        time_start = time.time()\n",
    "        for i in range(n_sample):\n",
    "            synthesizer.reset_sampling()\n",
    "            synthetic_data = synthesizer.sample(num_rows   = 10000\n",
    "                                            ,batch_size = 1000\n",
    "                                            )\n",
    "            synthetic_data.to_csv(f\".\\data_dpsd\\{exec_out}_10000.csv\")\n",
    "        print(f\"合成 {n_sample} 次 10K 筆時間 {round(time.time()-time_start ,4)} 秒\")\n",
    "\n",
    "        time_start = time.time()\n",
    "        synthetic_data = synthesizer.sample(num_rows   = __data_row_num\n",
    "                                        ,batch_size = 1000\n",
    "                                        )\n",
    "        synthetic_data.to_csv(f\".\\data_dpsd\\{exec_out}_{__data_row_num}.csv\")\n",
    "        print(f\"合成一次同筆數時間 {round(time.time()-time_start ,4)} 秒\")\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"Done: {exec_out}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
