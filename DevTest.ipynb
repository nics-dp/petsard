{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETs-Experiment')\n",
    "\n",
    "import PETs_Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loader \u001b[39m=\u001b[39m PETs_Experiment\u001b[39m.\u001b[39;49mLoader(filepath \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m[sunset]/data/[Adt Income] adult.csv\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      2\u001b[0m                                ,na_values \u001b[39m=\u001b[39;49m {k : \u001b[39m'\u001b[39;49m\u001b[39m?\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mfor\u001b[39;49;00m k \u001b[39min\u001b[39;49;00m [\u001b[39m'\u001b[39;49m\u001b[39mworkclass\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      3\u001b[0m                                                               ,\u001b[39m'\u001b[39;49m\u001b[39moccupation\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      4\u001b[0m                                                               ,\u001b[39m'\u001b[39;49m\u001b[39mnative-country\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      5\u001b[0m                                                               ]\n\u001b[0;32m      6\u001b[0m                                             }\n\u001b[0;32m      7\u001b[0m                                )\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(loader\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mhead(\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32md:\\Dropbox\\89_其他應用\\GitHub\\PETs-Experiment\\PETs_Experiment\\Loader\\Loader.py:96\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, filepath, header_exist, header_names, sep, sheet_name, colnames_discrete, colnames_datetime, dtype, na_values)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m####### ####### ####### ####### ####### ###### ######\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[39m####### [TODO] 我還在思考這裡要怎麼直接接收 pd.dateframe 的 dtype\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m df_cast_check        \u001b[39m###### ######\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m dtype\u001b[39m.\u001b[39mupdate(df_cast_check(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata ,dtype))  \u001b[39m######\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m dtype                      \u001b[39m###### ######\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m####### ####### ####### ####### ####### ###### ######\u001b[39;00m\n",
      "File \u001b[1;32md:\\Dropbox\\89_其他應用\\GitHub\\PETs-Experiment\\PETs_Experiment\\util\\df_cast_check.py:121\u001b[0m, in \u001b[0;36mdf_cast_check\u001b[1;34m(df_data, dict_dtype)\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdf_cast_check: Unsupported force dtype, now is \u001b[39m\u001b[39m{\u001b[39;00m_force_type\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m                                        ,\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWe only support category/date/datetime/int-/float-.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m                                        ]))\n\u001b[0;32m    118\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m         \u001b[39m####### ####### ####### ####### ####### ######\u001b[39;00m\n\u001b[0;32m    120\u001b[0m         \u001b[39m####### Otherwise determine by extreme value.\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m         dict_dtype[_col_name] \u001b[39m=\u001b[39m __col_cast_check(_col_data)\n\u001b[0;32m    123\u001b[0m \u001b[39mreturn\u001b[39;00m dict_dtype\n",
      "File \u001b[1;32md:\\Dropbox\\89_其他應用\\GitHub\\PETs-Experiment\\PETs_Experiment\\util\\df_cast_check.py:81\u001b[0m, in \u001b[0;36mdf_cast_check.<locals>.__col_cast_check\u001b[1;34m(col_data)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m is_string_dtype ,is_numeric_dtype\n\u001b[0;32m     80\u001b[0m \u001b[39mif\u001b[39;00m is_string_dtype(col_data):\n\u001b[1;32m---> 81\u001b[0m     \u001b[39mreturn\u001b[39;00m __col_cast_check_string( col_data)\n\u001b[0;32m     82\u001b[0m \u001b[39melif\u001b[39;00m is_numeric_dtype(col_data):\n\u001b[0;32m     83\u001b[0m     \u001b[39mreturn\u001b[39;00m __col_cast_check_numeric(col_data)\n",
      "File \u001b[1;32md:\\Dropbox\\89_其他應用\\GitHub\\PETs-Experiment\\PETs_Experiment\\util\\df_cast_check.py:25\u001b[0m, in \u001b[0;36mdf_cast_check.<locals>.__col_cast_check_string\u001b[1;34m(col_data)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m _value \u001b[39min\u001b[39;00m col_data\u001b[39m.\u001b[39mdropna():\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         _parsed_col_data \u001b[39m=\u001b[39m parse(_value)\n\u001b[0;32m     26\u001b[0m         \u001b[39mif\u001b[39;00m  _parsed_col_data\u001b[39m.\u001b[39mhour   \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\\\n\u001b[0;32m     27\u001b[0m         \u001b[39mand\u001b[39;00m _parsed_col_data\u001b[39m.\u001b[39mminute \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\\\n\u001b[0;32m     28\u001b[0m         \u001b[39mand\u001b[39;00m _parsed_col_data\u001b[39m.\u001b[39msecond \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     29\u001b[0m             _cnt_datetime \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[39mreturn\u001b[39;00m parser(parserinfo)\u001b[39m.\u001b[39mparse(timestr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1367\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     \u001b[39mreturn\u001b[39;00m DEFAULTPARSER\u001b[39m.\u001b[39mparse(timestr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:640\u001b[0m, in \u001b[0;36mparser.parse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m default \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    637\u001b[0m     default \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mreplace(hour\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, minute\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m    638\u001b[0m                                               second\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, microsecond\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m--> 640\u001b[0m res, skipped_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse(timestr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    642\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m ParserError(\u001b[39m\"\u001b[39m\u001b[39mUnknown string format: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, timestr)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:719\u001b[0m, in \u001b[0;36mparser._parse\u001b[1;34m(self, timestr, dayfirst, yearfirst, fuzzy, fuzzy_with_tokens)\u001b[0m\n\u001b[0;32m    716\u001b[0m     yearfirst \u001b[39m=\u001b[39m info\u001b[39m.\u001b[39myearfirst\n\u001b[0;32m    718\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result()\n\u001b[1;32m--> 719\u001b[0m l \u001b[39m=\u001b[39m _timelex\u001b[39m.\u001b[39;49msplit(timestr)         \u001b[39m# Splits the timestr into tokens\u001b[39;00m\n\u001b[0;32m    721\u001b[0m skipped_idxs \u001b[39m=\u001b[39m []\n\u001b[0;32m    723\u001b[0m \u001b[39m# year/month/day list\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:201\u001b[0m, in \u001b[0;36m_timelex.split\u001b[1;34m(cls, s)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit\u001b[39m(\u001b[39mcls\u001b[39m, s):\n\u001b[1;32m--> 201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mcls\u001b[39;49m(s))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:190\u001b[0m, in \u001b[0;36m_timelex.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 190\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_token()\n\u001b[0;32m    191\u001b[0m     \u001b[39mif\u001b[39;00m token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:98\u001b[0m, in \u001b[0;36m_timelex.get_token\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m token \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     96\u001b[0m state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meof:\n\u001b[0;32m     99\u001b[0m     \u001b[39m# We only realize that we've reached the end of a token when we\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[39m# find a character that's not part of the current token - since\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[39m# that character may be part of the next token, it's stored in the\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[39m# charstack.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcharstack:\n\u001b[0;32m    104\u001b[0m         nextchar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcharstack\u001b[39m.\u001b[39mpop(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loader = PETs_Experiment.Loader(filepath = '[sunset]/data/[Adt Income] adult.csv'\n",
    "                               ,na_values = {k : '?' for k in ['workclass'\n",
    "                                                              ,'occupation'\n",
    "                                                              ,'native-country'\n",
    "                                                              ]\n",
    "                                            }\n",
    "                               )\n",
    "print(loader.data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor - Missingist (Drop): Dropped 3620 rows.\n",
      "Preprocessor - Outlierist (IQR): Dropped  1331 rows on fnlwgt         . Kept [-63418.375, 418732.625] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  3790 rows on capital-gain   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   269 rows on age            . Kept [-0.5, 75.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  2140 rows on capital-loss   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   294 rows on educational-num. Kept [3.0, 19.0] only.\n",
      "Preprocessor - Outlierist (IQR): Totally Dropped  7569 in 45222 rows.\n",
      "Preprocessor - Encoder (Label): Column occupation      been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column race            been labelized from 0 to  4.\n",
      "Preprocessor - Encoder (Label): Column native-country  been labelized from 0 to 39.\n",
      "Preprocessor - Encoder (Label): Column income          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column education       been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column relationship    been labelized from 0 to  5.\n",
      "Preprocessor - Encoder (Label): Column marital-status  been labelized from 0 to  6.\n",
      "Preprocessor - Encoder (Label): Column gender          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column workclass       been labelized from 0 to  6.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0   25          2  226802          1                7               4   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0           6             3     2       1             0             0   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0              40              37       0  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'occupation': LabelEncoder(), 'race': LabelEncoder(), 'native-country': LabelEncoder(), 'income': LabelEncoder(), 'education': LabelEncoder(), 'relationship': LabelEncoder(), 'marital-status': LabelEncoder(), 'gender': LabelEncoder(), 'workclass': LabelEncoder()}\n"
     ]
    }
   ],
   "source": [
    "preproc = PETs_Experiment.Preprocessor(\n",
    "     data = loader.data\n",
    "    ,missing=True\n",
    "        ,missing_method  = 'drop'\n",
    "        ,missing_columns = None\n",
    "    ,outlier=True\n",
    "        ,outlier_method  = 'IQR'\n",
    "        ,outlier_columns = {'ignore': ['hours-per-week']}\n",
    "    ,encoding=True\n",
    "        ,encoding_method  = 'Label'\n",
    "        ,encoding_columns = None\n",
    "    ,scaling=False\n",
    ")\n",
    "print('\\n\\n\\n')\n",
    "print(preproc.data.head(1))\n",
    "print('\\n\\n\\n')\n",
    "print(preproc.encoder)\n",
    "\n",
    "\n",
    "        # ,scaling_method  = 'Standard'\n",
    "        # ,scaling_columns = None\n",
    "# print('\\n\\n\\n')\n",
    "# print(Preprocessor.scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.0249 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula spent 16.747 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCoupula # 37653 rows (same as raw) in 1.6151 sec.\n",
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0   55          1   52595         11                8               2   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0           8             0     4       1             0             0   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0              54              32       0  \n"
     ]
    }
   ],
   "source": [
    "synthesizer = PETs_Experiment.Synthesizer(data = preproc.data\n",
    "                                         ,synthesizing_method = 'sdv-singletable-gaussiancoupula'\n",
    "                                         )\n",
    "synthesizer.fit_sample()\n",
    "print(synthesizer.data_syn.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  workclass  fnlwgt education  educational-num      marital-status  \\\n",
      "0   55  Local-gov   52595   Masters                8  Married-civ-spouse   \n",
      "\n",
      "        occupation relationship   race gender  capital-gain  capital-loss  \\\n",
      "0  Priv-house-serv      Husband  White   Male             0             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              54       Scotland  <=50K  \n"
     ]
    }
   ],
   "source": [
    "postproc = PETs_Experiment.Postprocessor(data = synthesizer.data_syn\n",
    "                                        ,encoder = getattr(Preprocessor ,'encoder' ,None)\n",
    "                                        ,scaler  = getattr(Preprocessor ,'scaler'  ,None)\n",
    "                                        )\n",
    "print(postproc.data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor - Missingist (Drop): Dropped 3620 rows.\n",
      "Preprocessor - Outlierist (IQR): Dropped   269 rows on age            . Kept [-0.5, 75.5] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  2140 rows on capital-loss   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  1331 rows on fnlwgt         . Kept [-63418.375, 418732.625] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped  3790 rows on capital-gain   . Kept [0.0, 0.0] only.\n",
      "Preprocessor - Outlierist (IQR): Dropped   294 rows on educational-num. Kept [3.0, 19.0] only.\n",
      "Preprocessor - Outlierist (IQR): Totally Dropped  7569 in 45222 rows.\n",
      "Preprocessor - Encoder (Label): Column race            been labelized from 0 to  4.\n",
      "Preprocessor - Encoder (Label): Column marital-status  been labelized from 0 to  6.\n",
      "Preprocessor - Encoder (Label): Column occupation      been labelized from 0 to 13.\n",
      "Preprocessor - Encoder (Label): Column relationship    been labelized from 0 to  5.\n",
      "Preprocessor - Encoder (Label): Column workclass       been labelized from 0 to  6.\n",
      "Preprocessor - Encoder (Label): Column native-country  been labelized from 0 to 39.\n",
      "Preprocessor - Encoder (Label): Column income          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column gender          been labelized from 0 to  1.\n",
      "Preprocessor - Encoder (Label): Column education       been labelized from 0 to 13.\n",
      "Preprocessor - Scaler (Standard): Column fnlwgt been standardized.\n",
      "Synthesizer (SDV - SingleTable): Metafile loading time: 0.023 sec.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula.\n",
      "Synthesizer (SDV - SingleTable): Fitting  GaussianCoupula spent 16.2035 sec.\n",
      "Synthesizer (SDV - SingleTable): Sampling GaussianCoupula # 37653 rows (same as raw) in 1.4614 sec.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('D:\\\\Dropbox\\\\89_其他應用\\\\GitHub\\\\PETs-Experiment')\n",
    "\n",
    "import PETs_Experiment\n",
    "\n",
    "para_Executor = {\n",
    "     'Loader_filepath'  : '[sunset]/data/[Adt Income] adult.csv'\n",
    "    ,'Loader_na_values' : {k : '?' for k in ['workclass' ,'occupation' ,'native-country']}\n",
    "    ,'Preprocessor_missing_method'  : 'drop'\n",
    "    ,'Preprocessor_outlier_method'  : 'IQR'\n",
    "    ,'Preprocessor_outlier_columns' : {'ignore': ['hours-per-week']}\n",
    "    ,'Preprocessor_encoding_method' : 'Label'\n",
    "    ,'Preprocessor_scaling'         : True\n",
    "    ,'Preprocessor_scaling_method'  : 'Standard'\n",
    "    ,'Preprocessor_scaling_columns' : {'focus' : 'fnlwgt'}\n",
    "    ,'Synthesizer_synthesizing_method' : 'sdv-singletable-gaussiancoupula'\n",
    "}\n",
    "\n",
    "executor = PETs_Experiment.Executor(**para_Executor)\n",
    "executor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " executor.synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'key of type tuple not found and not a MultiIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(shape\u001b[39m=\u001b[39m(\u001b[39mlen\u001b[39m(executor\u001b[39m.\u001b[39msynthesizer\u001b[39m.\u001b[39mdata_syn[\u001b[39m'\u001b[39m\u001b[39mfnlwgt\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39m12\u001b[39m) )\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(test)\n\u001b[1;32m----> 4\u001b[0m test[:,\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m executor\u001b[39m.\u001b[39;49msynthesizer\u001b[39m.\u001b[39;49mdata_syn[\u001b[39m'\u001b[39;49m\u001b[39mfnlwgt\u001b[39;49m\u001b[39m'\u001b[39;49m][:,\u001b[39m0\u001b[39;49m] \u001b[39m# .values\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# executor.preprocessor.scaler['fnlwgt'].inverse_transform(\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[39m#     test\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m# )\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1072\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[0;32m   1070\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_rows_with_mask(key)\n\u001b[1;32m-> 1072\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_with(key)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1082\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1077\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   1078\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIndexing a Series with DataFrame is not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1079\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupported, use the appropriate DataFrame column\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1080\u001b[0m     )\n\u001b[0;32m   1081\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m-> 1082\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_values_tuple(key)\n\u001b[0;32m   1084\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key):\n\u001b[0;32m   1085\u001b[0m     \u001b[39m# e.g. scalars that aren't recognized by lib.is_scalar, GH#32684\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc[key]\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1126\u001b[0m, in \u001b[0;36mSeries._get_values_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m   1125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m-> 1126\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mkey of type tuple not found and not a MultiIndex\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1128\u001b[0m \u001b[39m# If key is contained, would have returned by now\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m indexer, new_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_loc_level(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'key of type tuple not found and not a MultiIndex'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test = np.zeros(shape=(len(executor.synthesizer.data_syn['fnlwgt']), 12) )\n",
    "print(test)\n",
    "test[:,0] = executor.synthesizer.data_syn['fnlwgt'][:,0] # .values\n",
    "\n",
    "\n",
    "# executor.preprocessor.scaler['fnlwgt'].inverse_transform(\n",
    "\n",
    "#     test\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "37648    0.0\n",
       "37649    0.0\n",
       "37650    0.0\n",
       "37651    0.0\n",
       "37652    0.0\n",
       "Name: fnlwgt, Length: 37653, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor.synthesizer.data_syn['fnlwgt']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
