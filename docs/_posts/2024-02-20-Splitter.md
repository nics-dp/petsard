The `splitter` module is responsible for splitting data for experimental purpose. It is used for `anonymeter` type `Evaluator`, which requires splitting the data into two parts: control and experiment datasets.

`splitter` 模組可切分資料，用於進行實驗。此模組用於 `anonymeter` 類的 `Evaluator`，因為其要求將資料分成兩部分：控制組與實驗組。

```python
from PETsARD.loader.splitter import Splitter

splitter = Splitter(data, train_split_ratio=0.8, random_state=42)
```

# `Splitter`

To use `Splitter`, you should provide a `pd.DataFrame` for initialisation. You can set different split methods as your requirements.

使用 `Splitter` 時須提供 `pd.DataFrame`，您可以依照需求自訂切分方法。


```python
splitter = Splitter(
    data,
    num_samples=1,
    train_split_ratio=0.8,
    random_state=None
)
```

**Parameters**

`data` (`pd.DataFrame`): The data to be split. 欲切分的資料集。

`num_samples` (`int`, default=`1`): Number of datasets will be generated. For example, if `num_samples=5`, there are 5 split datasets, and each of them contain control and experiment datasets. 生成的資料集數目。例如 `num_samples=5` 代表會產生 5 個切分資料集，每個資料集都包含控制組與實驗組的資料集。
        
`train_split_ratio` (`float`, default=`0.8`): The proportion of the dataset to include in the experiment dataset. Hence, the proportion of the dataset to include in the control dataset is $1-$`train_split_ratio`. 實驗組資料集的資料佔比。因此控制組資料集的資料佔比為 $1-$`train_split_ratio`。

`random_state` (`int`, default=`None`, optional): Controls the random sampling for reproducible output. 控制隨機切分過程，以便未來產生出相同切分結果的資料集。

## `self.data`

The split results are stored in `self.data` in the form of nested `dict`. The structure is shown below:

```python
{
    sample_num: {
        'train': train_df,
        'validation': validation_df
    }, ...
}
```

The key `sample_num` corresponds to the parameter `num_samples` during initialisation. For instance, if `num_samples=5`, the `self.data` will contain 5 elements with `sample_num` from `1` to `5`. Within each element, the value is a `dict` with two keys: `'train'` and `'validation'`, representing the experiment and control datasets, respectively. Each of these keys corresponds to a `pd.DataFrame`, which is the split data.