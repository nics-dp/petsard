The `Splitter` module is responsible for splitting data for experimental purpose. This module is for `anonymeter` type `Evaluator`, which requires splitting the data into two parts: control and experiment datasets. However, it can be used for other experimental requirements as well.

`Splitter` 模組可切分資料，用於進行實驗。開發動機是由於 `anonymeter` 類的 `Evaluator` 要求將資料分成兩部分：控制組與實驗組。但亦可用於其他實驗需求。


```Python
from PETsARD import Splitter

split = Splitter(
    num_samples=5,
    train_split_ratio=0.8
)
split.split(data=load.data)
print(split.data[1]['train'].head(1))
print(split.data[1]['validation'].head(1))
```


# `Splitter`

You can set different split methods as your requirements.

您可以依照需求自訂切分方法。


```Python
split = Splitter(
    num_samples=5,
    train_split_ratio=0.8,
    random_state=None
)
```


**Parameters**


`method` (`str`, default=`None`, optional): Supports loading existing split data, only accepting 'custom_data'. 支援讀取已存在的分割數據，僅接受 'custom_data'。

`num_samples` (`int`, default=`1`, optional): Number of datasets will be generated. For example, if `num_samples=5`, there are 5 split datasets, and each of them contain control and experiment datasets. 生成的資料集數目。例如 `num_samples=5` 代表會產生 5 個切分資料集，每個資料集都包含控制組與實驗組的資料集。

`train_split_ratio` (`float`, default=`0.8`, optional): The proportion of the dataset to include in the experiment dataset. Hence, the proportion of the dataset to include in the control dataset is 1-`train_split_ratio`. 實驗組資料集的資料佔比。因此控制組資料集的資料佔比為 1-`train_split_ratio`。

`random_state` (`int`, default=`None`, optional): Controls the random sampling for reproducible output. 控制隨機切分過程，以便未來產生出相同切分結果的資料集。


## `split()`


```Python
split.split(data=load.data)
```

When using `split()` without setting `method` to `'custom_data'`, it is required to provide a `pd.DataFrame`. Perform index bootstrapping and split the data into train and validation sets using the generated index samples.

在並未將 `method` 設定為 `'custom_data'` 的情況下使用 `split()` 時，必須提供 `pd.DataFrame`。利用索引來進行拔靴法以生成多份資料集，並將資料集切分成訓練及驗證資料集。


**Parameters**


`data` (`pd.DataFrame`): The data to be split. 欲切分的資料集。

`exclude_index` (`List[int]`): The exist indeces to be excluded during the sampling process. 在抽樣過程中欲排除的索引值。


## `self.config`

The configuration of `Splitter` module:

切分模組的參數：

- For standard usage, it contains `num_samples`, `train_split_ratio`, `random_state`. 在標準使用情況下，它包括 `num_samples`（樣本數量）、`train_split_ratio`（訓練集分割比例）與 `random_state`（隨機狀態）。
- When the `method` is set to `'custom_data'`, it encompasses `method`, `filepath`, and the configuration of `Loader`. 當 `method` 設為 `'custom_data'` 時，它包含 `method`（方法）、`filepath`（檔案路徑）以及其他 `Loader` 的配置。


## `self.data`


The split results are stored in `self.data` in the form of nested `dict`. The structure is shown below:

切分結果會以巢狀 `dict` 的形式存於 `self.data`。其結構如下：


```Python
{
    sample_num: {
        'train': train_df,
        'validation': validation_df
    }, ...
}
```


- The key `sample_num` corresponds to the parameter `num_samples` during initialisation. For instance, if `num_samples=5`, the `self.data` will contain 5 elements with `sample_num` from `1` to `5`.
    - Noted that `sample_num` starts from `1` for clarity and ease of understanding.
- Within each element, the value is a `dict` with two keys: `'train'` and `'validation'`, representing the experiment and control datasets, respectively. Each of these keys corresponds to a `pd.DataFrame`, which is the split data.

- 其中 `sample_num` 對應到初始化過程中的 `num_samples` 參數。例如當 `num_samples=5`，`self.data` 內會含有 5 個元素，其 `sample_num` 為 1 到 5。
    - 需要注意的是，`sample_num` 從 `1` 開始計數，以方便理解。
- 在每個元素中，其值皆為一個 `dict`，包含兩個鍵：`'train'`、`'validation'`，前者對應到實驗組資料集，後者對應到控制組資料集。其內部皆存放一個 `pd.DataFrame`，為切分後的資料集。