The `splitter` module is responsible for splitting data for experimental purpose. This module is for `anonymeter` type `Evaluator`, which requires splitting the data into two parts: control and experiment datasets. However, it can be used for other experimental requirements as well.

`splitter` 模組可切分資料，用於進行實驗。開發動機是由於 `anonymeter` 類的 `Evaluator` 要求將資料分成兩部分：控制組與實驗組。但亦可用於其他實驗需求。

```python
from PETsARD.loader import Splitter

split = Splitter(
    num_samples=30,
    train_split_ratio=0.1
)
split.split(data=load.data)
```

# `Splitter`

To use `Splitter`, you should provide a `pd.DataFrame` for initialisation. You can set different split methods as your requirements.

使用 `Splitter` 時須提供 `pd.DataFrame`，您可以依照需求自訂切分方法。


```python
split = Splitter(
    num_samples=1,
    train_split_ratio=0.8,
    random_state=None
)
```

**Parameters**

`num_samples` (`int`, default=`1`): Number of datasets will be generated. For example, if `num_samples=5`, there are 5 split datasets, and each of them contain control and experiment datasets. 生成的資料集數目。例如 `num_samples=5` 代表會產生 5 個切分資料集，每個資料集都包含控制組與實驗組的資料集。
        
`train_split_ratio` (`float`, default=`0.8`): The proportion of the dataset to include in the experiment dataset. Hence, the proportion of the dataset to include in the control dataset is $1-$`train_split_ratio`. 實驗組資料集的資料佔比。因此控制組資料集的資料佔比為 $1-$`train_split_ratio`。

`random_state` (`int`, default=`None`, optional): Controls the random sampling for reproducible output. 控制隨機切分過程，以便未來產生出相同切分結果的資料集。

## `split()`

Perform index bootstrapping and split the data into train and validation sets using the generated index samples.

利用索引來進行拔靴法以生成多份資料集，並將資料集切分成訓練及驗證資料集。

**Parameters**

`data` (`pd.DataFrame`): The data to be split. 欲切分的資料集。

`exclude_index` (`List[int]`): The exist indeces to be excluded during the sampling process. 在抽樣過程中欲排除的索引值。

            

## `self.data`

The split results are stored in `self.data` in the form of nested `dict`. The structure is shown below:

切分結果會以巢狀 `dict` 的形式存於 `self.data`。其結構如下：

```python
{
    sample_num: {
        'train': train_df,
        'validation': validation_df
    }, ...
}
```

The key `sample_num` corresponds to the parameter `num_samples` during initialisation. For instance, if `num_samples=5`, the `self.data` will contain 5 elements with `sample_num` from `1` to `5`. Within each element, the value is a `dict` with two keys: `'train'` and `'validation'`, representing the experiment and control datasets, respectively. Each of these keys corresponds to a `pd.DataFrame`, which is the split data. Noted that `sample_num` starts from `1` for clarity and ease of understanding.

其中 `sample_num` 對應到初始化過程中的 `num_samples` 參數。例如當 `num_samples=5`，`self.data` 內會含有 5 個元素，其 `sample_num` 為 1 到 5。在每個元素中，其值皆為一個 `dict`，包含兩個鍵：`'train'`、`'validation'`，前者對應到實驗組資料集，後者對應到控制組資料集。其內部皆存放一個 `pd.DataFrame`，為切分後的資料集。需要注意的是，`sample_num` 從 `1` 開始計數，以方便理解。