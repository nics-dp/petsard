<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://localhost:4000/PETsARD-Gitbook/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/PETsARD-Gitbook/" rel="alternate" type="text/html" /><updated>2024-02-19T15:45:54+08:00</updated><id>http://localhost:4000/PETsARD-Gitbook/feed.xml</id><title type="html">PETsARD - Gitbook</title><subtitle>Build PETsARD Gitbook site with Jekyll Gitbook.
</subtitle><author><name>NICS - PETs</name></author><entry><title type="html">Benchmark datasets</title><link href="http://localhost:4000/PETsARD-Gitbook/Benchmark-datasets.html" rel="alternate" type="text/html" title="Benchmark datasets" /><published>2024-01-24T00:00:00+08:00</published><updated>2024-01-24T00:00:00+08:00</updated><id>http://localhost:4000/PETsARD-Gitbook/Benchmark%20datasets</id><content type="html" xml:base="http://localhost:4000/PETsARD-Gitbook/Benchmark-datasets.html"><![CDATA[<h1 id="benchmark-datasets">Benchmark datasets</h1>

<p><strong>Benchmark datasets</strong> is an extended feature of the <code class="language-plaintext highlighter-rouge">Loader</code> module in <code class="language-plaintext highlighter-rouge">PETsARD</code> (<code class="language-plaintext highlighter-rouge">Benchmarker</code>), providing users with convenient and reliable example data for easier algorithm applicability analysit or Privacy-enhancement evaluating. Therefore, this document will focus on introducing various datasets. For details on how to use <code class="language-plaintext highlighter-rouge">Loader</code>, please refer to the <code class="language-plaintext highlighter-rouge">Loader</code> documentation.</p>

<p>Using benchmark datasets is straightforward. You only need to place the corresponding <strong>“Benchmark name”</strong> label for each dataset in the <code class="language-plaintext highlighter-rouge">filepath</code> parameter of <code class="language-plaintext highlighter-rouge">Loader</code> in the format <code class="language-plaintext highlighter-rouge">benchmark://{Benchmark name}</code> (case-insensitive). <code class="language-plaintext highlighter-rouge">PETsARD</code> will then download the corresponding dataset and load it into <code class="language-plaintext highlighter-rouge">Loader.data</code>, allowing you to customize the dataset’s <code class="language-plaintext highlighter-rouge">metadata</code> according to other Loader parameters. Here is an example of calling the “adult” dataset:</p>

<p><strong>基準資料集</strong> (<strong>Benchmark datasets</strong>) 是 <code class="language-plaintext highlighter-rouge">PETsARD</code> 的 <code class="language-plaintext highlighter-rouge">Loader</code> 模組的延伸功能 (<code class="language-plaintext highlighter-rouge">Benchmarker</code>)，提供使用者方便呼叫、且可靠的範例資料，讓後續的演算法適用性分析或隱私強化驗測都更為方便。因此，本文將著重在各資料集的介紹上，關於 <code class="language-plaintext highlighter-rouge">Loader</code> 的使用方式詳見 <code class="language-plaintext highlighter-rouge">Loader</code> 文檔。</p>

<p>基準資料集的使用非常簡單，你只要將各資料集對應的 <strong>“Benchmark name”</strong> 標籤，以 <code class="language-plaintext highlighter-rouge">benchmark://{Benchmark name}</code> 的形式放到 <code class="language-plaintext highlighter-rouge">Loader</code> 的 <code class="language-plaintext highlighter-rouge">filepath</code> 參數中（大小寫不限），<code class="language-plaintext highlighter-rouge">PETsARD</code> 便會將對應的資料集下載好，並遵照 <code class="language-plaintext highlighter-rouge">Loader</code> 的功能加載在 <code class="language-plaintext highlighter-rouge">Loader.data</code>，而你仍可以按照 <code class="language-plaintext highlighter-rouge">Loader</code> 的其他參數去自定義資料集的 <code class="language-plaintext highlighter-rouge">metadata</code>。以下是呼叫 “adult” 資料集的例子：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loader</span> <span class="o">=</span> <span class="n">PETsARD</span><span class="p">.</span><span class="n">Loader</span><span class="p">(</span>
    <span class="n">filepath</span><span class="o">=</span><span class="s">'benchmark://adult'</span><span class="p">,</span>
    <span class="n">na_values</span><span class="o">=</span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="s">'?'</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="s">'workclass'</span><span class="p">,</span>
        <span class="s">'occupation'</span><span class="p">,</span>
        <span class="s">'native-country'</span>
    <span class="p">]}</span>
<span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">loader</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="data-lists">data lists</h2>

<ul>
  <li><strong>Name</strong> <code class="language-plaintext highlighter-rouge">benchmark://{Benchmark}</code>: The labels for benchmark datasets, used as input, are case-insensitive. 基準資料集的標籤，用於輸入，大小寫不限。</li>
  <li><strong>Filename</strong> ( <code class="language-plaintext highlighter-rouge">./benchmark/{Benchmark filename}</code>): The actual file will be stored locally and read with the filename. 實際會存到本地、並讀取資料的檔名。</li>
  <li><strong>Access</strong>: Public or Private. 公開或私有。</li>
  <li><strong>Columns</strong>: Columns number. 欄位數。</li>
  <li><strong>Rows</strong>: Rows number. 行數。</li>
  <li><strong>File size</strong>: File size. 檔案大小。</li>
  <li><strong>License</strong>: License of datasets. 資料集的授權。</li>
  <li><strong>Hash</strong>: Top 6 digits of Hash values. 哈希值的前六位。</li>
</ul>

<!-- This <div> here is special function for sighingnow/jekyll-gitbook -->
<div class="table-wrapper">

  <table>
    <thead>
      <tr>
        <th style="text-align: center">Name</th>
        <th style="text-align: center">Filename</th>
        <th style="text-align: center">Access</th>
        <th style="text-align: center">Columns</th>
        <th style="text-align: center">Rows</th>
        <th style="text-align: center">File size</th>
        <th style="text-align: center">License</th>
        <th style="text-align: center">Hash</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: center">adult</td>
        <td style="text-align: center">adult.csv</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">15</td>
        <td style="text-align: center">48,842</td>
        <td style="text-align: center">5 MB</td>
        <td style="text-align: center">CC BY 4.0</td>
        <td style="text-align: center"><code class="language-plaintext highlighter-rouge">1f13ee</code></td>
      </tr>
      <tr>
        <td style="text-align: center">alarm</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
      </tr>
      <tr>
        <td style="text-align: center">car_insurance</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
      </tr>
      <tr>
        <td style="text-align: center">coil2000</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
      </tr>
      <tr>
        <td style="text-align: center">covtype</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">CC BY-NC-SA 4.0</td>
        <td style="text-align: center">TODO</td>
      </tr>
      <tr>
        <td style="text-align: center">ds_salaries</td>
        <td style="text-align: center">ds_salaries.csv</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">11</td>
        <td style="text-align: center">607</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">CC0</td>
        <td style="text-align: center">TODO</td>
      </tr>
      <tr>
        <td style="text-align: center">expedia_hotel_logs</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
      </tr>
      <tr>
        <td style="text-align: center">intrusion</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
      </tr>
      <tr>
        <td style="text-align: center">nhanes_diabetes</td>
        <td style="text-align: center">B.csv</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">12</td>
        <td style="text-align: center">4,190</td>
        <td style="text-align: center">&lt;1 MB</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
      </tr>
      <tr>
        <td style="text-align: center">smoking_driking</td>
        <td style="text-align: center">smoking_driking_dataset_Ver01.csv</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">24</td>
        <td style="text-align: center">991,346</td>
        <td style="text-align: center">104 MB</td>
        <td style="text-align: center">CC BY-NC-SA 4.0</td>
        <td style="text-align: center">TODO</td>
      </tr>
      <tr>
        <td style="text-align: center">uk_us_pf_household</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">3,094,494</td>
        <td style="text-align: center">167 MB</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
      </tr>
      <tr>
        <td style="text-align: center">uk_us_pf_person</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">7,688,060</td>
        <td style="text-align: center">83 MB</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
      </tr>
      <tr>
        <td style="text-align: center">uk_us_pf_prop_net</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">Public</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">166,971,542</td>
        <td style="text-align: center">6,117 MB</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
      </tr>
      <tr>
        <td style="text-align: center">us_census_1940</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">Private</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">TODO</td>
        <td style="text-align: center">Restricted</td>
        <td style="text-align: center">TODO</td>
      </tr>
    </tbody>
  </table>

</div>

<h3 id="adult"><strong>adult</strong></h3>

<ul>
  <li>Name: <strong>Adult</strong></li>
  <li>Alias: <strong>Adult income</strong>, <strong>Census Income</strong></li>
  <li>Subject Area: <strong>Social Science</strong></li>
  <li>Precision: 1 Person 1 records</li>
  <li>Columns: 15
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: 0</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: “?”</li>
    </ul>
  </li>
  <li>Hash: <code class="language-plaintext highlighter-rouge">1f13ee2bf9d7c66098429281ab91fa1b51cbabd3b805cc365b3c6b44491ea2c0</code></li>
</ul>

<p>Filtered extraction from 1994 US Census.</p>

<p>來自 1994 年美國人口普查的過濾資料。</p>

<pre><code class="language-Python">loader = PETsARD.Loader(
    filepath='benchmark://adult',
    na_values={k: '?' for k in [
        'workclass',
        'occupation',
        'native-country'
    ]}
)
print(loader.data.head(1))
</code></pre>

<p>https://archive.ics.uci.edu/dataset/2/adult
https://archive.ics.uci.edu/dataset/20/census+income
https://www.kaggle.com/datasets/wenruliu/adult-income-dataset</p>

<h3 id="alarm"><strong>alarm</strong></h3>

<ul>
  <li>Name: <strong>A Logical Alarm Reduction Mechanism (ALARM) monitoring system (synthetic) data set</strong></li>
  <li>Alias:</li>
  <li>Subject Area: <strong>Health and Medicine</strong></li>
  <li>Precision: 1 House 1 records</li>
  <li>Columns: TODO
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>https://www.bnlearn.com/documentation/man/alarm.html</p>

<h3 id="car_insurance"><strong>car_insurance</strong></h3>

<ul>
  <li>Name: <strong>Insurance evaluation network (synthetic) data set</strong></li>
  <li>Alias: <strong>insurance</strong></li>
  <li>Subject Area: <strong>Business</strong></li>
  <li>Precision: 1 Person 1 records</li>
  <li>Columns: TODO
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>The naming as “car_insurance” is because the name “insurance” may be confused with many datasets provided by insurance companies on Kaggle. This is just a temporary name.</p>

<p>命名為 “car_insurance” 是因為 “insurance” 這個名稱可能會跟許多 Kaggle 上保險公司提供的資料集混淆。這只是暫時的命名。</p>

<h3 id="coil2000"><strong>coil2000</strong></h3>

<ul>
  <li>Name: <strong>Insurance Company Benchmark (COIL 2000)</strong></li>
  <li>Alias:</li>
  <li>Subject Area: <strong>Social Science</strong></li>
  <li>Precision: 1 Person 1 records</li>
  <li>Columns: 86
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>The caravan insurance dataset from the Netherlands, used for the Computational Intelligence and Learning (CoIL) Challenge 2000 in Europe.</p>

<p>荷蘭的房車保險資料集，用於歐洲計算智能和學習（CoIL）挑戰賽 2000。</p>

<p>https://archive.ics.uci.edu/dataset/125/insurance+company+benchmark+coil+2000</p>

<h3 id="covtype"><strong>covtype</strong></h3>

<ul>
  <li>Name: <strong>Forest cover types datasets</strong></li>
  <li>Alias:</li>
  <li>Subject Area: <strong>Climate and Enviorment</strong></li>
  <li>Precision: 1 geospatial 1 records</li>
  <li>Columns: TODO
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado, combined data from US Forest Service (USFS) and US Geological Survey (USGS). Predicting forest cover type from cartographic variables only.</p>

<p>這個研究區域包括科羅拉多北部羅斯福國家森林中的四個荒野地區，結合了美國森林服務（USFS）和美國地質調查（USGS）的數據。僅從地圖變數預測森林覆蓋類型。</p>

<p>https://archive.ics.uci.edu/dataset/31/covertype</p>

<h3 id="ds_salaries"><strong>ds_salaries</strong></h3>

<ul>
  <li>Name: <strong>Data Science Jobs Salaries Dataset</strong></li>
  <li>Alias:</li>
  <li>Subject Area: <strong>Business</strong></li>
  <li>Precision: 1 Person 1 records</li>
  <li>Columns: TODO
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>Salary data for Data Scientists from 2020 to 2021 sourced from ai-jobs.net.</p>

<p>來自 ai-jobs.net 的 2020~2021年中的資料科學家薪資資料。</p>

<p>https://www.kaggle.com/datasets/saurabhshahane/data-science-jobs-salaries
https://ai-jobs.net/salaries/form/</p>

<h3 id="expedia_hotel_logs"><strong>expedia_hotel_logs</strong></h3>

<ul>
  <li>Name: <strong>Expedia Hotel Recommendations datasets</strong></li>
  <li>Alias:</li>
  <li>Subject Area: <strong>Computer Science</strong></li>
  <li>Precision: 1 Recommendations 1 records</li>
  <li>Columns: TODO
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>From Expedia Hotel Recommendations competitions in Kaggle.</p>

<p>來自 Kaggle 的 Expedia 飯店推薦競賽。</p>

<p>https://www.kaggle.com/competitions/expedia-hotel-recommendations/data</p>

<h3 id="intrusion"><strong>intrusion</strong></h3>

<ul>
  <li>Name: <strong>Intrusion Detector Learning</strong></li>
  <li>Alias:</li>
  <li>Subject Area: <strong>Computer Science</strong></li>
  <li>Precision: 1 Connection 1 records</li>
  <li>Columns: TODO
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>This dataset contains network traffic with simulated attacks on a U.S. Air Force LAN and was prepared and managed by MIT Lincoln Labs for the 1998 DARPA Intrusion Detection Evaluation Program, aimed at surveying and evaluating research in intrusion detection. The dataset provides a standardized set of audited data, including a wide variety of intrusions simulated in a military network environment. A version of this dataset was used in the 1999 KDD intrusion detection contest.</p>

<p>這個資料集包含模擬對美國空軍局域網的攻擊的網絡流量，是為了 1998 年 DARPA 入侵檢測評估計劃而由MIT林肯實驗室準備的，旨在調查和評估入侵檢測領域的研究，並使用在 1999 年的 KDD 入侵檢測競賽。</p>

<p>https://kdd.ics.uci.edu/databases/kddcup99/task.html</p>

<h3 id="iris"><strong>iris</strong></h3>

<ul>
  <li>Name: <strong>Fisher’s Iris data set</strong></li>
  <li>Alias:</li>
  <li>Subject Area: <strong>Biology</strong></li>
  <li>Precision: 1 Organism 1 records</li>
  <li>Columns: TODO
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>The Iris dataset, was originally collected by Edgar Anderson to quantify morphological variations in Iris flowers and made famous by Ronald Fisher in 1936. It includes measurements of sepals and petals from three Iris species, usually used to develop a species-distinguishing model in machine learning field.</p>

<p>Iris 資料集，最初是由 Edgar Anderson 收集以量化鳶尾花的形態變異，並在1936年被 Ronald Fisher 使用而知名。它包括三個鳶尾花物種的花萼和花瓣的測量，在機器學習領域上常用於開發區分物種的模型。</p>

<p>來自 Kaggle 的 Expedia 飯店推薦競賽。</p>

<p>https://en.wikipedia.org/wiki/Iris_flower_data_set</p>

<h3 id="nhanes_diabetes"><strong>nhanes_diabetes</strong></h3>

<ul>
  <li>Name: <strong>National Health and Nutrition Examination Survey (NHANES) 2015-2016 diabetes</strong></li>
  <li>Alias:</li>
  <li>Subject Area: <strong>Health and Medicine</strong></li>
  <li>Precision: 1 Person 1 records</li>
  <li>Columns: 12
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: TODO (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p><strong>“nhanes_diabetes”</strong> is integrated from subsets of NHANES data, and is used in PWSCup2021. Composition details can be found in PWSCup2021 GitHub <code class="language-plaintext highlighter-rouge">activ_diabet9_csv.py</code>. Involves the following subdatasets:</p>

<p><strong>“nhanes_diabetes”</strong> is named this way because “diabet” is commonly used in the community, especially on Kaggle, to refer to other datasets.</p>

<p><strong>“nhanes_diabetes”</strong> 是由 NHANES 資料子集整合而成，並在 PWSCup2021 中使用。有關組成詳情可在 PWSCup2021 GitHub 的 <code class="language-plaintext highlighter-rouge">activ_diabet9_csv.py</code> 中找到。涉及以下子資料集：</p>

<ul>
  <li>DIQ_I - [Questionnaire Data] Diabetes [問卷資料] 糖尿病</li>
  <li>BMX_I - [Examination Data] Body Measures [檢查資料] 身體測量</li>
  <li>PAQ_I - [Questionnaire Data] Physical Activity [問卷資料] 體育活動</li>
  <li>GHB_I - [Laboratory Data] Glycohemoglobin [實驗室資料] 醣化血色素</li>
  <li>DPQ_I - [Questionnaire Data] Mental Health - Depression Screener [問卷資料] 心理健康 - 憂鬱篩檢</li>
  <li>INQ_I - [Questionnaire Data] Income [問卷資料] 收入</li>
</ul>

<p>因為 “diabet” 在社群上、尤其是 Kaggle、通常是指其他的資料集，所以本資料集命名為 <strong>“nhanes_diabetes”</strong>。</p>

<pre><code class="language-Python">loader = PETsARD.Loader(
    filepath='benchmark://nhanes_diabetes',
    header_exist=False,
    header_names=[
      'gen','age','race','edu','mar',
      'bmi','dep','pir','gh','mets',
      'qm','dia'
    ]
)
print(loader.data.head(1))
</code></pre>

<p>https://www.iwsec.org/pws/2021/index.html
https://github.com/kikn88/pwscup2021
https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx?BeginYear=2015
https://hackmd.io/@petworks/rJ-UOh9Rn/https%3A%2F%2Fhackmd.io%2F%40petworks%2Fr15yF3zYT</p>

<h3 id="smoking_driking"><strong>smoking_driking</strong></h3>

<ul>
  <li>Name: <strong>Smoking and Drinking Dataset with body signal</strong></li>
  <li>Alias:</li>
  <li>Subject Area: <strong>Health and Medicine</strong></li>
  <li>Precision: 1 Person 1 records</li>
  <li>Columns: 24
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>Provided by the National Health Insurance Service in Korea, a dataset on smoking, drinking, and body signal (physiological indicators) with sensitive information removed. Dataset labels are named based on the original dataset file names.</p>

<p>由韓國健康保險公團提供，去除機敏資料的抽菸、飲酒、與生理指標資料集。資料集標籤按照原始資料集檔案名稱取名。</p>

<p>https://www.kaggle.com/datasets/sooyoungher/smoking-drinking-dataset/data</p>

<h3 id="uk_us_pf_household"><strong>uk_us_pf_household</strong></h3>

<ul>
  <li>Name: <strong>UK-US PETs prize challenges - Pandemic Forecasting: Household datasets</strong></li>
  <li>Alias:</li>
  <li>Subject Area: <strong>Health and Medicine</strong></li>
  <li>Precision: 1 House 1 records</li>
  <li>Columns: TODO
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>The data is sourced from the Synthetic Epidemiology Challenge within the U.S.-UK Privacy Enhancement Technologies prize challenges. It should be noted that it currently only includes data entity two provided by the University of Virginia from the U.S., and selects only three representative datasets.</p>

<p>資料來源於美國英國隱私強化技術比賽當中的合成流行病學比賽項目。須注意的是目前只包含美國方的維吉尼亞大學提供的資料實體二，且僅挑選三個代表性資料集。</p>

<p>https://petsprizechallenges.com/
https://prepare-vo.org/synthetic-pandemic-outbreaks
https://dataverse.lib.virginia.edu/dataset.xhtml?persistentId=doi:10.18130/V3/ZOG1FF
https://net.science/files/resources/datasets/PET_Prize_PandemicForecasting/</p>

<h3 id="uk_us_pf_person"><strong>uk_us_pf_person</strong></h3>

<ul>
  <li>Name: <strong>UK-US PETs prize challenges - Pandemic Forecasting: Person datasets</strong></li>
  <li>Alias:</li>
  <li>Subject Area: <strong>Health and Medicine</strong></li>
  <li>Precision: 1 Person 1 records</li>
  <li>Columns: TODO
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>See <strong>uk_us_pf_household</strong> for more details.</p>

<p>詳情請見 <strong>uk_us_pf_household</strong>。</p>

<h3 id="uk_us_pf_prop_net"><strong>uk_us_pf_prop_net</strong></h3>

<ul>
  <li>Name: <strong>UK-US PETs prize challenges - Pandemic Forecasting: Population Network datasets</strong></li>
  <li>Alias:</li>
  <li>Subject Area: <strong>Health and Medicine</strong></li>
  <li>Precision: 1 Connection 1 records</li>
  <li>Columns: TODO
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: Yes (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>See <strong>uk_us_pf_household</strong> for more details.</p>

<p>詳情請見 <strong>uk_us_pf_household</strong>。</p>

<h3 id="us_census_1940"><strong>us_census_1940</strong></h3>

<ul>
  <li>Name: <strong>Version 8.0 Extract of 1940 Census full-count dataset</strong></li>
  <li>Alias: <strong>US Census</strong></li>
  <li>Subject Area: <strong>Social Science</strong></li>
  <li>Precision: 1 Person 1 records</li>
  <li>Columns: 15
    <ul>
      <li>Continuous: TODO</li>
      <li>Datetime: TODO</li>
      <li>Discrete: TODO</li>
      <li>Float: TODO</li>
      <li>String: TODO</li>
      <li>Int: TODO</li>
    </ul>
  </li>
  <li>Missing %: TODO (TODO)
    <ul>
      <li>Special NA value: TODO</li>
    </ul>
  </li>
</ul>

<p>Any IPUMS USA Full Count data is not redistribute without permission, so we set as “Private”</p>

<p>未經許可，不得重新分發任何 IPUMS USA 全統計資料，故設定為 “Private”。</p>

<p>https://usa.ipums.org/usa/1940CensusDASTestData.shtml</p>

<h2 id="data-summary">Data summary</h2>

<h3 id="subject-area">Subject Area</h3>

<p><strong>Subject Area</strong> refers to the classification of datasets based on the <a href="https://archive.ics.uci.edu/">UC Irvine Machine Learning Repository</a>.</p>

<p><strong>Subject Area</strong> 是根據<a href="https://archive.ics.uci.edu/">加州大學爾灣分校機器學習資料庫</a>的資料集分類。</p>

<!-- This <div> here is special function for sighingnow/jekyll-gitbook -->
<div class="table-wrapper">

  <table>
    <thead>
      <tr>
        <th style="text-align: center">Subject Area</th>
        <th style="text-align: center">Counts</th>
        <th style="text-align: center">Public</th>
        <th style="text-align: center">Private</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: center">Biology</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">iris</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Business</td>
        <td style="text-align: center">3</td>
        <td style="text-align: center">car_insurance, ds_salaries, expedia_hotel_logs,</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Climate and Enviorment</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">covtype</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Computer Science</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">intrusion</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Engineering</td>
        <td style="text-align: center">0</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Games</td>
        <td style="text-align: center">0</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Health and Medicine</td>
        <td style="text-align: center">5</td>
        <td style="text-align: center">nhanes_diabetes, smoking_driking, uk_us_pf_household, uk_us_pf_person, uk_us_pf_prop_net</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Law</td>
        <td style="text-align: center">0</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Physics and Chemistry</td>
        <td style="text-align: center">0</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Social Science</td>
        <td style="text-align: center">3</td>
        <td style="text-align: center">adult, coil2000</td>
        <td style="text-align: center">us_census_1940</td>
      </tr>
      <tr>
        <td style="text-align: center">Other</td>
        <td style="text-align: center">0</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center"> </td>
      </tr>
    </tbody>
  </table>

</div>

<ul>
  <li><strong>car_insurance</strong> be categorized in <strong>Business</strong>, but <strong>coil2000</strong> from UCI ML have been categorized in <strong>Social Science</strong>.</li>
</ul>

<h3 id="precision">Precision</h3>

<!-- This <div> here is special function for sighingnow/jekyll-gitbook -->
<div class="table-wrapper">

  <table>
    <thead>
      <tr>
        <th style="text-align: center">Precision</th>
        <th style="text-align: center">Counts</th>
        <th style="text-align: center">Public</th>
        <th style="text-align: center">Private</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: center">By Connection</td>
        <td style="text-align: center">2</td>
        <td style="text-align: center">intrusion, uk_us_pf_prop_net</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">By Geospatial</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">covtype</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">By House</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">uk_us_pf_household</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">By Organism</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">iris</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">By Person</td>
        <td style="text-align: center">All remains</td>
        <td style="text-align: center">(skip)</td>
        <td style="text-align: center">(skip)</td>
      </tr>
      <tr>
        <td style="text-align: center">By Recommendation</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">expedia_hotel_logs</td>
        <td style="text-align: center"> </td>
      </tr>
    </tbody>
  </table>

</div>

<h3 id="inclusion-reasons">Inclusion Reasons</h3>

<p>The inclusion of the Benchmark dataset is based on retaining only the most significant reason.</p>

<p>納入基準資料集原因只保留最重要的一個原因。</p>

<!-- This <div> here is special function for sighingnow/jekyll-gitbook -->
<div class="table-wrapper">

  <table>
    <thead>
      <tr>
        <th style="text-align: center">Reason</th>
        <th style="text-align: center">Counts</th>
        <th style="text-align: center">Public</th>
        <th style="text-align: center">Private</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: center">Common PETs</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">adult</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Common DS/ML</td>
        <td style="text-align: center">2</td>
        <td style="text-align: center">coil2000, iris</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Taiwan guidelines</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">nhanes_diabetes</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">112 ITRI</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">ds_salaries, smoking_driking</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Precision</td>
        <td style="text-align: center">3</td>
        <td style="text-align: center">covtype, expedia_hotel_logs, uk_us_pf_person, uk_us_pf_prop_net</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Replication</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center">us_census_1940</td>
      </tr>
      <tr>
        <td style="text-align: center">Competition</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">uk_us_pf_household</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">Others</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">alarm, car_insurance, intrusion</td>
        <td style="text-align: center"> </td>
      </tr>
    </tbody>
  </table>

</div>

<ul>
  <li>Common PETs：Commonly Used in PETs fields 常用於隱私強化技術領域</li>
  <li>Common DS/ML：Commonly Used in Data Science/Machine Learning 常用於資料科學/機器學習領域
    <ul>
      <li>The value of “iris” in privacy protection research is questionable “iris” 在隱私保護研究的價值是存疑的</li>
    </ul>
  </li>
  <li>Taiwan guidelines: The Taiwan guideline handbook has been utilized 臺灣指引手冊有使用
    <ul>
      <li>PETsWork: included <a href="https://hackmd.io/@petworks/rJ-UOh9Rn/https%3A%2F%2Fhackmd.io%2F%40petworks%2Fr15yF3zYT">“nhanes_diabetes”</a></li>
    </ul>
  </li>
  <li>112 ITRI: (Industrial Technology Research Institute) 工研院112年計畫成果有使用
    <ul>
      <li>Some of the data from 112 ITRI are solely test data created by the Academia Sinica, and the dataset size is too small so we excluded. 有些工研院112年使用的只是中研院產生的測試用假資料，且資料大小太小，故不納入。
        <ul>
          <li>Included <strong>fake_job.csv</strong>, <strong>fake_lat.csv</strong>, <strong>fake_lon.csv</strong>, <strong>revenue_tw_id.csv</strong>, <strong>sports_id.csv</strong>, and <strong>zh_tw_header.csv</strong>.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Precision: Enrich Precision type 增加多元精度類型
    <ul>
      <li>The value of <strong>covtype</strong> in privacy protection research is questionable <strong>covtype</strong> 在隱私保護研究的價值是存疑的</li>
    </ul>
  </li>
  <li>Replication: Replicated research findings 重製研究成果</li>
  <li>Competition: Used in a competition 在隱私強化技術競賽用過</li>
  <li>Others: Others/Uncategorized 其他/未分類
    <ul>
      <li>some of <strong>SDGym</strong> datasets have be categorized here because not sure are these datasets popular enough. 有些 <strong>SDGym</strong> 的資料集被分在此，是由於不清楚這些資料集是否夠知名。</li>
    </ul>
  </li>
</ul>

<h3 id="mention-in-research">Mention in Research</h3>

<!-- This <div> here is special function for sighingnow/jekyll-gitbook -->
<div class="table-wrapper">

  <table>
    <thead>
      <tr>
        <th style="text-align: center">Topic</th>
        <th style="text-align: center">Paper</th>
        <th style="text-align: center">Counts</th>
        <th style="text-align: center">Public</th>
        <th style="text-align: center">Private</th>
        <th style="text-align: center">Coverage%</th>
        <th style="text-align: center">Notes</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: center">Anonymeter</td>
        <td style="text-align: center">1.</td>
        <td style="text-align: center">2</td>
        <td style="text-align: center">adult</td>
        <td style="text-align: center">us_census_1940</td>
        <td style="text-align: center">66.7%</td>
        <td style="text-align: center">a.</td>
      </tr>
      <tr>
        <td style="text-align: center">SDGym</td>
        <td style="text-align: center">2.</td>
        <td style="text-align: center">6</td>
        <td style="text-align: center">adult, alarm, car_insurance, covtype, expedia_hotel_logs, intrusion</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center">66.7%</td>
        <td style="text-align: center">b.c.</td>
      </tr>
      <tr>
        <td style="text-align: center">smartnoise</td>
        <td style="text-align: center">3.</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">iris</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center">16.7%</td>
        <td style="text-align: center">d.e.</td>
      </tr>
    </tbody>
  </table>

</div>

<ol>
  <li>Giomi, M., Boenisch, F., Wehmeyer, C., &amp; Tasnádi, B. (2023). A Unified Framework for Quantifying Privacy Risk in Synthetic Data. <em>Proceedings of Privacy Enhancing Technologies Symposium</em>, 2023(2), 312–328. https://doi.org/10.56553/popets-2023-0055</li>
  <li>https://docs.sdv.dev/sdgym/customization/datasets/public-sdv-datasets</li>
  <li>https://github.com/opendp/smartnoise-sdk/tree/main/datasets</li>
</ol>

<p>a. <strong>texas</strong> requires payment. <strong>texas</strong> 需要付費。
b. <strong>census</strong> is duplicated and its webpage is offline. <strong>census</strong> 資料集重複，且其網頁已經無法訪問。
c. <strong>child</strong> and <strong>news</strong> datasets didn’t have reference. <strong>child</strong> 和 <strong>news</strong> 資料集缺乏參考資料。
d. 4 <strong>pums</strong> datasets discussion see below. 有關4個 <strong>pums</strong> 資料集的討論請參見下文。
e. <strong>reddit</strong> dataset didn’t have reference. <strong>reddit</strong> 資料集缺乏參考資料。</p>

<h3 id="used-in-competition">Used in Competition</h3>

<!-- This <div> here is special function for sighingnow/jekyll-gitbook -->
<div class="table-wrapper">

  <table>
    <thead>
      <tr>
        <th style="text-align: center">Topic</th>
        <th style="text-align: center">Link</th>
        <th style="text-align: center">Counts</th>
        <th style="text-align: center">Public</th>
        <th style="text-align: center">Private</th>
        <th style="text-align: center">Notes</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: center">PWSCup</td>
        <td style="text-align: center">1.2.</td>
        <td style="text-align: center">2</td>
        <td style="text-align: center">adult, nhanes_diabetes</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">UK-US</td>
        <td style="text-align: center">3.</td>
        <td style="text-align: center">3</td>
        <td style="text-align: center">uk_us_pf_household, uk_us_pf_person, uk_us_pf_prop_net</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center"> </td>
      </tr>
    </tbody>
  </table>

</div>

<ol>
  <li>PWSCup2021: Use <strong>nhanes_diabetes</strong> https://www.iwsec.org/pws/2021/index.html</li>
  <li>PWSCup2020: Use Synthetic data from <strong>adult</strong> https://www.iwsec.org/pws/2020/cup20.html</li>
  <li>UK-US PETs prize challenges 2023: https://petsprizechallenges.com/
    <ul>
      <li>There’s couples of datasets in UK-US, we include only the most representative. Here’s remains: TODO</li>
    </ul>
  </li>
</ol>

<h2 id="appendix-for-non-included-datasets">Appendix for non-included datasets</h2>

<h3 id="pums"><strong>pums</strong></h3>

<ul>
  <li>Name: <strong>The American Community Survey (ACS) Public Use Microdata Sample (PUMS)</strong></li>
</ul>

<p><strong>OpenDP</strong>’s and <strong>smartnoise</strong>’s demo use 1,000 records of California demographics, only below columns: [“age”, “sex”, “educ”, “race”, “income”, “married”]. But didn’t specific which year they use (2005~2022 is available)</p>

<p>In reference to the NIST CRC 2023 Deidentified Data Archives, it may be possible to define multiple <strong>PUMAs</strong> based on geographical regions, and the classification approach can initially follow their guidelines</p>

<p><strong>OpenDP</strong> 與 <strong>smartnoise</strong> 的示範使用了 1,000 條加州人口統計數據，僅包含以下欄位：[“age”, “sex”, “educ”, “race”, “income”, “married”]。但並未具體指明使用了哪一年的數據（2005年至2022年的數據均可用）。</p>

<p>參考了 NIST CRC 2023 去識別化資料存檔的介紹，或許可以依照地區定義多個 <strong>PUMAs</strong>，然後分類方法可以先依照他們。</p>

<p>https://www.census.gov/programs-surveys/acs/microdata.html
https://github.com/opendp/smartnoise-sdk/tree/main/datasets
https://pages.nist.gov/privacy_collaborative_research_cycle/pages/archive.html#acceleration-bundle
https://github.com/usnistgov/SDNist/tree/main/nist%20diverse%20communities%20data%20excerpts</p>

<h3 id="texas"><strong>texas</strong></h3>

<ul>
  <li>Name: <strong>Texas Hospital Discharge Data Public Use Data</strong></li>
</ul>

<p>For data downloads by non-Texas public universities and public health institutions, it is necessary to complete an application form and pay an annual subscription fee.</p>

<p>對於非德州的公立大學和公共衛生機構來說，需要填寫一份申請表格並支付年度訂閱費。</p>

<p>https://www.dshs.texas.gov/texas-health-care-information-collection/general-public-information/hospital-discharge-data-public</p>

<h2 id="storage">storage</h2>

<p>The module of benchmark dataset will first download the requested raw data, and store it in a “benchmark” folder within the working directory (in lowercase). If the folder does not exist, it will be created automatically (<code class="language-plaintext highlighter-rouge">./benchmark/{Benchmark filename}</code>). Subsequently, it will follow the regular <code class="language-plaintext highlighter-rouge">Loader</code> process for loading. When using it, please be mindful of your permissions and available hardware space.</p>

<p>If the “benchmark” folder already contains a file with the same filename as the dataset, the program will check if the local data matches the records in <code class="language-plaintext highlighter-rouge">PETsARD</code>. If they match, the program will skip the download and use the local data directly, making it convenient for users to reuse the data multiple times. It’s important to note that if there is a file with the same name but with inconsistent data, <code class="language-plaintext highlighter-rouge">Loader</code> will issue a warning and stop. In such cases, users should be aware that the benchmark dataset might have been tampered with, potentially contaminating the experimental results.</p>

<p>基準資料集功能會先下載你所請求的原始資料，存到工作目錄下方的 “benchmark” 資料夾裡（小寫），如果不存在會自動開一個 (<code class="language-plaintext highlighter-rouge">./benchmark/{Benchmark filename}</code>)，之後照一般的 <code class="language-plaintext highlighter-rouge">Loader</code> 流程加載。使用時請注意你的權限與硬體空間。</p>

<p>如果你的 “benchmark” 資料夾裡面已經有該資料集對應的同名檔案了，則程式會檢驗本地端的資料是否與 <code class="language-plaintext highlighter-rouge">PETsARD</code> 的紀錄一致，如果一致的話，便會省去下載、直接使用本地端資料，方便使用者多次使用。要注意的是如果同檔名但檢驗不一致的話，<code class="language-plaintext highlighter-rouge">Loader</code> 會告警並停止，此時使用者應該留意到可能儲存到了非原版的基準資料集，這很有可能對實驗結果造成汙染。</p>

<h2 id="verification">verification</h2>

<p>Classic benchmark datasets are often used in various data analysis or machine learning scenarios. However, when discussing the same dataset, it is common to find inconsistencies in the content in practical experience. Common patterns include:</p>

<ul>
  <li>Inconsistent variable encoding transformations (e.g., having original categorical variables recorded as strings, <code class="language-plaintext highlighter-rouge">Label Encoding</code> encoded versions, or generalized categorical versions).</li>
  <li>Inconsistent row counts (e.g., versions before or after removing missing values).</li>
  <li>Inconsistent columns (e.g., column renaming, or versions after feature engineering).</li>
</ul>

<p>The reasons for these patterns are often not malicious tampering, but rather the release of optimized or preprocessed data, which is then inadvertently propagated by subsequent users. Since the preprocessing methods for privacy-enhancing technologies are crucial, obtaining the same version of the benchmark dataset is the recommended experimental procedure in <code class="language-plaintext highlighter-rouge">PETsARD</code>.</p>

<p>經典的基準資料集常被用於各種資料分析或機器學習的場合，但實務經驗上，常遇到討論同一個資料集的時候，發現彼此的資料集內容不一致。常見的樣態有：</p>

<ul>
  <li>變項編碼轉換不一致（例如分別有原始以字串紀錄的類別變項、<code class="language-plaintext highlighter-rouge">Label Encoding</code>過的編碼、概化後的分類的版本）</li>
  <li>筆數不一致（例如剔除遺失值前或後的版本）</li>
  <li>欄位不一致（例如欄位重命名，或是欄位經過特徵工程的版本）</li>
</ul>

<p>造成這些樣態原因常常不是惡意竄改，而是某些優化過、或是前處理過的資料被釋出，而後續使用者不經意地加以傳播所導致。由於隱私強化技術的前處理方式至關重要，於是取得相同版本的基準資料集是 <code class="language-plaintext highlighter-rouge">PETsARD</code> 建議的實驗程序。</p>

<h3 id="_calculate_sha256">_calculate_sha256()</h3>

<p><code class="language-plaintext highlighter-rouge">PETsARD</code> ensures the consistency of benchmark datasets’ versions by calculating the SHA-256 hash value of files and comparing it to the settings in the <code class="language-plaintext highlighter-rouge">benchmark_datasets.yaml</code> file. Specifically, <code class="language-plaintext highlighter-rouge">PETsARD</code> uses <code class="language-plaintext highlighter-rouge">hashlib.sha256()</code> to calculate the hash of the binary version of a file and records its hexadecimal representation (<code class="language-plaintext highlighter-rouge">.hexdigest()</code>).</p>

<p>In the functionality related to benchmark datasets, the SHA-256 calculation is entirely background, automated, and in future versions, methods will be provided for users to calculate it manually if desired.</p>

<p><code class="language-plaintext highlighter-rouge">PETsARD</code> 藉由計算檔案的 SHA-256 值，與設定檔案 <code class="language-plaintext highlighter-rouge">benchmark_datasets.yaml</code> 做比較，來確保基準資料集的版本一致。具體來說，<code class="language-plaintext highlighter-rouge">PETsARD</code> 使用 <code class="language-plaintext highlighter-rouge">hashlib.sha256()</code> 計算檔案二進位版本的雜湊，並記錄其雜湊值的 16 進位表示 (<code class="language-plaintext highlighter-rouge">.hexdigest()</code>)。</p>

<p>在基準資料集的功能中，計算 SHA-256 是完全後台的、自動化的，未來版本會再提供方法供使用者自行計算。</p>

<h2 id="publicprivate-access">public/private access</h2>

<p>The <code class="language-plaintext highlighter-rouge">PETsARD</code> development team, which belongs to the <a href="https://www.nics.nat.gov.tw/">National Institute for Cyber Security (NICS)</a>, stores the benchmark datasets in their cloud space. These datasets are categorized as <strong>public</strong> or <strong>private access</strong>, and the calling methods for both are identical.</p>

<p><strong>Public datasets</strong> are securely stored in the cloud space after obtaining proper authorization, and they can be downloaded using <code class="language-plaintext highlighter-rouge">request.get()</code> On the other hand, <strong>Private datasets</strong>, which may have restrictions based on the dataset’s authorization or considerations from the data provider, are intended for internal use by the development team and collaborating parties. Access to private datasets is established through <code class="language-plaintext highlighter-rouge">boto3</code> connection, and configuring cloud permissions is necessary. For any related inquiries, please contact the development team.</p>

<p>基準資料集儲存在 <code class="language-plaintext highlighter-rouge">PETsARD</code> 開發團隊所屬的臺灣<a href="https://www.nics.nat.gov.tw/">國家資通安全研究院 (NICS)</a>雲端空間，分成<strong>公開</strong>與<strong>私有訪問</strong>兩種。兩者的呼叫方式完全一樣。</p>

<p><strong>公開資料集</strong>皆是確認過其授權後，由團隊保存之雲端備份，使用 <code class="language-plaintext highlighter-rouge">request.get()</code> 下載。而<strong>私有資料集</strong>，包含了資料集本身授權的限制、或是資料提供方的考量等原因，僅供團隊與合作方內部使用。目前私有資料集使用 <code class="language-plaintext highlighter-rouge">boto3</code> 連線，需要預先設定雲端權限，相關問題請聯絡開發團隊。</p>]]></content><author><name>NICS - PETs</name></author><summary type="html"><![CDATA[Benchmark datasets]]></summary></entry><entry><title type="html">Encoder</title><link href="http://localhost:4000/PETsARD-Gitbook/Encoder.html" rel="alternate" type="text/html" title="Encoder" /><published>2024-01-05T00:00:00+08:00</published><updated>2024-01-05T00:00:00+08:00</updated><id>http://localhost:4000/PETsARD-Gitbook/Encoder</id><content type="html" xml:base="http://localhost:4000/PETsARD-Gitbook/Encoder.html"><![CDATA[<h1 id="encoder">Encoder</h1>

<p>The <code class="language-plaintext highlighter-rouge">Encoder</code> module transforms categorical data into numerical format, a requirement for many modeling procedures. Currently, we provide two encoders: the uniform encoder and the label encoder.</p>

<p><code class="language-plaintext highlighter-rouge">Encoder</code> 模組將類別資料轉換為連續型資料，方便套用大多數的模型。目前我們提供兩種方法：Uniform encoder 和 Label encoder。</p>

<h2 id="encoder_uniform-uniform-encoder"><code class="language-plaintext highlighter-rouge">Encoder_Uniform</code>: Uniform Encoder</h2>

<p>Applying uniform encoders during data processing, as suggested by <a href="https://datacebo.com/blog/improvement-uniform-encoder/">datacebo</a>, can enhance the performance of generative algorithms compared to other encoders. The concept is straightforward: map each category to a specific range in the uniform distribution, with ranges determined by the relative proportion of each category in the data. Major categories occupy larger areas under the distribution.</p>

<p><a href="https://datacebo.com/blog/improvement-uniform-encoder/">datacebo</a> 認為在資料處理過程中使用 Uniform encoder 來處理類別資料，可以提升生成模型的表現。Uniform encoder 的概念非常直觀：將每個類別映射到 Uniform distribution 中的特定範圍，範圍由資料中各類別的比例決定，因此較常見的類別會對應到較大的範圍。</p>

<p>Advantages of using a uniform encoder:</p>

<ol>
  <li>The variable’s distribution converts from discrete to continuous, facilitating modeling.</li>
  <li>The range of the new distribution is fixed, allowing easy conversion of any value between 0 and 1 to a category.</li>
  <li>The mapping relationship retains information about the original distribution, a valuable property for sampling. More frequent categories are more likely to be sampled due to their larger areas under the distribution.</li>
</ol>

<p>相較於其他類型的處理方式，使用 Uniform encoder 有以下優勢：</p>

<ol>
  <li>變數的分布從離散轉換為連續，有助於建模。</li>
  <li>新分配的範圍固定，可將任何介於 0 和 1 之間的值輕鬆轉換為類別變數。</li>
  <li>映射關係保留原始資料分配的訊息，有助於進行抽樣。由於出現頻率較高的類別其分配下的面積較大，因此更有可能被抽樣，反映出原始資料的樣態。</li>
</ol>

<p>A toy example demonstrates the output of a uniform encoder:</p>

<p>Assuming a categorical variable with three categories, ‘a’, ‘b’, and ‘c’, and associated proportions of 1:3:1, respectively. The mapping relationship is as follows:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
    'a': [0.0, 0.2),
    'b': [0.2, 0.8),
    'c': [0.8, 1.0]
}
</code></pre></div></div>

<p>After transformation by the uniform encoder, data belonging to category ‘a’ will be assigned a random value between 0.0 (inclusive) and 0.2 (exclusive), data in category ‘b’ between 0.2 (inclusive) and 0.8 (exclusive), and data in category ‘c’ between 0.8 (inclusive) and 1.0 (inclusive).</p>

<p>To inverse transform numerical data to categorical data, simply check the range in which the value falls and convert it back to the corresponding category using the mapping relationship.</p>

<p>以下是 Uniform encoder 的簡易範例：</p>

<p>假設一個具有三個類別 ‘a’、’b’ 和 ‘c’的類別變數，其資料比例為 1:3:1。則映射關係如下：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
    'a': [0.0, 0.2),
    'b': [0.2, 0.8),
    'c': [0.8, 1.0]
}
</code></pre></div></div>

<p>經過 Uniform encoder 的轉換後，類別 ‘a’ 會用介於 0.0（包含）和 0.2（不包含）之間的隨機值取代，類別 ‘b’ 會用介於 0.2（包含）和 0.8（不包含）之間的隨機值取代，類別 ‘c’ 則會用介於 0.8（包含）和 1.0（包含）之間的隨機值取代。</p>

<p>而要將連續型變數反轉為類別資料，只需檢查其值所處的範圍，然後使用映射關係將其轉換回相應的類別即可。</p>

<p>Uniform encoders are available by calling <code class="language-plaintext highlighter-rouge">Encoder_Uniform</code>.</p>

<p>要使用此方法，可以透過 <code class="language-plaintext highlighter-rouge">Encoder_Uniform</code> 類別。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Encoder</span> <span class="kn">import</span> <span class="n">Encoder_Uniform</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder_Uniform</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="encoder_label-label-encoder"><code class="language-plaintext highlighter-rouge">Encoder_Label</code>: Label Encoder</h2>

<p>Transform categorical data into numerical data by assigning a series of integers (1, 2, 3,…) to the categories.</p>

<p>將類別變數對應到一系列的整數 (1, 2, 3,…) 藉此達到轉換為連續型資料的目的。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Encoder</span> <span class="kn">import</span> <span class="n">Encoder_Label</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder_Label</span><span class="p">()</span>
</code></pre></div></div>]]></content><author><name>NICS - PETs</name></author><summary type="html"><![CDATA[Encoder]]></summary></entry><entry><title type="html">Missingist</title><link href="http://localhost:4000/PETsARD-Gitbook/Missingist.html" rel="alternate" type="text/html" title="Missingist" /><published>2024-01-05T00:00:00+08:00</published><updated>2024-01-05T00:00:00+08:00</updated><id>http://localhost:4000/PETsARD-Gitbook/Missingist</id><content type="html" xml:base="http://localhost:4000/PETsARD-Gitbook/Missingist.html"><![CDATA[<h1 id="missingist">Missingist</h1>

<p>The <code class="language-plaintext highlighter-rouge">Missingist</code> module handles missing values in a dataset, offering four methods for coping with them.</p>

<p><code class="language-plaintext highlighter-rouge">Missingist</code> 模組處理數據集中的缺失值，並提供四種處理方法。</p>

<h2 id="missingist_drop-drop-the-missing-values"><code class="language-plaintext highlighter-rouge">Missingist_Drop</code>: Drop the missing values</h2>

<p>This method involves dropping the rows containing missing values in any column.</p>

<p>捨棄任何含有缺失值的列。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Missingist</span> <span class="kn">import</span> <span class="n">Missingist_Drop</span>

<span class="n">missingist</span> <span class="o">=</span> <span class="n">Missingist_Drop</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="missingist_mean-fill-the-missing-values-with-the-mean"><code class="language-plaintext highlighter-rouge">Missingist_Mean</code>: Fill the missing values with the mean</h2>

<p>Missing values are filled with the mean value of the corresponding column.</p>

<p>將缺失值用該欄的平均值填入。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Missingist</span> <span class="kn">import</span> <span class="n">Missingist_Mean</span>

<span class="n">missingist</span> <span class="o">=</span> <span class="n">Missingist_Mean</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="missingist_median-fill-the-missing-values-with-the-median"><code class="language-plaintext highlighter-rouge">Missingist_Median</code>: Fill the missing values with the median</h2>

<p>Missing values are filled with the median value of the corresponding column.</p>

<p>將缺失值用該欄的中位數填入。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Missingist</span> <span class="kn">import</span> <span class="n">Missingist_Median</span>

<span class="n">missingist</span> <span class="o">=</span> <span class="n">Missingist_Median</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="missingist_simple-fill-the-missing-values-with-a-predefined-value"><code class="language-plaintext highlighter-rouge">Missingist_Simple</code>: Fill the missing values with a predefined value</h2>

<p>Missing values are filled with a predefined value for the corresponding column.</p>

<p>將缺失值用指定的值填入。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Missingist</span> <span class="kn">import</span> <span class="n">Missingist_Simple</span>

<span class="n">missingist</span> <span class="o">=</span> <span class="n">Missingist_Simple</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="parameters">Parameters</h3>
<p><code class="language-plaintext highlighter-rouge">value</code> (<code class="language-plaintext highlighter-rouge">float</code>): The value to be imputed.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">value</code> (<code class="language-plaintext highlighter-rouge">float</code>): 要填入的自訂值。</p>]]></content><author><name>NICS - PETs</name></author><summary type="html"><![CDATA[Missingist]]></summary></entry><entry><title type="html">Outlierist</title><link href="http://localhost:4000/PETsARD-Gitbook/Outlierist.html" rel="alternate" type="text/html" title="Outlierist" /><published>2024-01-05T00:00:00+08:00</published><updated>2024-01-05T00:00:00+08:00</updated><id>http://localhost:4000/PETsARD-Gitbook/Outlierist</id><content type="html" xml:base="http://localhost:4000/PETsARD-Gitbook/Outlierist.html"><![CDATA[<h1 id="outlierist">Outlierist</h1>

<p>The <code class="language-plaintext highlighter-rouge">Outlierist</code> module is designed to identify and remove data classified as outliers. Four methods for identifying outliers are provided:</p>

<p><code class="language-plaintext highlighter-rouge">Outlierist</code> 模組旨在識別並刪除被歸類為異常值的數據。此套件提供了四種識別異常值的方法：</p>

<h2 id="outlierist_zscore-identify-outliers-by-z-score"><code class="language-plaintext highlighter-rouge">Outlierist_ZScore</code>: Identify outliers by z-score</h2>

<p>This method classifies data as outliers if the absolute value of the z-score is greater than 3.</p>

<p>此方法將 z 分數的絕對值大於 3 的資料歸類為異常值。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Outlierist</span> <span class="kn">import</span> <span class="n">Outlierist_ZScore</span>

<span class="n">outlierist</span> <span class="o">=</span> <span class="n">Outlierist_ZScore</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="outlierist_iqr-identify-outliers-by-iqr"><code class="language-plaintext highlighter-rouge">Outlierist_IQR</code>: Identify outliers by IQR</h2>

<p>Data outside the range of 1.5 times the interquartile range (IQR) is determined as an outlier.</p>

<p>在此方法中，超過 1.5 倍四分位距（IQR）範圍的資料會被視為異常值。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Outlierist</span> <span class="kn">import</span> <span class="n">Outlierist_IQR</span>

<span class="n">outlierist</span> <span class="o">=</span> <span class="n">Outlierist_IQR</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="outlierist_isolationforest-identify-outliers-by-isolation-forest"><code class="language-plaintext highlighter-rouge">Outlierist_IsolationForest</code>: Identify outliers by Isolation Forest</h2>

<p>This method uses <code class="language-plaintext highlighter-rouge">IsolationForest</code> from sklearn to identify outliers. It is a global transformation, meaning that if any column uses the isolation forest as an outlierist, it will overwrite the entire config and apply isolation forest to all outlierists.</p>

<p>此方法使用 sklearn 的 <code class="language-plaintext highlighter-rouge">IsolationForest</code> 進行異常值識別。這是一種全域轉換，意即只要設定檔中有任何欄位使用此方法作為異常值處理器，它將覆寫整個設定檔並將此方法應用於所有欄位。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Outlierist</span> <span class="kn">import</span> <span class="n">Outlierist_IsolationForest</span>

<span class="n">outlierist</span> <span class="o">=</span> <span class="n">Outlierist_IsolationForest</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="outlierist_lof-identify-outliers-by-local-outlier-factor"><code class="language-plaintext highlighter-rouge">Outlierist_LOF</code>: Identify outliers by Local Outlier Factor</h2>

<p>This method uses <code class="language-plaintext highlighter-rouge">LocalOutlierFactor</code> from sklearn to identify outliers. It is a global transformation, meaning that if any column uses the isolation forest as an outlierist, it will overwrite the entire config and apply isolation forest to all outlierists.</p>

<p>此方法使用 sklearn 的 <code class="language-plaintext highlighter-rouge">LocalOutlierFactor</code> 進行異常值識別。這是一種全域轉換，意即只要設定檔中有任何欄位使用此方法作為異常值處理器，它將覆寫整個設定檔並將此方法應用於所有欄位。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Outlierist</span> <span class="kn">import</span> <span class="n">Outlierist_LOF</span>

<span class="n">outlierist</span> <span class="o">=</span> <span class="n">Outlierist_LOF</span><span class="p">()</span>
</code></pre></div></div>]]></content><author><name>NICS - PETs</name></author><summary type="html"><![CDATA[Outlierist]]></summary></entry><entry><title type="html">Processor</title><link href="http://localhost:4000/PETsARD-Gitbook/Processor.html" rel="alternate" type="text/html" title="Processor" /><published>2024-01-05T00:00:00+08:00</published><updated>2024-01-05T00:00:00+08:00</updated><id>http://localhost:4000/PETsARD-Gitbook/Processor</id><content type="html" xml:base="http://localhost:4000/PETsARD-Gitbook/Processor.html"><![CDATA[<h1 id="processor">Processor</h1>

<p>The <code class="language-plaintext highlighter-rouge">Processor</code> module is responsible for managing preprocessing and postprocessing procedures during experiments. This component facilitates easy data handling, including tasks such as encoding categorical data, handling missing data, excluding outliers, and scaling data. This guide will walk you through the creation and manipulation of a processor instance from the <code class="language-plaintext highlighter-rouge">Processor</code> class.</p>

<p><code class="language-plaintext highlighter-rouge">Processor</code> 模組負責在實驗期間管理資料前處理和後處理（還原）的過程。此元件可進行多種數據處理，包括為類別資料進行編碼、處理缺失值、排除異常值以及標準化資料等任務。本指南將引導您建立和操作 <code class="language-plaintext highlighter-rouge">Processor</code> 類的物件。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Base</span> <span class="kn">import</span> <span class="n">Processor</span>

<span class="n">processor</span> <span class="o">=</span> <span class="n">Processor</span><span class="p">(</span><span class="n">metadata</span><span class="p">)</span>

<span class="n">processor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">transformed_data</span> <span class="o">=</span> <span class="n">processor</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">inverse_transformed_data</span> <span class="o">=</span> <span class="n">processor</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">synthetic_data</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="processor-creation"><code class="language-plaintext highlighter-rouge">Processor</code> Creation</h2>

<p>Once you have an instance of metadata built from the <code class="language-plaintext highlighter-rouge">Metadata</code> class, you can create a <code class="language-plaintext highlighter-rouge">Processor</code>. The <code class="language-plaintext highlighter-rouge">config</code> parameter is optional, allowing you to customise procedures. Upon creation, the processor analyses the metadata to determine the necessary preprocessing and postprocessing procedures. If a <code class="language-plaintext highlighter-rouge">config</code> is passed, the processor will overwrite default settings and follow the procedures specified in the <code class="language-plaintext highlighter-rouge">config</code>.</p>

<p>創建 <code class="language-plaintext highlighter-rouge">Processor</code> 類別的物件之前，必須要有利用 <code class="language-plaintext highlighter-rouge">Metadata</code> 建立的 metadata 物件。在 <code class="language-plaintext highlighter-rouge">Processor</code> 參數中，<code class="language-plaintext highlighter-rouge">config</code> 參數不是必須的，其功能為自訂處理流程。此物件會分析 metadata 以確定所需的前處理和後處理流程。如果有給予 <code class="language-plaintext highlighter-rouge">config</code>，物件會覆寫預設值，並依照 <code class="language-plaintext highlighter-rouge">config</code> 中自訂的流程執行。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">processor</span> <span class="o">=</span> <span class="n">Processor</span><span class="p">(</span>
    <span class="n">metadata</span><span class="p">,</span> <span class="c1"># required
</span>    <span class="n">config</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</code></pre></div></div>

<h3 id="parameters">Parameters</h3>

<p><code class="language-plaintext highlighter-rouge">metadata</code>: The data schema used for creating the processor and inferring appropriate data processing procedures.</p>

<p><code class="language-plaintext highlighter-rouge">config</code> (<code class="language-plaintext highlighter-rouge">dict</code>): User-defined procedures containing information about the components to be used in each column.</p>

<hr />

<p><code class="language-plaintext highlighter-rouge">metadata</code>: 用於推論前處理及後處理流程的數據架構。</p>

<p><code class="language-plaintext highlighter-rouge">config</code> (<code class="language-plaintext highlighter-rouge">dict</code>): 針對每個欄位的自定義處理流程。</p>

<h3 id="get_config"><code class="language-plaintext highlighter-rouge">get_config</code></h3>

<p>Use this method to access the configuration of procedures to be done during the transformation/inverse transform process. It is summarised by the processor types (missingist, outlierist, encoder, scaler) and columns, storing all data processing objects for user access.</p>

<p>使用此方法取得在轉換/逆轉換過程中的設定檔。此設定檔依據處理類型（missingist、outlierist、encoder、scaler）與欄位進行整理，並呈現給使用者使用，使用者可以直接透過此方法存取儲存在內的處理物件。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">processor</span><span class="p">.</span><span class="n">get_config</span><span class="p">(</span>
    <span class="n">col</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">print_config</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="s">'missingist'</span><span class="p">:</span> <span class="p">{</span><span class="s">'gen'</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">PETsARD</span><span class="p">.</span><span class="n">Processor</span><span class="p">.</span><span class="n">Missingist</span><span class="p">.</span><span class="n">Missingist_Drop</span> <span class="n">at</span> <span class="mh">0x14715dcc0</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="s">'age'</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">PETsARD</span><span class="p">.</span><span class="n">Processor</span><span class="p">.</span><span class="n">Missingist</span><span class="p">.</span><span class="n">Missingist_Simple</span> <span class="n">at</span> <span class="mh">0x14715f9d0</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="p">},</span>
 <span class="s">'outlierist'</span><span class="p">:</span> <span class="p">{</span><span class="s">'gen'</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
  <span class="s">'age'</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">PETsARD</span><span class="p">.</span><span class="n">Processor</span><span class="p">.</span><span class="n">Outlierist</span><span class="p">.</span><span class="n">Outlierist_LOF</span> <span class="n">at</span> <span class="mh">0x14715c670</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="p">},</span>
 <span class="s">'encoder'</span><span class="p">:</span> <span class="p">{</span><span class="s">'gen'</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">PETsARD</span><span class="p">.</span><span class="n">Processor</span><span class="p">.</span><span class="n">Encoder</span><span class="p">.</span><span class="n">Encoder_Uniform</span> <span class="n">at</span> <span class="mh">0x14715c1f0</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="s">'age'</span><span class="p">:</span> <span class="bp">None</span>
  <span class="p">},</span>
 <span class="s">'scaler'</span><span class="p">:</span> <span class="p">{</span><span class="s">'gen'</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
  <span class="s">'age'</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">PETsARD</span><span class="p">.</span><span class="n">Processor</span><span class="p">.</span><span class="n">Scaler</span><span class="p">.</span><span class="n">Scaler_MinMax</span> <span class="n">at</span> <span class="mh">0x14715d300</span><span class="o">&gt;</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h4 id="parameters-1">Parameters</h4>
<p><code class="language-plaintext highlighter-rouge">col</code> (<code class="language-plaintext highlighter-rouge">list</code>): The columns the user wants to get the config from. If the list is empty, all columns from the metadata will be selected.</p>

<p><code class="language-plaintext highlighter-rouge">print_config</code> (<code class="language-plaintext highlighter-rouge">bool</code>, default=False): Whether the result should be printed.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">col</code> (<code class="language-plaintext highlighter-rouge">list</code>): 欲取用的欄位。若沒有輸入則視為選擇所有的欄位。</p>

<p><code class="language-plaintext highlighter-rouge">print_config</code> (<code class="language-plaintext highlighter-rouge">bool</code>, default=False): 是否需列印結果。</p>

<h4 id="outputs">Outputs</h4>
<p>(<code class="language-plaintext highlighter-rouge">dict</code>): The config with selected columns.</p>

<hr />
<p>(<code class="language-plaintext highlighter-rouge">dict</code>): 含有選定欄位的設定檔。</p>

<h3 id="set_config"><code class="language-plaintext highlighter-rouge">set_config</code></h3>

<p>Edit the whole config. To maintain the structure of the config, it fills the unspecified processors with <code class="language-plaintext highlighter-rouge">None</code>. If you don’t want to do this, use <code class="language-plaintext highlighter-rouge">update_config</code> instead.</p>

<p>編輯整份設定檔。為了保持設定檔的結構，會將未指定的處理器設為 <code class="language-plaintext highlighter-rouge">None</code>。如果您不想這樣做，請改用 <code class="language-plaintext highlighter-rouge">update_config</code>。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">processor</span><span class="p">.</span><span class="n">set_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="parameters-2">Parameters</h4>
<p><code class="language-plaintext highlighter-rouge">config</code> (<code class="language-plaintext highlighter-rouge">dict</code>): The dict with the same format as the config class.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">config</code> (<code class="language-plaintext highlighter-rouge">dict</code>): 與設定檔格式相同的 <code class="language-plaintext highlighter-rouge">dict</code> 輸入。</p>

<h3 id="update_config"><code class="language-plaintext highlighter-rouge">update_config</code></h3>

<p>Update part of the config.</p>

<p>更改部分設定檔。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">processor</span><span class="p">.</span><span class="n">update_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="parameters-3">Parameters</h4>
<p><code class="language-plaintext highlighter-rouge">config</code> (<code class="language-plaintext highlighter-rouge">dict</code>): The dict with the same format as the config class.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">config</code> (<code class="language-plaintext highlighter-rouge">dict</code>): 與設定檔格式相同的 <code class="language-plaintext highlighter-rouge">dict</code> 輸入。</p>

<h3 id="get_changes"><code class="language-plaintext highlighter-rouge">get_changes</code></h3>

<p>Compare the differences between the current config and the default config.</p>

<p>比較目前設定檔與預設設定檔之間的差異。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">processor</span><span class="p">.</span><span class="n">get_changes</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="outputs-1">Outputs</h4>
<p>(<code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>): A dataframe recording the differences bewteen the current config and the default config.</p>

<hr />
<p>(<code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>): 記錄兩者差異的資料表。</p>

<h2 id="data-processing">Data Processing</h2>

<h3 id="fit"><code class="language-plaintext highlighter-rouge">fit</code></h3>

<p>Learn the structure of the data.</p>

<p>學習資料整體結構。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">processor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">sequence</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</code></pre></div></div>

<h4 id="parameters-4">Parameters</h4>
<p><code class="language-plaintext highlighter-rouge">data</code> (<code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>): The data to be fitted.</p>

<p><code class="language-plaintext highlighter-rouge">sequence</code> (<code class="language-plaintext highlighter-rouge">list</code>): The processing sequence, allowing users to skip procedures and alter the execution order. Avaliable procedures: ‘missingist’, ‘outlierist’, ‘encoder’, ‘scaler’. This is the default sequence if the user doesn’t pass a sequence to the method.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">data</code> (<code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>): 用來學習的資料。</p>

<p><code class="language-plaintext highlighter-rouge">sequence</code> (<code class="language-plaintext highlighter-rouge">list</code>): 處理流程，可允許用戶跳過特定流程或改變執行順序。可用的流程選項：’missingist’、’outlierist’、’encoder’、’scaler’。若用戶未指定流程，則使用此作為預設序列。</p>

<h3 id="transform"><code class="language-plaintext highlighter-rouge">transform</code></h3>

<p>Conduct the data preprocessing procedure.</p>

<p>進行資料前處理。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">transformed</span> <span class="o">=</span> <span class="n">processor</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="parameters-5">Parameters</h4>
<p><code class="language-plaintext highlighter-rouge">data</code> (<code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>): The data to be transformed.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">data</code> (<code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>): 要轉換的資料。</p>

<h4 id="outputs-2">Outputs</h4>
<p>(<code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>): The data after transformation.</p>

<hr />
<p>(<code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>): 轉換完成的資料。</p>

<h3 id="inverse_transform"><code class="language-plaintext highlighter-rouge">inverse_transform</code></h3>

<p>Conduct the data postprocessing procedure.</p>

<p>進行資料後處理。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inverse_transformed</span> <span class="o">=</span> <span class="n">processor</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="parameters-6">Parameters</h4>
<p><code class="language-plaintext highlighter-rouge">data</code> (<code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>): The data to be inverse transformed.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">data</code> (<code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>): 要轉換的資料。</p>

<h4 id="outputs-3">Outputs</h4>
<p>(<code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>): The data after inverse transformation.</p>

<hr />
<p>(<code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>): 轉換完成的資料。</p>]]></content><author><name>NICS - PETs</name></author><summary type="html"><![CDATA[Processor]]></summary></entry><entry><title type="html">Scaler</title><link href="http://localhost:4000/PETsARD-Gitbook/Scaler.html" rel="alternate" type="text/html" title="Scaler" /><published>2024-01-05T00:00:00+08:00</published><updated>2024-01-05T00:00:00+08:00</updated><id>http://localhost:4000/PETsARD-Gitbook/Scaler</id><content type="html" xml:base="http://localhost:4000/PETsARD-Gitbook/Scaler.html"><![CDATA[<h1 id="scaler">Scaler</h1>

<p>The <code class="language-plaintext highlighter-rouge">Scaler</code> module is designed to standardise and scale data using various methods. Four scaling methods are provided:</p>

<p><code class="language-plaintext highlighter-rouge">Scaler</code> 模組旨在使用各種方法對數據進行標準化和縮放。套件中提供了四種縮放方法：</p>

<h2 id="scaler_standard-standardise-the-data"><code class="language-plaintext highlighter-rouge">Scaler_Standard</code>: Standardise the data</h2>

<p>This method applies <code class="language-plaintext highlighter-rouge">StandardScaler</code> from the sklearn library, transforming the data to have a mean of 0 and a standard deviation of 1.</p>

<p>此方法使用 sklearn 中的 <code class="language-plaintext highlighter-rouge">StandardScaler</code>，將資料轉換為平均值為 0、標準差為 1 的樣態。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Scaler</span> <span class="kn">import</span> <span class="n">Scaler_Standard</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">Scaler_Standard</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="scaler_zerocenter-scale-the-data-to-have-the-mean0"><code class="language-plaintext highlighter-rouge">Scaler_ZeroCenter</code>: Scale the data to have the mean=0</h2>

<p>Utilising <code class="language-plaintext highlighter-rouge">StandardScaler</code> from sklearn, this method centres the transformed data around a mean of 0.</p>

<p>利用 sklearn 中的 <code class="language-plaintext highlighter-rouge">StandardScaler</code>，將資料轉換為平均值為 0 的樣態。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Scaler</span> <span class="kn">import</span> <span class="n">Scaler_ZeroCenter</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">Scaler_ZeroCenter</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="scaler_minmax-scale-the-data-to-have-the-range-0-1"><code class="language-plaintext highlighter-rouge">Scaler_MinMax</code>: Scale the data to have the range [0, 1]</h2>

<p>By applying <code class="language-plaintext highlighter-rouge">MinMaxScaler</code> from sklearn, this method scales the data to fit within the range [0, 1].</p>

<p>利用 sklearn 中的 <code class="language-plaintext highlighter-rouge">MinMaxScaler</code>，將資料轉換至 [0, 1] 的範圍。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Scaler</span> <span class="kn">import</span> <span class="n">Scaler_MinMax</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">Scaler_MinMax</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="scaler_log-scale-the-data-by-log-transformation"><code class="language-plaintext highlighter-rouge">Scaler_Log</code>: Scale the data by log transformation</h2>

<p>This method requires the input data to be positive. It applies log transformation to mitigate the impact of extreme values.</p>

<p>此方法僅能在資料為正的情形可用，可用於減緩極端值對整體資料的影響。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD.Processor.Scaler</span> <span class="kn">import</span> <span class="n">Scaler_Log</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">Scaler_Log</span><span class="p">()</span>
</code></pre></div></div>]]></content><author><name>NICS - PETs</name></author><summary type="html"><![CDATA[Scaler]]></summary></entry><entry><title type="html">Evaluator anonymeter</title><link href="http://localhost:4000/PETsARD-Gitbook/Evaluator-Anonymeter.html" rel="alternate" type="text/html" title="Evaluator anonymeter" /><published>2024-01-03T00:00:00+08:00</published><updated>2024-01-03T00:00:00+08:00</updated><id>http://localhost:4000/PETsARD-Gitbook/Evaluator%20-%20Anonymeter</id><content type="html" xml:base="http://localhost:4000/PETsARD-Gitbook/Evaluator-Anonymeter.html"><![CDATA[<h1 id="anonymeter">Anonymeter</h1>

<p><code class="language-plaintext highlighter-rouge">Anonymeter</code> is a comprehensive Python library that evaluates various aspects of privacy risks in synthetic tabular data, including <strong>Singling Out</strong>, <strong>Linkability</strong>, and <strong>Inference</strong> risks.</p>

<p>These three points are based on the criteria established by <a href="https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2014/wp216_en.pdf">Article 29 Data Protection Working Party (WP29)</a> under the Data Protection Directive (Directive 95/46), as outlined in their written guidance published in 2014, for evaluating the effectiveness standards of anonymization techniques. <code class="language-plaintext highlighter-rouge">Anonymeter</code>` received positively reviewed from the <a href="https://www.cnil.fr/en/home">Commission Nationale de l’Informatique et des Libertés (CNIL)</a> on February 13, 2023, acknowledging its ability to effectively evaluate the three standards of anonymization effectiveness in synthetic data. CNIL recommends using this library to evaluate the risk of re-identification.</p>

<p>Therefore, <code class="language-plaintext highlighter-rouge">PETsARD</code> includes built-in calls to <code class="language-plaintext highlighter-rouge">Anonymeter</code>. For more details, please refer to its official GitHub: <a href="https://github.com/statice/anonymeter">statice/anonymeter</a></p>

<p><code class="language-plaintext highlighter-rouge">Anonymeter</code> 是一個全面評估合成表格資料中不同層面隱私風險的 Python 函式庫，包括<strong>指認性</strong>(<strong>Singling Out</strong>)、<strong>連結性</strong>(<strong>Linkability</strong>)、和<strong>推斷性</strong>(<strong>Inference</strong>)風險。</p>

<p>此三點是根據歐盟個人資料保護指令第29條設立之<a href="https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2014/wp216_en.pdf">個資保護工作小組</a>(WP29)，於 2014 年發布的書面指引中所列出，用於評估匿名化技術的有效性標準。而 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 於 2023 年 02 月 13 日受到<a href="https://www.cnil.fr/en/home">法國國家資訊自由委員會</a>(CNIL)的正面評價，認為此工具能有效評估合成資料的匿名化有效性三個標準，並建議使用本函式庫來評估資料被重新識別的風險。</p>

<p>因此 <code class="language-plaintext highlighter-rouge">PETsARD</code>整合了對 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 的使用。更多詳情請參閱其官方 GitHub：<a href="https://github.com/statice/anonymeter">statice/anonymeter</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">PETsARD</span> <span class="kn">import</span> <span class="n">Evaluator</span>
<span class="nb">eval</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">(</span>
    <span class="n">evaluating_method</span><span class="o">=</span><span class="s">'anonymeter-singlingout-univariate'</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s">'ori'</span><span class="p">:</span> <span class="n">train_data</span><span class="p">,</span>
          <span class="s">'syn'</span><span class="p">:</span> <span class="n">synethsizing_data</span><span class="p">,</span>
          <span class="s">'control'</span><span class="p">:</span> <span class="n">validation_data</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="nb">eval</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="nb">eval</span><span class="p">.</span><span class="n">Evaluator</span><span class="p">.</span><span class="n">evaluation</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'Risk': 0.0,
 'Risk_CI_btm': 0.0,
 'Risk_CI_top': 0.0013568577126237004,
 'Attack_Rate': 0.0009585236406264672,
 'Attack_Rate_err': 0.0009585236406264671,
 'Baseline_Rate': 0.0009585236406264672,
 'Baseline_Rate_err': 0.0009585236406264671,
 'Control_Rate': 0.0009585236406264672,
 'Control_Rate_err': 0.0009585236406264671}
</code></pre></div></div>

<hr />

<h2 id="common-inherited-from-evaluator">Common: Inherited from Evaluator</h2>

<p>In the <code class="language-plaintext highlighter-rouge">Anonymeter</code> module, which is embedded within the <code class="language-plaintext highlighter-rouge">Evaluator</code> module and inherits parameters from it. Additionally, “Anonymeter” follows a standardized output format.</p>

<p><code class="language-plaintext highlighter-rouge">Anonymeter</code> 內嵌在 <code class="language-plaintext highlighter-rouge">Evaluator</code> 模組、並繼承其參數。同時 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 也有統一的輸出格式。</p>

<hr />

<h3 id="evaluating_method">evaluating_method</h3>

<p><code class="language-plaintext highlighter-rouge">evaluating_method</code> (<code class="language-plaintext highlighter-rouge">str</code>): evaluating method 評估方法</p>

<p>The parameter <code class="language-plaintext highlighter-rouge">evaluating_method</code>, which is inherited from Evaluator, determines which evaluation module to invoke. Input values starting with ‘anonymeter-‘ can call the following methods of <code class="language-plaintext highlighter-rouge">Anonymeter</code> (case-insensitive):</p>

<p>繼承自 <code class="language-plaintext highlighter-rouge">Evaluator</code> 的參數評估方法 (<strong><code class="language-plaintext highlighter-rouge">evaluating_method</code></strong>) 能決定呼叫哪種評估模組，其中以 <strong>‘anonymeter-‘</strong> 開頭的輸入值便能調用 <code class="language-plaintext highlighter-rouge">Anonymeter</code>，有以下方法（大小寫不分）：</p>

<ul>
  <li><strong>‘anonymeter-singlingout-univariate’</strong>: Singling Out risk - Univariate mode
  指認性風險 - 單變數模式</li>
  <li><strong>‘anonymeter-linkability’</strong>: Linkability risk 連結性風險</li>
  <li><strong>‘anonymeter-inference’</strong>: Inference risks 推斷性風險</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">evaluating_method</span><span class="o">=</span><span class="s">'anonymeter-singlingout-univariate'</span> <span class="c1"># Singling Out risk
</span><span class="n">evaluating_method</span><span class="o">=</span><span class="s">'anonymeter-linkability'</span>            <span class="c1"># Linkability risk
</span><span class="n">evaluating_method</span><span class="o">=</span><span class="s">'anonymeter-inference'</span>              <span class="c1"># Inference risk
</span></code></pre></div></div>

<hr />

<h3 id="data">data</h3>

<p><code class="language-plaintext highlighter-rouge">data</code> (<code class="language-plaintext highlighter-rouge">Dict[str, pd.DataFrame]</code>): input data 輸入資料</p>

<p><code class="language-plaintext highlighter-rouge">data</code> is a dictionary with a specific format, containing specific keys, and each value is a Pandas DataFrame.</p>

<p><code class="language-plaintext highlighter-rouge">data</code> 是具特定格式的字典，有特定的鍵，並且每個值都是一個 Pandas DataFrame。</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ori</code>: <code class="language-plaintext highlighter-rouge">Original Train data</code>. A portion of the original data used to generate synthetic data (<code class="language-plaintext highlighter-rouge">syn</code>).</li>
  <li><code class="language-plaintext highlighter-rouge">syn</code>: <code class="language-plaintext highlighter-rouge">Synethsizing data</code>. Synthetic data generated from <code class="language-plaintext highlighter-rouge">ori</code>.</li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">control</code>: <code class="language-plaintext highlighter-rouge">Validation data</code>. Another portion of the original data not used for generating synthetic data and kept confidential.</p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">ori</code>：<code class="language-plaintext highlighter-rouge">原始訓練資料</code>。被用於生成合成資料 (<code class="language-plaintext highlighter-rouge">syn</code> )的原始資料部份。</li>
  <li><code class="language-plaintext highlighter-rouge">syn</code>：<code class="language-plaintext highlighter-rouge">合成資料</code>。是用 <code class="language-plaintext highlighter-rouge">ori</code> 生成得來。</li>
  <li><code class="language-plaintext highlighter-rouge">control</code>：<code class="language-plaintext highlighter-rouge">驗證資料</code>。控制未用於生成合成資料、訊息未洩漏的原始資料部份。</li>
</ul>

<hr />

<h3 id="n_attacks">n_attacks</h3>

<p><code class="language-plaintext highlighter-rouge">n_attacks</code> (<code class="language-plaintext highlighter-rouge">int</code>, default=2000): Number of target records for specific attack 特定攻擊的攻擊目標數</p>

<p><code class="language-plaintext highlighter-rouge">n_attacks</code> is the parameter in <code class="language-plaintext highlighter-rouge">Anonymeter</code> that specifies how many times this particular attack will be executed. A higher number will reduce the statistical uncertainties on the results, at the expense of a longer computation time. In fact, each type of attack has a potential maximum limit on number of attacks:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Singling Out</code>: Number of distinct <code class="language-plaintext highlighter-rouge">queries</code>. A <code class="language-plaintext highlighter-rouge">query</code> is a specific condition-based searching command matching only one record in a certain field, achieving <code class="language-plaintext highlighter-rouge">Singling Out</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">Linkability</code> and <code class="language-plaintext highlighter-rouge">Inference</code>: Number of rows in the training dataset. The implementation of these two attack methods is to sample from the <code class="language-plaintext highlighter-rouge">Original Train data</code>.</li>
</ul>

<p>If a value exceeding the potential maximum attack count is set, <code class="language-plaintext highlighter-rouge">Anonymeter</code> will issue a warning and disregard the remaining counts.</p>

<p>Therefore, we plan to determine the default upper limit automatically in future release, to ensure comprehensive testing for <code class="language-plaintext highlighter-rouge">PETsARD</code>. If users find that the computation time is too long during a trial, it is recommended to reduce reduce it to the attack numbers provided in the official <code class="language-plaintext highlighter-rouge">Anonymeter</code> examples: 500 for <code class="language-plaintext highlighter-rouge">Singling Out</code>, and 2,000 for <code class="language-plaintext highlighter-rouge">Linkability</code> and <code class="language-plaintext highlighter-rouge">Inference</code>.</p>

<p><code class="language-plaintext highlighter-rouge">n_attacks</code> 代表著 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 將執行這種攻擊多少次的參數，較高的數量會降低結果的統計不確定性，但會增加運算時間。事實上各種攻擊方式都存在有潛在的攻擊次數上限：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Singling Out</code>：不重複<code class="language-plaintext highlighter-rouge">搜索語句</code> (<code class="language-plaintext highlighter-rouge">queries</code>)的數量。<code class="language-plaintext highlighter-rouge">搜索語句</code>是特定的條件查詢式，使得該語句能在某欄位中僅對應到一筆資料，達到<code class="language-plaintext highlighter-rouge">指認性</code>。</li>
  <li><code class="language-plaintext highlighter-rouge">Linkability</code> 跟 <code class="language-plaintext highlighter-rouge">Inference</code>：訓練資料集行數。這兩種攻擊方式背後實現的原理，是對<code class="language-plaintext highlighter-rouge">原始訓練資料</code>進行抽樣。</li>
</ul>

<p>如果設定了超過潛在上限攻擊次數的值，則 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 將回傳警告，並忽略剩下的次數。</p>

<p>因此，在未來的更新中，我們計劃能預設自動判斷攻擊的上限，以確保 <code class="language-plaintext highlighter-rouge">PETsARD</code> 的測試足夠全面。如果使用者在試用中發現運算時間過長，可以暫時將攻擊數調低，而 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 官方範例中設定的值為：<code class="language-plaintext highlighter-rouge">Singling Out</code> 為 500，<code class="language-plaintext highlighter-rouge">Linkability</code> 跟 <code class="language-plaintext highlighter-rouge">Inference</code> 為 2,000。</p>

<hr />

<h3 id="eval">.eval()</h3>

<p>Execute the evaluation. This method is inherited from <code class="language-plaintext highlighter-rouge">Evaluator</code>, and does not require nor accept any parameters.”</p>

<p>執行評估。繼承自 <code class="language-plaintext highlighter-rouge">Evaluator</code> 的方法，不需也不接受任何參數。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">eval</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">(...)</span>
<span class="nb">eval</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
</code></pre></div></div>

<hr />

<h4 id="output">output</h4>

<p><code class="language-plaintext highlighter-rouge">self.Evaluator.evaluation</code> (<code class="language-plaintext highlighter-rouge">Dict[str, float]</code>): evaluation 評估結果</p>

<p>The evaluation results are stored directly as a dictionary in <code class="language-plaintext highlighter-rouge">self.Evaluator.evaluation</code> with a specific format, and all values are floating-point numbers within the range of 0.0 to 1.0:</p>

<p>評估結果直接作為字典儲存在 <code class="language-plaintext highlighter-rouge">self.Evaluator.evaluation</code> 內，具有特定格式，且值都是範圍為 0.0 ~ 1.0 的浮點數：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'Risk': 0.0,
 'Risk_CI_btm': 0.0,
 'Risk_CI_top': 0.0,
 'Attack_Rate': 0.0,
 'Attack_Rate_err': 0.0,
 'Baseline_Rate': 0.0,
 'Baseline_Rate_err': 0.0,
 'Control_Rate': 0.0,
 'Control_Rate_err': 0.0}
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>key</th>
      <th>Definition</th>
      <th>定義</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Risk</td>
      <td><strong>Privacy Risk</strong></td>
      <td><strong>隱私風險</strong></td>
    </tr>
    <tr>
      <td>Risk_CI_btm</td>
      <td>The <strong>bottom</strong> of confidence interval of Privacy Risk</td>
      <td>隱私風險信賴區間<strong>下界</strong></td>
    </tr>
    <tr>
      <td>Risk_CI_top</td>
      <td>The <strong>top</strong> of confidence interval of Privacy Risk</td>
      <td>隱私風險信賴區間<strong>上界</strong></td>
    </tr>
    <tr>
      <td>Attack_Rate</td>
      <td>The Main Privacy <strong>Attack</strong> rate</td>
      <td>主要隱私<strong>攻擊</strong>率</td>
    </tr>
    <tr>
      <td>Attack_Rate_err</td>
      <td>Error of Main Privacy Attack rate</td>
      <td>主要隱私<strong>攻擊</strong>率誤差</td>
    </tr>
    <tr>
      <td>Baseline_Rate</td>
      <td>The <strong>Baseline</strong> Privacy Attack rate</td>
      <td><strong>基線</strong>隱私攻擊率</td>
    </tr>
    <tr>
      <td>Baseline_Rate_err</td>
      <td>Error of the Baseline Privacy Attack rate</td>
      <td><strong>基線</strong>隱私攻擊率誤差</td>
    </tr>
    <tr>
      <td>Control_Rate</td>
      <td>The <strong>Control</strong> Privacy Attack rate</td>
      <td><strong>控制</strong>隱私攻擊率</td>
    </tr>
    <tr>
      <td>Control_Rate_err</td>
      <td>Error of the Control Privacy Attack rate</td>
      <td><strong>控制</strong>隱私攻擊率誤差</td>
    </tr>
  </tbody>
</table>

<ul>
  <li><strong>Privacy Risk</strong> is a high level estimation of specific privacy risk obtained from the attack rates mentioned below. Its formula is as follows.
    <ul>
      <li>The numerator represents the attacker’s exploitation of synthetic data, as the <strong>Main Attack</strong> to excess of the <strong>Control Attack</strong> success rate.</li>
      <li>The denominator is the normalization factor by <strong>1 minus Control Attack</strong>, representing the signifying the effectiveness of Main Attack relative to the Perfect Attacker (100%), to calculate the difference in the numerator.</li>
      <li><strong>Perfect Attacker</strong> is a concept that represents an all-knowing, all-powerful attacker. In our evaluating, this means they have a 100% chance of a successful attack. Therefore, the underlying idea behind this score is that <strong>Main Attack</strong>, due to their access to synthesized data, have a higher success rate compared to <strong>Control Attack</strong>. However, the proportion of this success rate increase relative to the <strong>Perfect Attacker’s</strong> perfect success rate is what matters.</li>
      <li>Ranging from zero to one, with higher numbers indicating higher privacy risk, the information provided by synthetic data brings attackers closer to that of a perfect attacker.</li>
    </ul>
  </li>
  <li><strong>隱私風險</strong>是綜合下述攻擊率而得到的對特定隱私風險的評估，其公式如下。
    <ul>
      <li>分子代表攻擊者利用合成資料的攻擊、也就是<strong>主要攻擊</strong>對<strong>控制攻擊</strong>成功率的改進。</li>
      <li>分母則以 <strong>1 減 控制攻擊</strong> 代表<strong>主要攻擊</strong>相對於完美攻擊者 (100%) 的效果，作為歸一化因子計算分子的差異。</li>
      <li><strong>完美攻擊者</strong>是一個概念，代表著一個全知全能的攻擊者，在我們的驗測中，這表示他有 100% 的成功攻擊機會。因此，這個分數背後的思想是，<strong>主要攻擊</strong>因為取得合成資料，因此相對於控制攻擊有更高的成功率，但這個成功率提升，相對於<strong>完美攻擊者</strong>完美的成功率提升，所佔的比例有多少。</li>
      <li>零到一，數字越大代表隱私的風險越高，合成資料提供的資訊能使攻擊者越接近完美攻擊者。</li>
    </ul>
  </li>
</ul>

\[PrivacyRisk = \frac{AttackRate_{Main}-AttackRate_{Control}}{1-AttackRate_{Control}}\]

<ul>
  <li><strong>Attack Rate</strong> refers to the proportion of <strong>successful</strong> executions of a specific attack, whether by malicious or honest-but-curious users. Also called <strong>Success Attack Rate</strong>.
    <ul>
      <li>Since it is assumed that each attack is independent, and attacks are only concerned with either success or failure, they can be modeled as Bernoulli trials. The <strong>Wilson Score Interval</strong> can be used to estimate the binomial success rate and adjusted confidence interval as below. The default of confidence level is 95%.</li>
      <li>From zero to one, a higher number indicates a higher success rate for that specific attack.</li>
    </ul>
  </li>
  <li><strong>攻擊率</strong>意指無論是由惡意還是誠實但好奇的使用者<strong>成功</strong>執行特定攻擊的比例。又被稱為<strong>成功攻擊率</strong>。
    <ul>
      <li>由於假設每次攻擊都是獨立的，而攻擊只關心成功或失敗兩種結果，因此它們可以被建模為伯努利試驗。可以使用<strong>威爾遜分數區間</strong>來估算二項式成功率與調整後的信賴區間如下。預設信心水準為 95%。</li>
      <li>零到一，數字越大代表該特定攻擊的成功率越高。</li>
    </ul>
  </li>
</ul>

\[AttackRate =
\frac{N_{ Success}+\frac{ {Z}^{2} }{2} }{ N_{Total}+{Z}^{2} }\quad\left
\{\begin{matrix}
N_{Success} &amp; Number\;of\;Success\;Attack\\
N_{Total} &amp; Number\;of\;Total\;Attack\\
Z &amp; Z\;score\;of\;confidence\;level
\end{matrix}
\right.\]

<ul>
  <li><strong>Main Attack Rate</strong> refers to the attack rate inferred from the training data records using synthetic data.</li>
  <li><strong>Baseline Attack Rate</strong> or <strong>Naive Attack Rate</strong> is the success rate inferred from the training data records using random guessing.
    <ul>
      <li>The Baseline Attack Rate provides a benchmark for measuring the strength of attacks. If the <strong>Main Attack Rate is less than or equal to the Baseline Attack Rate</strong>, it indicates the Main Attack modeling is less effective than random guessing. In this case, the result is meaningless, and the <code class="language-plaintext highlighter-rouge">Anonymeter</code> library will issue a warning, suggesting that users should exclude such results from their analysis to avoid incorrectly reporting a “no risk” outcome. <code class="language-plaintext highlighter-rouge">PETsARD</code> will directly return the result, and users are responsible for their own filtering.
        <ul>
          <li>The possibility of the Main Attack being inferior to random includes scenarios with insufficient attack occurrences (<code class="language-plaintext highlighter-rouge">n_attacks</code>), attackers having too little auxiliary information (e.g., misconfigured <code class="language-plaintext highlighter-rouge">aux_cols</code> in the <code class="language-plaintext highlighter-rouge">Inference</code> function), or issues with the data itself (e.g., too few columns, too few records, or too few combinations of categorical variables).</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Control Attack Rate</strong> is the attack rate inferred from the control data records using synthetic data.</p>
  </li>
  <li><strong>主要攻擊率</strong> (<strong>Main Attack Rate</strong>) 是指使用合成資料來推斷訓練資料紀錄的攻擊率</li>
  <li><strong>基線攻擊率</strong> (<strong>Baseline Attack Rate</strong>) 或是<strong>天真攻擊率</strong> (<strong>Naive Attack Rate</strong>) 則是使用隨機猜測來推斷訓練資料紀錄的成功率
    <ul>
      <li>基線攻擊率提供了衡量攻擊強度的基準值，如果<strong>主要攻擊率小於等於基線攻擊率</strong>，則代表主要攻擊的建模、其效果還不如隨機猜測，此時結果沒有意義，<code class="language-plaintext highlighter-rouge">Anonymeter</code>函式庫會在回傳結果的同時。警告用戶應該從分析中加以排除，避免錯誤的報告成「沒有風險」的結果。<code class="language-plaintext highlighter-rouge">PETsARD</code> 會直接回傳結果，請用戶自行篩選。</li>
      <li>導致主要攻擊率不如隨機猜測的可能性，包括攻擊次數過少 (<code class="language-plaintext highlighter-rouge">n_attacks</code>)，攻擊者可獲得的輔助資訊過少（例如 <code class="language-plaintext highlighter-rouge">Inference</code> 功能中 <code class="language-plaintext highlighter-rouge">aux_cols</code> 設定錯誤），或者資料本身存在問題（例如欄位數量不足、記錄太少、或者類別變數的排列組合過於有限等情況）。</li>
    </ul>
  </li>
  <li><strong>控制攻擊率</strong> (<strong>Control Attack Rate</strong>) 則是使用合成資料來推斷控制資料紀錄的攻擊率</li>
</ul>

<hr />

<h2 id="evaluating_methodanonymeter-singlingout-univariate">evaluating_method=’anonymeter-singlingout-univariate’</h2>

<p><strong>Singling Out risk</strong> represents the possibility of still being able to identify a particular individual, their part, or complete records, even after any Privacy-Enhancing Techniques have been applied. In the example from the <code class="language-plaintext highlighter-rouge">Anonymeter</code>, it refers to the scenario where “there is only one person with attributes X, Y, and Z”. In other words, attackers may attempt to identify specific individuals.</p>

<p>The paper on <code class="language-plaintext highlighter-rouge">Anonymeter</code> specifically mentions: “It’s important to note that singling out does not imply re-identification. Yet the ability to isolate an
individual is often enough to exert control on that individual, or to
mount other privacy attacks.”</p>

<p>Currently, only single variable mode of Singling Out evaluating (<code class="language-plaintext highlighter-rouge">univariate</code>) is implemented. In future updates, multi variables mode (<code class="language-plaintext highlighter-rouge">multivariate</code>) will be included to support singling out attacks by multiple attributes combination.</p>

<p><strong>指認性風險</strong>表示即便經過隱私強化技術處理，仍有多大的可能性去識別出來<strong>特定個體</strong>，其部分或完整記錄的可能性。以 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 的舉例，就是「只有一個人同時擁有著 X、Y、與 Z 特徵」。換句話說，攻擊者可以嘗試辨識出特定的個體。</p>

<p><code class="language-plaintext highlighter-rouge">Anonymeter</code> 的論文有特別提到：「值得注意的是，指認不等於重新識別。然而，能夠單獨辨識一個體通常足以對該個體施加控制，或者進行其他隱私攻擊。」</p>

<p>目前僅實作單變數指認性驗測 (<code class="language-plaintext highlighter-rouge">univariate</code>)，未來更新將納入指認性驗測的多變數模式 (<code class="language-plaintext highlighter-rouge">multivariate</code>)，支援結合多種屬性的指認攻擊。</p>

<hr />

<h3 id="n_cols">n_cols</h3>

<p><code class="language-plaintext highlighter-rouge">n_cols</code> (<code class="language-plaintext highlighter-rouge">int</code>): Number of attributes used in the attacker queries 攻擊中所使用的屬性數量</p>

<p>Only applicable to multi-variable mode (<code class="language-plaintext highlighter-rouge">multivariate</code>), not implemented</p>

<p>僅適用於多變數模式 (<code class="language-plaintext highlighter-rouge">multivariate</code>)，未實作。</p>

<hr />

<h2 id="evaluating_methodanonymeter-linkability">evaluating_method=’anonymeter-linkability’</h2>

<p><strong>Linkability risk</strong> represents the possibility that, even after Privacy-Enhancing Techniques have been applied, or when records exist in different databases, at least two records about the same individual or group of individuals can still be <strong>linked</strong> together. In the example from the <code class="language-plaintext highlighter-rouge">Anonymeter</code>, it refers to the scenario where “records A and B belong to the same person”. In particular, even if attackers <strong>cannot single out</strong> the specific individual’s identity, they may still attempt to establish links between records through shared features or information.</p>

<p><strong>連結性風險</strong>表示即使經過隱私強化技術處理、或是存在不同的資料庫中，仍有多大的可能，將至少兩條關於同一個人或一組人的記錄<strong>連結</strong>在一起。以 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 的舉例，就是「紀錄 A 與紀錄 B 屬於同一個人」。具體來說，即使攻擊者<strong>無法指認</strong>具體的個體身份，他們仍可能嘗試透過某些共同特徵或資訊，來建立記錄之間的關聯。</p>

<hr />

<h3 id="aux_cols">aux_cols</h3>

<p><code class="language-plaintext highlighter-rouge">aux_cols</code> (<code class="language-plaintext highlighter-rouge">Tuple[List[str], List[str]]</code>) Columns of auxiliary information 輔助資訊欄位</p>

<p>The pattern of Linkability attacks assumes that attackers, whether malicious or honest-but-curious users, possesses two sets of non-overlapping <strong>original train data</strong> columns. When composite synthesized data involving these two sets of data columns is released, the attacker can use the synthetic data to link to their own original data, to determine whether the data from one dataset belongs to certain records in another dataset. In this context, the auxiliary data columns <code class="language-plaintext highlighter-rouge">aux_cols</code> are the two pieces of information the attackers own.</p>

<p>For example, a medical center intends to release synthesized data from their heart disease research, which includes age, gender, postal code, and the number of heart attacks. Meanwhile, the attacker may have obtained real population data, such as gender and postal codes, from public sources or data leaks, along with real epidemiological data, such as age and the frequency of heart attacks, in their original form or in proportion. In this case, aux_cols` would be as follows:</p>

<p>連結性攻擊的攻擊樣態，是假定攻擊者，無論惡意還是誠實但好奇的使用者，擁有兩部分不重疊的<strong>原始訓練資料</strong>欄位，而當涉及這兩份資料欄位的綜合性合成資料被釋出，攻擊者便可以用合成資料<strong>連結</strong>到自己手中的原始資料，來推測哪些資料是互相對應的。此時輔助資料欄位 <code class="language-plaintext highlighter-rouge">aux_cols</code> 便是這兩批資料所各自包含的資料欄位。</p>

<p>舉例來說，某間醫學中心要釋出自己心臟病研究的合成資料，其中包括了年齡、性別、郵遞區號、心臟病發次數，而攻擊者可能已經從公開資料或資料洩漏中，得知了真實的戶政資料：性別與郵遞區號、以及真實的流行病學資料：年紀與心臟病發次數，兩種資料的比例或原始資料。那 <code class="language-plaintext highlighter-rouge">aux_cols</code> 便如下所示：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">aux_cols</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s">'sex'</span><span class="p">,</span> <span class="s">'zip_code'</span><span class="p">],</span> <span class="c1"># public
</span>    <span class="p">[</span><span class="s">'age'</span><span class="p">,</span> <span class="s">'heart_attack_times'</span><span class="p">]</span> <span class="c1"># private
</span><span class="p">]</span>
</code></pre></div></div>

<p>The potential linkage attack method in this case may be that “due to the close similarity between the real population data and real epidemiological data with the values in this synthesized data, it is possible to link the age and the frequency of heart attacks of a certain group of people from the population data, or link the gender and place of residence of a certain group of people from the epidemiological data.”</p>

<p><code class="language-plaintext highlighter-rouge">aux_cols</code> involves domain-specific knowledge about the dataset, so neither <code class="language-plaintext highlighter-rouge">PETsARD</code> nor <code class="language-plaintext highlighter-rouge">Anonymeter</code> provide default values for it. Users need to configure it themselves based on their understanding of the dataset. In future updates, following the experimental approach outlined in the <code class="language-plaintext highlighter-rouge">Anonymeter</code> paper, different amounts of auxiliary information will be considered. The attacker’s auxiliary information will be sampled from “only two columns” to “the maximum number of columns in the dataset,” and these options will be provided as default values.</p>

<p>而此時潛在的連結性攻擊方式，便可能是「由於真實戶政資料跟真實流行病學資料，都跟此合成資料的數值差異足夠接近，於是可以由戶政資料連結出某群人的年紀與心臟病發次數，或是由流行病學資料連結出某群人的性別與居住地」。</p>

<p><code class="language-plaintext highlighter-rouge">aux_cols</code> 涉及對資料集的專業知識，故 <code class="language-plaintext highlighter-rouge">PETsARD</code>  跟 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 均不設預設值，須由使用者自行設定。在未來更新中，也將依照 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 論文的實驗方式，考量不同數量的輔助資訊，將攻擊者的輔助資訊從「僅有兩列」到「資料集的最大列數」所有抽樣方式都遍歷考慮一次，提供這樣的預設值。</p>

<hr />

<h3 id="n_neighbors">n_neighbors</h3>

<p><code class="language-plaintext highlighter-rouge">n_neighbors</code> (<code class="language-plaintext highlighter-rouge">int</code>, default=10): The N closest neighbors considered for the link search 連結搜索時考慮的前 N 個最近鄰居數量</p>

<p>To handle mixed data types, <code class="language-plaintext highlighter-rouge">Anonymeter</code> uses Gower’s Distance/Similarity:</p>

<ul>
  <li>Numeric  variables: Gower’s Distance is the absolute difference between the normalized values.</li>
  <li>Categorical variables: Gower’s Distance is 1 if the values are not equal.</li>
</ul>

<p>After combining all attributes, the Manhattan Distance is calculated, and return the nearest N neighbors. So, in the context of <code class="language-plaintext highlighter-rouge">Linkability risk</code>, <code class="language-plaintext highlighter-rouge">n_neighbors</code> represents how close the two sets of data from the same person need to be linked to be considered a successful linkability attack.</p>

<p><code class="language-plaintext highlighter-rouge">Anonymeter</code> does not provide a recommended value for <code class="language-plaintext highlighter-rouge">n_neighbors</code>. In an example, a value of 10 is used, but the default value in the code is 1. <code class="language-plaintext highlighter-rouge">PETsARD</code> uses 10 as the default value.</p>

<p>為了處理混合資料類型的資料，<code class="language-plaintext highlighter-rouge">Anonymeter</code> 使用的是高爾距離/高爾相似性 (Gower’s Distance/Similarity)：</p>

<ul>
  <li>數值型變數：高爾距離為歸一化後兩者相差的絕對值</li>
  <li>類別型變數：只要不相等，高爾距離即為 1</li>
</ul>

<p>綜合所有屬性之後計算其曼哈頓距離，最後返回最近的 N 個鄰居。於是 <code class="language-plaintext highlighter-rouge">n_neighbors</code> 在 <code class="language-plaintext highlighter-rouge">連結性風險</code> 上的意思，是指同一個人的兩批資料，要在多近的距離內被連結到，才算是連結性攻擊成功。</p>

<p><code class="language-plaintext highlighter-rouge">Anonymeter</code> 並沒有給出 <code class="language-plaintext highlighter-rouge">n_neighbors</code> 的建議值，在範例中使用 10、但在程式裡預設值是 1，<code class="language-plaintext highlighter-rouge">PETsARD</code> 使用 10 作為預設值。</p>

<hr />

<h2 id="evaluating_methodanonymeter-inference">evaluating_method=’anonymeter-inference’</h2>

<p><strong>Inference risk</strong> represents the possibility that, even after Privacy-Enhancing Techniques have been applied, there is still a significant chance of deducing the value of an attribute from the values of a set of other attributes. In the example from the <code class="language-plaintext highlighter-rouge">Anonymeter</code>, it refers to the scenario where “a person with attributes X and Y also have Z”. To phrase it differently, even if attackers <strong>cannot single out</strong> individual identities or <strong>cannot link</strong> different records, they may still be able to deduce specific information via statistical analysis or other methods.</p>

<p><strong>推斷性風險</strong>代表的是即使經過隱私強化技術處理，仍有多大的可能，從一組其他的特徵中推斷出某個特徵的值。以 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 的舉例，就是「擁有特徵 X 和特徵 Y 的人也擁有特徵 Z」。也就是說，即使攻擊者<strong>無法指認</strong>個體身分、也無法<strong>連結</strong>不同紀錄，攻擊者仍可以透過統計分析或其他方法來推斷出特定的資訊。</p>

<hr />

<h3 id="secret-and-aux_cols">secret and aux_cols</h3>

<p><code class="language-plaintext highlighter-rouge">secret</code> (<code class="language-plaintext highlighter-rouge">str</code>) Column(s) of secret information 秘密資訊欄位</p>

<p><code class="language-plaintext highlighter-rouge">aux_cols</code> (<code class="language-plaintext highlighter-rouge">List[str]</code>) Columns of auxiliary information 輔助資訊欄位</p>

<p>In the context of Inference risk, the parameters <code class="language-plaintext highlighter-rouge">secret</code> and <code class="language-plaintext highlighter-rouge">aux_cols</code> go hand in hand. <code class="language-plaintext highlighter-rouge">secret</code> represents the attribute that is kept confidential, and in this scenario, <code class="language-plaintext highlighter-rouge">aux_cols</code> are the attributes other than secret that are considered to provide auxiliary information to the attacker.</p>

<p>The example provided by <code class="language-plaintext highlighter-rouge">Anonymeter</code> suggests the following configuration:</p>

<p>在推斷性風險中，<code class="language-plaintext highlighter-rouge">secret</code> 與 <code class="language-plaintext highlighter-rouge">aux_cols</code> 參數是一體兩面的，secret 代表被保密的屬性 (attribute)，此時 <code class="language-plaintext highlighter-rouge">aux_cols</code> 則是除了 <code class="language-plaintext highlighter-rouge">secret</code> 以外的屬性、都被認為可以提供攻擊者輔助資訊。</p>

<p><code class="language-plaintext highlighter-rouge">Anonymeter</code> 的範例建議了以下的設定方法：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">columns</span> <span class="o">=</span> <span class="n">ori</span><span class="p">.</span><span class="n">columns</span>

<span class="k">for</span> <span class="n">secret</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
    <span class="n">aux_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns</span> <span class="k">if</span> <span class="n">col</span> <span class="o">!=</span> <span class="n">secret</span><span class="p">]</span>
    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">InferenceEvaluator</span><span class="p">(</span>
        <span class="n">aux_cols</span><span class="o">=</span><span class="n">aux_cols</span><span class="p">,</span>
        <span class="n">secret</span><span class="o">=</span><span class="n">secret</span><span class="p">,</span>
        <span class="p">...</span>
    <span class="p">)</span>
</code></pre></div></div>

<p>This approach allows us to iterate through each column considered as a <code class="language-plaintext highlighter-rouge">secret</code>. And following the method outlined in the <code class="language-plaintext highlighter-rouge">Anonymeter</code> paper, averaging all the risk results for the <code class="language-plaintext highlighter-rouge">secret</code> attributes results in the dataset’s overall inference risk (not detailed in the paper, but calculated as the arithmetic mean by <code class="language-plaintext highlighter-rouge">PETsARD</code>).</p>

<p>Currently, both <code class="language-plaintext highlighter-rouge">secret</code> and <code class="language-plaintext highlighter-rouge">aux_cols</code> have no default values, and it is recommended for users to manually set <code class="language-plaintext highlighter-rouge">aux_cols</code> as all attributes except for the <code class="language-plaintext highlighter-rouge">secret</code>. In future updates, following the experimental approach outlined in the <code class="language-plaintext highlighter-rouge">Anonymeter</code> paper, the attacker’s auxiliary information will be considered in a range from “only one column other than secret” to “all columns other than secret,” and these options will be provided as default values.</p>

<p>這樣能遍歷每個欄位被視作 <code class="language-plaintext highlighter-rouge">secret</code>。然後參考 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 論文的方法，對所有 <code class="language-plaintext highlighter-rouge">secret</code> 的風險結果取平均、則為資料集整體的 <strong>推論性風險</strong>（論文中沒詳細描述，但 <code class="language-plaintext highlighter-rouge">PETsARD</code> 使用算術平均）。</p>

<p>目前 <code class="language-plaintext highlighter-rouge">secret</code> 跟 <code class="language-plaintext highlighter-rouge">aux_cols</code> 都沒有預設值，建議使用者手動設定為 <code class="language-plaintext highlighter-rouge">aux_cols</code> 統一為 <code class="language-plaintext highlighter-rouge">secret</code> 以外的所有屬性。在未來更新中，將依照 <code class="language-plaintext highlighter-rouge">Anonymeter</code> 論文的實驗方式，將攻擊者的輔助資訊從「除 <code class="language-plaintext highlighter-rouge">secret</code> 以外僅有一列」到「除 <code class="language-plaintext highlighter-rouge">secret</code> 以外所有列」所有抽樣方式都遍歷考慮一次，來提供這樣的預設值。</p>

<h2 id="refenece">Refenece</h2>

<p>For explanations of the library in this paper and translations of terminologies between Chinese and English, please refer to the following references:</p>

<p>本文之函式庫解釋與中英用詞翻譯，請參閱以下文獻：</p>

<ul>
  <li>Giomi, M., Boenisch, F., Wehmeyer, C., &amp; Tasnádi, B. (2023). A Unified Framework for Quantifying Privacy Risk in Synthetic Data. <em>Proceedings of Privacy Enhancing Technologies Symposium</em>, 2023(2), 312–328. https://doi.org/10.56553/popets-2023-0055</li>
  <li>蔡柏毅（2021）。淺談個資「去識別化」與「合理利用」間的平衡。《金融聯合徵信》，第三十九期，2021年12月。</li>
</ul>]]></content><author><name>NICS - PETs</name></author><summary type="html"><![CDATA[Anonymeter]]></summary></entry></feed>