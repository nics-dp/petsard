---
title: 反覆調校：資料屬性調整
type: docs
weight: 5
prev: docs/best-practices
next: docs/api
sidebar:
  open: true
---

## 概述

資料屬性調整是確保合成資料品質的關鍵環節，但這**不是一次性的設定工作，而是一個反覆迭代的調校過程**。

### 反覆調整的工作流程

在實務應用中，資料屬性調整遵循以下迭代循環：

1. **初步合成**：使用預設或基本的資料處理設定，產生第一版合成資料
2. **評測分析**：透過評測指標（如 Column Shapes、Column Pair Trends、Synthesis）檢視合成品質
3. **問題診斷**：當評測結果不理想時，深入分析哪些欄位或資料特性導致問題
4. **針對性調整**：根據資料特性，調整個別欄位的處理方式或整體資料集的設定
5. **重新合成與評測**：應用新的設定，再次產生合成資料並評測
6. **持續優化**：重複上述步驟，直到達到滿意的評測結果

這個過程強調**以評測為導向的優化策略**：不是盲目套用所有可能的調整方法，而是根據評測結果的具體問題，有針對性地選擇和調整處理策略。例如：

- 當 **Column Shapes 分數偏低**時，可能需要考慮對數轉換來處理長尾分佈
- 當 **類別變數的分布差異大**時，可能需要套用均勻編碼
- 當 **時間邏輯出現矛盾**時，可能需要使用時間定錨縮放
- 當 **某些子群的合成品質不佳**時，可能需要考慮拆分合成策略

### 調整方法的本質

不同的資料特性需要採用不同的處理策略，以確保合成器能夠有效學習資料的統計特性與業務邏輯。每一種調整方法都是針對特定類型的資料問題所設計的工具，透過適當的組合運用，可以顯著提升合成品質。

本節介紹四種常見的資料屬性調整方法，涵蓋處理複雜資料結構、類別變數、分布偏態以及時序關係等重要議題。重要的是理解**何時**以及**為何**需要使用這些方法，而非機械式地套用所有技術。

## 調整方法概覽

### 一、高異質性資料：拆分合成

針對包含多種異質性屬性的資料，透過拆分-合成-合併（Split-Synthesize-Merge）策略將資料分成較為同質的子集，分別進行合成後再整合。這種方法源於處理大型資料集的硬體限制，但實踐中發現其對改善異質性資料和不平衡資料的合成品質有顯著效果。

**適用情境**：
- 資料量過大，單次無法載入記憶體（如全臺人口資料 ~5GB）
- 存在明顯的內在異質性（如單人戶 vs. 多人戶）
- 高度不平衡資料（如詐欺偵測中正常交易 99% vs. 詐欺交易 1%）
- 需要針對不同子群採用不同的合成策略或參數

**預期效果**：
- 突破硬體限制，處理大型資料集
- 提升各子群的合成品質（更精確捕捉子群特性）
- 改善罕見類別的合成效果
- 可針對不同子群靈活調整策略

**詳細說明**：[高異質性資料：拆分合成](split-synthesize)

### 二、類別資料：均勻編碼

針對類別變數採用均勻編碼（Uniform Encoding）方法，將離散的類別值映射到連續的 [0,1] 區間，且區間大小由類別出現頻率決定，使合成器能更有效地學習類別分布與關聯性。

**適用情境**：
- 資料包含名義或順序尺度的類別變數
- 類別數量適中（每個變數不超過 100 個唯一值）
- 類別間的出現頻率存在差異
- 使用深度學習合成器（如 CTGAN、TVAE）

**預期效果**：
- 避免引入不存在的順序關係
- 保留原始類別分布資訊
- 提升合成資料的保真度（平均提升 15-40%）
- 減少無效或不合理的合成樣本

**詳細說明**：[類別資料：均勻編碼](categorical)

### 三、長尾分佈：對數轉換

針對呈現長尾分佈（heavy-tailed distribution）的數值變數，透過對數轉換（log 或 log1p）將偏態分布轉換為較為對稱的分布，使合成器更容易捕捉資料特性。對數轉換能夠壓縮值域範圍、減少極端值影響，並改善模型學習效果。

**適用情境**：
- 數值變數呈現顯著的右偏或左偏（偏度絕對值 > 1）
- 存在極端值或離群值（最大值與中位數比值 > 10）
- 變數的動態範圍很大（如收入、交易金額、網站流量）
- 變數間呈現乘法關係而非加法關係

**預期效果**：
- 將偏態分布轉換為接近常態分布
- 降低極端值的主導影響
- 改善合成器的學習效果與訓練穩定性
- 提升數值分布相似度（Column Shapes 分數平均提升 10-30%）

**詳細說明**：[長尾分佈：對數轉換](long-tail)

### 四、多時間點資料：時間定錨縮放

針對包含多個時間點的資料，採用時間定錨（Time Anchoring）方法，將各時間點轉換為相對於錨點的時間差，確保合成資料能夠保持時間點之間的邏輯關係與業務約束。

**適用情境**：
- 資料包含 2 個以上的時間或日期欄位
- 時間點之間有明確的先後順序關係
- 時間點代表同一實體的不同生命週期階段
- 時間點之間的間隔反映重要的業務規律

**預期效果**：
- 大幅降低違反時間邏輯的合成記錄
- 更好地保留時間點之間的關聯模式
- 提升合成器的學習效率與穩定性
- 確保業務邏輯的一致性

**詳細說明**：[多時間點資料：時間定錨縮放](multi-timestamp)

## 選擇適當的調整方法

不同的資料特性需要採用不同的調整策略。以下是選擇指南：

| 資料特性 | 建議方法 | 優先級 |
|---------|---------|-------|
| 包含多種類別變數 | 均勻編碼 | 必要 |
| 包含多個時間點 | 時間定錨縮放 | 強烈建議 |
| 數值分布呈現長尾 | 對數轉換 | 建議 |
| 資料結構高度異質 | 拆分合成 | 視情況 |

## 組合使用

在實務應用中，往往需要組合使用多種調整方法：

**範例 1：企業融資資料**
- 時間定錨縮放（處理多個申請、核准、追蹤時間點）
- 均勻編碼（處理產業類別、融資類型等）
- 對數轉換（處理融資金額等長尾分布）

**範例 2：學生入學資料**
- 均勻編碼（處理系所、入學方式、身分別等）
- 類別視為時間（處理出生年月日）
- 高基數處理（處理系所代碼等）

## 注意事項

1. **評估必要性**：並非所有資料都需要所有調整方法，應根據實際資料特性選擇
2. **順序考量**：某些調整方法的執行順序會影響結果，需要謹慎規劃
3. **業務邏輯**：調整過程應始終考慮業務邏輯，避免產生不合理的資料
4. **效果驗證**：調整後應透過評估指標確認是否達到預期效果

## 相關文件

- [最佳實踐](../best-practices)
- [Preprocessor 設定詳細說明](../petsard-yaml/preprocessor-yaml)
- [資料保真度評測](../petsard-yaml/evaluator-yaml/#資料保真度)
- [保真度或實用性](../evaluation-purpose/fidelity-or-utility)